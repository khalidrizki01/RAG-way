# dataset config
dataset_path: "khalidrizki/postretrieve-raw-dataset-v2"
query_col: "query"
ans_col: "label"
psg_col: "sorted_truncPassages"
max_samples: null

# model config
model_dtype: "bfloat16"

# trainer config
seed: 42
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
lr_scheduler_type: "linear"
warmup_ratio: 0.03
alpha_nll: 1.0

# retriever config
retriever_name_or_path: "intfloat/multilingual-e5-small"
retrieval_context_length: 340

# prompting config
chat_format: "qwen"

# output
model_size: "1.7B"
output_dir: "../output"

# xrag
update_projector_only: true
save_embeddings_generated: false
processing_steps_output_dir: "../../generated_data/xRAG-process"

# task config
task_type: "finetune"
model_name_or_path: "Qwen/Qwen3-1.7B"
projector_path: "../output/pretrained/2025-07-17_18-02-15/projector_checkpoints/epoch_10/projector.pth"
num_train_epochs: 10
learning_rate: 0.001
alpha_kl: 2.0
kl_temperature: 1.0
max_seq_length: 1620
retrieval_embed_length: 3
use_rag_tuning: true