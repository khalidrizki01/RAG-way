{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf145be",
   "metadata": {},
   "source": [
    "# Cek Apakah passage masih memiliki \\n\\n\n",
    "\\n\\n adalah separator antara passage, yg mana jika tidak ada berarti model llm hanya menerima input teks berupa passage pertama saja, dan bukan passage kedua & ketika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load dataset dan tokenizer\n",
    "dataset_name = \"khalidrizki//RECOMP-tuning\"\n",
    "model_name = \"./models/-google-flan-t5-base-2025-06-09_19-36-13\"\n",
    "dataset = load_from_disk(dataset_name)\n",
    "test_data = dataset[\"test\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Inisialisasi\n",
    "decoded_passages = []\n",
    "pipe_counts = []\n",
    "multi_pipe_count = 0\n",
    "single_or_none_pipe_count = 0\n",
    "\n",
    "# Proses setiap passage\n",
    "for passage in tqdm(test_data[\"passages\"]):\n",
    "    # Tokenisasi dan truncation\n",
    "    tokenized = tokenizer(\n",
    "        passage,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    # Decode\n",
    "    decoded = tokenizer.decode(tokenized[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    decoded_passages.append(decoded)\n",
    "\n",
    "    # Hitung jumlah karakter pipe\n",
    "    pipe_count = decoded.count(\"|\")\n",
    "    pipe_counts.append(pipe_count)\n",
    "\n",
    "    # Klasifikasi\n",
    "    if pipe_count > 1:\n",
    "        multi_pipe_count += 1\n",
    "    else:\n",
    "        single_or_none_pipe_count += 1\n",
    "\n",
    "# Tambahkan kolom ke dataset\n",
    "test_data = test_data.add_column(\"truncated_decoded_passage\", decoded_passages)\n",
    "test_data = test_data.add_column(\"pipe_count\", pipe_counts)\n",
    "\n",
    "# Hitung total dan persentase\n",
    "total = multi_pipe_count + single_or_none_pipe_count\n",
    "percent_multi = 100 * multi_pipe_count / total\n",
    "percent_single_or_none = 100 * single_or_none_pipe_count / total\n",
    "\n",
    "# Cetak statistik\n",
    "print(f\"Total entries: {total}\")\n",
    "print(f\"Pipe > 1: {multi_pipe_count} ({percent_multi:.2f}%)\")\n",
    "print(f\"Pipe ≤ 1: {single_or_none_pipe_count} ({percent_single_or_none:.2f}%)\")\n",
    "\n",
    "# # Contoh hasil\n",
    "# print(\"\\nContoh hasil:\")\n",
    "# for i in range(3):\n",
    "#     print(f\"\\nOriginal passage:\\n{test_data['passages'][i]}\")\n",
    "#     print(f\"\\nTruncated-decoded passage:\\n{test_data['truncated_decoded_passage'][i]}\")\n",
    "#     print(f\"Jumlah karakter '|': {test_data['pipe_count'][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 990M/990M [12:59<00:00, 1.27MB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/khalidrizki/T5base-RECOMP-seededDataset-withSelection/commit/0ae16a2cd84260598315c767c2130f589dd45333', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='0ae16a2cd84260598315c767c2130f589dd45333', pr_url=None, repo_url=RepoUrl('https://huggingface.co/khalidrizki/T5base-RECOMP-seededDataset-withSelection', endpoint='https://huggingface.co', repo_type='model', repo_id='khalidrizki/T5base-RECOMP-seededDataset-withSelection'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "seeded_and_with_selection = \"./models/-google-flan-t5-base-2025-06-09_19-36-13\"\n",
    "t5_seeded_with_selection = AutoModelForSeq2SeqLM.from_pretrained(seeded_and_with_selection)\n",
    "t5_sws_tokenizer = AutoTokenizer.from_pretrained(seeded_and_with_selection)\n",
    "t5_seeded_with_selection.push_to_hub('khalidrizki/T5base-RECOMP-seededDataset-withSelection')\n",
    "t5_sws_tokenizer.push_to_hub('khalidrizki/T5base-RECOMP-seededDataset-withSelection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fc44b",
   "metadata": {},
   "source": [
    "# Generate Answer based on T5 Summary (dgn target=final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e929529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on cuda with torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"khalidrizki/RECOMP-tuning\")\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "from utils import load_model_and_tokenizer\n",
    "model_name='Qwen/Qwen3-1.7B'\n",
    "model, tokenizer, config = load_model_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626b542",
   "metadata": {},
   "source": [
    "Di bawah, aku akan melakukan pengujian terhadap beberapa kasus berbeda:\n",
    "1. Model yg dilatih thd dataset yg telah di-seed dan dataset latihan tsb ada seleksinya `(khalidrizki/T5base-RECOMP-seededDataset-withSelection)`\n",
    "2. Model yg dilatih thd dataset yg telah di-seed dan dataset latihan tsb tiada seleksi\n",
    "3. Model yg dilatih thd dataset yg belum di-seed dan dataset latihan tsb ada seleksi\n",
    "4. Model yg dilatih thd dataset yg belum di-seed dan dataset latihan tsb tiada seleksi `(khalidrizki/T5base-RECOMP-unseedDataset-noSelection)`\n",
    "\n",
    "Perangkuman oleh kompresor sudah dijalankan dengan command `python train_summarizer.py --model_name_or_path khalidrizki/{TERGANTUNG PAKAI MODEL APA} --do_predict --dataset_name khalidrizki/RECOMP-tuning --max_target_length 52 --output_dir ./outputs/ --per_device_eval_batch_size=32 --predict_with_generate --summary_column final_summary --seed 42`\n",
    "\n",
    "Seharusnya: antar model yg sama2 melakukan with/no seleksi (tetapi hanya dibedakan oleh seed dataset saja) akan memiliki skor yang mirip. \n",
    "\n",
    "__Ukuran dataset kurang?__: antar model yg sama-sama un/seeded (tetapi berbeda pada diterapkan atau tidaknya seleksi), model yg dgn seleksi seharusnya lebih baik. Kalau tidak lebih baik, berarti ukuran dataset kurang. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2451df",
   "metadata": {},
   "source": [
    "Idealnya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddc59e",
   "metadata": {},
   "source": [
    "## T5base-RECOMP-seededDataset-withSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93da710",
   "metadata": {},
   "source": [
    "Sebelum menjalankan generasi jawaban dengan rangkuman hasil fine tuning T5, T5 sudah melakukan generasi rangkuman ketika menjalankan train_summarizer.py dengan command `python train_summarizer.py --do_predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee605d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Jumlah prediksi (564) tidak sama dengan jumlah data (565)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pastikan jumlah prediksi sama dengan jumlah data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predictions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJumlah prediksi (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) tidak sama dengan jumlah data (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Jumlah prediksi (564) tidak sama dengan jumlah data (565)"
     ]
    }
   ],
   "source": [
    "# Muat baris-baris teks dari file\n",
    "with open(\"./outputs/-khalidrizki-T5base-RECOMP-seededDataset-withSelection_on-recompTuning_hub_dataset/generated_predictions.txt\", \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "    predictions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Pastikan jumlah prediksi sama dengan jumlah data\n",
    "assert len(predictions) == len(test_data), f\"Jumlah prediksi ({len(predictions)}) tidak sama dengan jumlah data ({len(test_data)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4223e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah prediksi kurang, meng-append string kosong (\"\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses with summary only:   0%|          | 0/565 [00:00<?, ?it/s]c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Generating responses with summary only: 100%|██████████| 565/565 [30:59<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "while len(predictions) < len(test_data):\n",
    "    print('jumlah prediksi kurang, meng-append string kosong (\"\")')\n",
    "    predictions.append(\"\")\n",
    "\n",
    "# Pastikan jumlah prediksi sama dengan jumlah data\n",
    "assert len(predictions) == len(test_data), f\"Jumlah prediksi ({len(predictions)}) tidak sama dengan jumlah data ({len(test_data)})\"\n",
    "\n",
    "# Tambahkan kolom ke dataset\n",
    "test_data = test_data.add_column(\"T5_summary\", predictions)\n",
    "\n",
    "from generate_answer import generate_answer_and_do_scoring\n",
    "\n",
    "answer_based_on_t5_summary = generate_answer_and_do_scoring(\n",
    "    test_data, \n",
    "    query_col='query', \n",
    "    summary_col=\"T5_summary\", \n",
    "    label_col='answer', \n",
    "    passages_col='passages', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=52\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854bd1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.10973451327433628\n",
      "F1: 0.08678890872044633\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "result = Dataset.from_list(answer_based_on_t5_summary)\n",
    "em_avg = sum(result['em'])/len(result)\n",
    "f1_avg =  sum(result['f1'])/len(result)\n",
    "print(\"EM:\" ,em_avg)\n",
    "print(\"F1:\", f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11504424778761062"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "em_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da279cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0948697836281932"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c4554",
   "metadata": {},
   "source": [
    "## T5base-RECOMP-unseedDataset-noSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f5e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses with summary only:   0%|          | 0/565 [00:00<?, ?it/s]c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Generating responses with summary only: 100%|██████████| 565/565 [26:12<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.4247787610619469\n",
      "F1: 0.2505083083585362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Muat baris-baris teks dari file\n",
    "with open(\"./outputs/-khalidrizki-T5base-RECOMP-unseedDataset-noSelection_on-recompTuning_hub_dataset/generated_predictions.txt\", \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "    predictions_unselective = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Pastikan jumlah prediksi sama dengan jumlah data\n",
    "assert len(predictions_unselective) == len(test_data), f\"Jumlah prediksi ({len(predictions_unselective)}) tidak sama dengan jumlah data ({len(test_data)})\"\n",
    "\n",
    "# Tambahkan kolom ke dataset\n",
    "test_data = test_data.add_column(\"unselective_summary\", predictions_unselective)\n",
    "\n",
    "from generate_answer import generate_answer_and_do_scoring\n",
    "\n",
    "answer_based_on_unselective_summary = generate_answer_and_do_scoring(\n",
    "    test_data, \n",
    "    query_col='query', \n",
    "    summary_col=\"unselective_summary\", \n",
    "    label_col='answer', \n",
    "    passages_col='passages', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=52\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "result_uns = Dataset.from_list(answer_based_on_unselective_summary)\n",
    "em_uns_avg = sum(result_uns['em'])/len(result_uns)\n",
    "f1_uns_avg =  sum(result_uns['f1'])/len(result_uns)\n",
    "print(\"EM:\" ,em_uns_avg)\n",
    "print(\"F1:\", f1_uns_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed06fa",
   "metadata": {},
   "source": [
    "## RAG konvensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1dff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses with summary only: 100%|██████████| 565/565 [35:01<00:00,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HASIL RAG BIASA\n",
      "rerata EM: 0.32035398230088497\n",
      "rerata F1: 0.1765652985106173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from generate_answer import generate_answer_and_do_scoring\n",
    "answer_based_on_passages = generate_answer_and_do_scoring(\n",
    "    test_data, \n",
    "    query_col='query', \n",
    "    summary_col=\"passages\", \n",
    "    label_col='answer', \n",
    "    passages_col='passages', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=52, \n",
    "    max_source_length = 512\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "normal_RAG = Dataset.from_list(answer_based_on_passages)\n",
    "print(\"HASIL RAG BIASA\")\n",
    "print(\"rerata EM:\", sum(normal_RAG['em'])/len(normal_RAG))\n",
    "print(\"rerata F1:\", sum(normal_RAG['f1'])/len(normal_RAG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae39292",
   "metadata": {},
   "source": [
    "# Comparison (tidak diperlukan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dab6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris sama    : 465\n",
      "Jumlah baris berbeda : 100\n"
     ]
    }
   ],
   "source": [
    "result_1 = \"./outputs/-.-models--google-flan-t5-base-2025-05-28_07-17-31-2025-05-28_10-26-57/generated_predictions.txt\"\n",
    "result_2 = \"./outputs/-khalidrizki-T5base-RECOMP-unseedDataset-noSelection_on-recompTuning_hub_dataset/generated_predictions.txt\"\n",
    "output_diff = \"perbedaan.txt\"\n",
    "\n",
    "# Baca semua baris dari kedua file\n",
    "with open(result_1, \"r\", encoding=\"utf-8\") as f1, open(result_2, \"r\", encoding=\"utf-8\") as f2:\n",
    "    lines1 = [line.rstrip('\\n') for line in f1]\n",
    "    lines2 = [line.rstrip('\\n') for line in f2]\n",
    "\n",
    "# Pastikan jumlah baris sama\n",
    "min_len = min(len(lines1), len(lines2))\n",
    "same_count = 0\n",
    "diff_count = 0\n",
    "\n",
    "with open(output_diff, \"w\", encoding=\"utf-8\") as out:\n",
    "    for i in range(min_len):\n",
    "        if lines1[i] == lines2[i]:\n",
    "            same_count += 1\n",
    "        else:\n",
    "            diff_count += 1\n",
    "            out.write(f\"[Baris {i+1} berbeda]\\n\")\n",
    "            out.write(f\"result_1: {lines1[i]}\\n\")\n",
    "            out.write(f\"result_2: {lines2[i]}\\n\\n\")\n",
    "\n",
    "    if len(lines1) != len(lines2):\n",
    "        out.write(\"[Jumlah baris berbeda antara kedua file]\\n\")\n",
    "        out.write(f\"Total baris result_1: {len(lines1)}\\n\")\n",
    "        out.write(f\"Total baris result_2: {len(lines2)}\\n\")\n",
    "\n",
    "# Cetak ringkasan\n",
    "print(f\"Jumlah baris sama    : {same_count}\")\n",
    "print(f\"Jumlah baris berbeda : {diff_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad80e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('khalidrizki/RECOMP-tuning')\n",
    "test = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc65954",
   "metadata": {},
   "source": [
    "# Percobaan pada dataset lama (tidak di-seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "result_of_unseed_dataset_with_no_selective_summarization = (\"./outputs/EM_F1_testing/SCORES_google-flan-t5-base-2025-05-28_07-17-31\")\n",
    "fin = load_dataset(result_of_unseed_dataset_with_no_selective_summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c96b284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42123893805309737"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fin['em'])/len(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63c4c66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(substringmatch_xcode_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c0e3d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(substringmatch_xcode_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea5f642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25522817089095584"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fin['f1'])/len(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904bccc",
   "metadata": {},
   "source": [
    "## Menguji kinerja jika menggunakan RAG biasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_answer import generate_answer_and_do_scoring\n",
    "answer_based_on_passages = generate_answer_and_do_scoring(\n",
    "    test_data, \n",
    "    query_col='query', \n",
    "    summary_col=\"passages\", \n",
    "    label_col='answer', \n",
    "    passages_col='passages', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=52, \n",
    "    max_source_length = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3beeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HASIL RAG BIASA\n",
      "rerata EM: 0.29557522123893804\n",
      "rerata F1: 0.1659491847867348\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "normal_RAG = Dataset.from_list(answer_based_on_passages)\n",
    "print(\"HASIL RAG BIASA\")\n",
    "print(\"rerata EM:\", sum(normal_RAG['em'])/len(normal_RAG))\n",
    "print(\"rerata F1:\", sum(normal_RAG['f1'])/len(normal_RAG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402105f4",
   "metadata": {},
   "source": [
    "__Terbukti bahwa dengan menggunakan RECOMP kinerja RAG menjadi lebih baik, bisa dilihat dari skor EM dan F1 nya yang lebih tinggi__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc1cfe",
   "metadata": {},
   "source": [
    "# Push Model ke Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d95914",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model_path = \"./models/-google-flan-t5-base-2025-05-28_07-17-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b58f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_model_path)\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_repo = \"khalidrizki/indonesian-T5-RECOMP\"\n",
    "t5_model.push_to_hub(hub_repo)\n",
    "t5_tokenizer.push_to_hub(hub_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c9ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
