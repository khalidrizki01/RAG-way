{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model, Tokenizer, dan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on cuda with torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERHASIL MELOAD MODEL DAN DATASET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load ===================================================================================\n",
    "from datasets import load_dataset\n",
    "from utils import load_model_and_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\" \n",
    "model, tokenizer, config = load_model_and_tokenizer(model_name)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "dataset = load_dataset(\"khalidrizki/post-retrieval-research_raw-dataset\")\n",
    "print(\"BERHASIL MELOAD MODEL DAN DATASET\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERHASIL MEMFORMAT PASSAGES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Formatting ============================================================================================================\n",
    "import datasets\n",
    "from functools import partial\n",
    "\n",
    "def format_passages(example, psgs_col):\n",
    "    \"\"\"\n",
    "    Join ketiga passages dengan \\n\\n sebagai penghubung\n",
    "    \"\"\"\n",
    "    \n",
    "    example['formatted_passages'] = \"\\n\\n\".join(example[psgs_col])\n",
    "    return example\n",
    "\n",
    "_format_psgs = partial(\n",
    "    format_passages, \n",
    "    psgs_col = 'passages'\n",
    ")\n",
    "\n",
    "fin_dataset = {}\n",
    "\n",
    "for split in dataset.keys():\n",
    "    fin_dataset[split] = dataset[split].map(_format_psgs)\n",
    "    fin_dataset[split] = fin_dataset[split].remove_columns('passages')\n",
    "\n",
    "fin_dataset = datasets.DatasetDict(fin_dataset)\n",
    "print(\"BERHASIL MEMFORMAT PASSAGES\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Memproses split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing dataset:   0%|          | 0/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\recomp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Summarizing dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [4:27:19<00:00,  3.53s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Split train selesai dalam 16040.18 detik\n",
      "ðŸ”„ Memproses split: dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1143/1143 [1:07:38<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Split dev selesai dalam 4059.40 detik\n",
      "ðŸ”„ Memproses split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [33:12<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Split test selesai dalam 1993.46 detik\n",
      "BERHASIL MEMBUAT DRAFT SUMMARY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate draft summary =============================================================================================\n",
    "from transformers import set_seed\n",
    "from summarize import generate_summary_dataset\n",
    "import time\n",
    "from datasets import DatasetDict\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Dictionary untuk menyimpan hasil per split\n",
    "processed_splits = {}\n",
    "\n",
    "# Loop untuk setiap split (train, dev, test)\n",
    "for split in fin_dataset.keys():\n",
    "    print(f\"ðŸ”„ Memproses split: {split}\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Jalankan rangkuman untuk split tertentu\n",
    "    final_dataset = generate_summary_dataset(\n",
    "        dataset=fin_dataset[split],  # Proses per split\n",
    "        query_col=\"query\",\n",
    "        psgs_col=\"formatted_passages\", \n",
    "        model=model, \n",
    "        teacher_tokenizer=tokenizer,\n",
    "        student_tokenizer=student_tokenizer,\n",
    "        batch_size=1, \n",
    "        temperature=0, \n",
    "        create_truncated_psg_column=True\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    print(f\"âœ… Split {split} selesai dalam {duration:.2f} detik\")\n",
    "\n",
    "    # Simpan hasil per split ke dalam dictionary\n",
    "    processed_splits[split] = final_dataset\n",
    "\n",
    "# Gabungkan kembali hasil per split menjadi DatasetDict\n",
    "dataset_with_draft_summary = DatasetDict(processed_splits)\n",
    "print(\"BERHASIL MEMBUAT DRAFT SUMMARY\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 69823.59 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1143/1143 [00:00<00:00, 47283.19 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:00<00:00, 28881.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Path penyimpanan hasil akhir\n",
    "save_path = \"./generated_data/draft_summary_dataset\"\n",
    "\n",
    "# Simpan dataset yang telah digabungkan\n",
    "dataset_with_draft_summary.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Generation with Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat dataset latihan (tuning) dimana jika:\n",
    "1. baris yang dengan-rangkuman menghasilkan jawaban lebih baik (EM lebih besar atau F1 lebih besar) maka summary disimpan sebagai kolom final_summary\n",
    "2. baris yang tanpa-rangkuman menghasilkan jawaban lebih baik, maka string kosong (\"\") ditambahkan ke final_summary\n",
    "Untuk melihat baris yang memenuhi kondisi 2, bisa mengecek melalui EDA-tydiqa.ipynb (cell-cell terakhir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Memproses split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses (w/ & wo/ summary): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [7:53:33<00:00,  6.26s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Proses selesai dalam 28413.48 detik\n",
      "ðŸ”„ Memproses split: dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses (w/ & wo/ summary): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1143/1143 [1:59:56<00:00,  6.30s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Proses selesai dalam 7196.87 detik\n",
      "ðŸ”„ Memproses split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses (w/ & wo/ summary): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [1:00:55<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Proses selesai dalam 3655.68 detik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 164068.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1143/1143 [00:00<00:00, 111167.29 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:00<00:00, 71692.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Hasil telah disimpan dalam ./generated_data/RECOMP-tuning-seeded-truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate final summary for Fine-Tuning ==================================================================================\n",
    "from generate_answer import generate_answers_and_compare_between_with_and_without_summary\n",
    "from datasets import DatasetDict, Dataset\n",
    "import time\n",
    "\n",
    "processed_splits = {}\n",
    "\n",
    "# ðŸ”¹ Mulai proses evaluasi per split\n",
    "for split in dataset_with_draft_summary.keys():\n",
    "    print(f\"ðŸ”„ Memproses split: {split}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    final_dataset = generate_answers_and_compare_between_with_and_without_summary(\n",
    "        dataset=dataset_with_draft_summary[split],\n",
    "        passages_column='truncated_passages',\n",
    "        query_column='query', \n",
    "        label_column='answer', \n",
    "        summary_column='summary',  \n",
    "        model=model,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # ðŸ•’ Waktu eksekusi\n",
    "    print(f\"âœ… Proses selesai dalam {end_time - start_time:.2f} detik\")\n",
    "    processed_splits[split] = Dataset.from_list(final_dataset)\n",
    "\n",
    "fin_dataset = DatasetDict(processed_splits)\n",
    "\n",
    "save_path = \"./generated_data/RECOMP-tuning-seeded-truncated\"\n",
    "fin_dataset.save_to_disk(save_path)\n",
    "\n",
    "print(f\"ðŸ“„ Hasil telah disimpan dalam {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
