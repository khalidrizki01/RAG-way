{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015625,
      "grad_norm": 9.878660202026367,
      "learning_rate": 1e-05,
      "loss": 2.3803,
      "step": 1
    },
    {
      "epoch": 0.015625,
      "grad_norm": 14.521728515625,
      "learning_rate": 9.9859375e-06,
      "loss": 3.1348,
      "step": 10
    },
    {
      "epoch": 0.03125,
      "grad_norm": 20.10140609741211,
      "learning_rate": 9.970312500000001e-06,
      "loss": 2.4922,
      "step": 20
    },
    {
      "epoch": 0.046875,
      "grad_norm": 23.816598892211914,
      "learning_rate": 9.9546875e-06,
      "loss": 1.9473,
      "step": 30
    },
    {
      "epoch": 0.0625,
      "grad_norm": 14.149495124816895,
      "learning_rate": 9.9390625e-06,
      "loss": 1.5507,
      "step": 40
    },
    {
      "epoch": 0.078125,
      "grad_norm": 15.617491722106934,
      "learning_rate": 9.9234375e-06,
      "loss": 1.6194,
      "step": 50
    },
    {
      "epoch": 0.09375,
      "grad_norm": 20.295989990234375,
      "learning_rate": 9.907812500000001e-06,
      "loss": 1.4912,
      "step": 60
    },
    {
      "epoch": 0.109375,
      "grad_norm": 5.414828777313232,
      "learning_rate": 9.8921875e-06,
      "loss": 1.0185,
      "step": 70
    },
    {
      "epoch": 0.125,
      "grad_norm": 6.272586345672607,
      "learning_rate": 9.8765625e-06,
      "loss": 1.1705,
      "step": 80
    },
    {
      "epoch": 0.140625,
      "grad_norm": 6.701419353485107,
      "learning_rate": 9.8609375e-06,
      "loss": 1.1057,
      "step": 90
    },
    {
      "epoch": 0.15625,
      "grad_norm": 4.695932388305664,
      "learning_rate": 9.845312500000001e-06,
      "loss": 1.1481,
      "step": 100
    },
    {
      "epoch": 0.171875,
      "grad_norm": 10.191308975219727,
      "learning_rate": 9.829687500000001e-06,
      "loss": 1.1034,
      "step": 110
    },
    {
      "epoch": 0.1875,
      "grad_norm": 3.1307036876678467,
      "learning_rate": 9.8140625e-06,
      "loss": 0.9549,
      "step": 120
    },
    {
      "epoch": 0.203125,
      "grad_norm": 4.758365154266357,
      "learning_rate": 9.7984375e-06,
      "loss": 0.9472,
      "step": 130
    },
    {
      "epoch": 0.21875,
      "grad_norm": 6.166752338409424,
      "learning_rate": 9.782812500000001e-06,
      "loss": 1.1302,
      "step": 140
    },
    {
      "epoch": 0.234375,
      "grad_norm": 4.313662528991699,
      "learning_rate": 9.767187500000001e-06,
      "loss": 0.9067,
      "step": 150
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.697737216949463,
      "learning_rate": 9.7515625e-06,
      "loss": 0.8018,
      "step": 160
    },
    {
      "epoch": 0.265625,
      "grad_norm": 2.892016887664795,
      "learning_rate": 9.7359375e-06,
      "loss": 0.786,
      "step": 170
    },
    {
      "epoch": 0.28125,
      "grad_norm": 3.620281219482422,
      "learning_rate": 9.720312500000002e-06,
      "loss": 0.8594,
      "step": 180
    },
    {
      "epoch": 0.296875,
      "grad_norm": 4.49307918548584,
      "learning_rate": 9.704687500000001e-06,
      "loss": 0.9466,
      "step": 190
    },
    {
      "epoch": 0.3125,
      "grad_norm": 6.143674373626709,
      "learning_rate": 9.689062500000001e-06,
      "loss": 0.737,
      "step": 200
    },
    {
      "epoch": 0.328125,
      "grad_norm": 6.139085292816162,
      "learning_rate": 9.6734375e-06,
      "loss": 0.836,
      "step": 210
    },
    {
      "epoch": 0.34375,
      "grad_norm": 3.24640154838562,
      "learning_rate": 9.657812500000002e-06,
      "loss": 0.9011,
      "step": 220
    },
    {
      "epoch": 0.359375,
      "grad_norm": 5.092447757720947,
      "learning_rate": 9.642187500000001e-06,
      "loss": 0.7585,
      "step": 230
    },
    {
      "epoch": 0.375,
      "grad_norm": 3.549611806869507,
      "learning_rate": 9.626562500000001e-06,
      "loss": 0.7694,
      "step": 240
    },
    {
      "epoch": 0.390625,
      "grad_norm": 3.381171703338623,
      "learning_rate": 9.6109375e-06,
      "loss": 0.9948,
      "step": 250
    },
    {
      "epoch": 0.40625,
      "grad_norm": 3.3904149532318115,
      "learning_rate": 9.5953125e-06,
      "loss": 0.8358,
      "step": 260
    },
    {
      "epoch": 0.421875,
      "grad_norm": 3.653538465499878,
      "learning_rate": 9.579687500000002e-06,
      "loss": 0.8212,
      "step": 270
    },
    {
      "epoch": 0.4375,
      "grad_norm": 4.717761993408203,
      "learning_rate": 9.564062500000001e-06,
      "loss": 0.7795,
      "step": 280
    },
    {
      "epoch": 0.453125,
      "grad_norm": 4.11002779006958,
      "learning_rate": 9.548437500000001e-06,
      "loss": 1.1027,
      "step": 290
    },
    {
      "epoch": 0.46875,
      "grad_norm": 3.019670248031616,
      "learning_rate": 9.5328125e-06,
      "loss": 0.8219,
      "step": 300
    },
    {
      "epoch": 0.484375,
      "grad_norm": 2.3448030948638916,
      "learning_rate": 9.5171875e-06,
      "loss": 0.8835,
      "step": 310
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.872535228729248,
      "learning_rate": 9.501562500000001e-06,
      "loss": 0.9347,
      "step": 320
    },
    {
      "epoch": 0.515625,
      "grad_norm": 4.835353374481201,
      "learning_rate": 9.485937500000001e-06,
      "loss": 0.7865,
      "step": 330
    },
    {
      "epoch": 0.53125,
      "grad_norm": 5.92650032043457,
      "learning_rate": 9.4703125e-06,
      "loss": 0.9354,
      "step": 340
    },
    {
      "epoch": 0.546875,
      "grad_norm": 4.092313766479492,
      "learning_rate": 9.4546875e-06,
      "loss": 0.8978,
      "step": 350
    },
    {
      "epoch": 0.5625,
      "grad_norm": 2.4733853340148926,
      "learning_rate": 9.4390625e-06,
      "loss": 0.7854,
      "step": 360
    },
    {
      "epoch": 0.578125,
      "grad_norm": 4.5236358642578125,
      "learning_rate": 9.423437500000001e-06,
      "loss": 0.7521,
      "step": 370
    },
    {
      "epoch": 0.59375,
      "grad_norm": 3.9206225872039795,
      "learning_rate": 9.4078125e-06,
      "loss": 0.7358,
      "step": 380
    },
    {
      "epoch": 0.609375,
      "grad_norm": 3.3624720573425293,
      "learning_rate": 9.3921875e-06,
      "loss": 0.9183,
      "step": 390
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.554854154586792,
      "learning_rate": 9.3765625e-06,
      "loss": 0.7929,
      "step": 400
    },
    {
      "epoch": 0.640625,
      "grad_norm": 10.8413667678833,
      "learning_rate": 9.3609375e-06,
      "loss": 0.7852,
      "step": 410
    },
    {
      "epoch": 0.65625,
      "grad_norm": 3.7603797912597656,
      "learning_rate": 9.345312500000001e-06,
      "loss": 0.869,
      "step": 420
    },
    {
      "epoch": 0.671875,
      "grad_norm": 2.472838878631592,
      "learning_rate": 9.3296875e-06,
      "loss": 0.6559,
      "step": 430
    },
    {
      "epoch": 0.6875,
      "grad_norm": 5.035876274108887,
      "learning_rate": 9.3140625e-06,
      "loss": 0.8767,
      "step": 440
    },
    {
      "epoch": 0.703125,
      "grad_norm": 11.822576522827148,
      "learning_rate": 9.2984375e-06,
      "loss": 0.7859,
      "step": 450
    },
    {
      "epoch": 0.71875,
      "grad_norm": 4.003129005432129,
      "learning_rate": 9.2828125e-06,
      "loss": 0.9071,
      "step": 460
    },
    {
      "epoch": 0.734375,
      "grad_norm": 4.136967658996582,
      "learning_rate": 9.2671875e-06,
      "loss": 0.7993,
      "step": 470
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.364150524139404,
      "learning_rate": 9.2515625e-06,
      "loss": 0.8491,
      "step": 480
    },
    {
      "epoch": 0.765625,
      "grad_norm": 2.731536865234375,
      "learning_rate": 9.2359375e-06,
      "loss": 0.841,
      "step": 490
    },
    {
      "epoch": 0.78125,
      "grad_norm": 2.9675099849700928,
      "learning_rate": 9.2203125e-06,
      "loss": 0.7261,
      "step": 500
    },
    {
      "epoch": 0.796875,
      "grad_norm": 5.471321105957031,
      "learning_rate": 9.204687500000001e-06,
      "loss": 0.8568,
      "step": 510
    },
    {
      "epoch": 0.8125,
      "grad_norm": 3.23465895652771,
      "learning_rate": 9.1890625e-06,
      "loss": 0.7539,
      "step": 520
    },
    {
      "epoch": 0.828125,
      "grad_norm": 3.7732815742492676,
      "learning_rate": 9.1734375e-06,
      "loss": 0.7933,
      "step": 530
    },
    {
      "epoch": 0.84375,
      "grad_norm": 5.947319984436035,
      "learning_rate": 9.1578125e-06,
      "loss": 0.6193,
      "step": 540
    },
    {
      "epoch": 0.859375,
      "grad_norm": 2.8264122009277344,
      "learning_rate": 9.142187500000001e-06,
      "loss": 0.6884,
      "step": 550
    },
    {
      "epoch": 0.875,
      "grad_norm": 5.236668586730957,
      "learning_rate": 9.1265625e-06,
      "loss": 0.7733,
      "step": 560
    },
    {
      "epoch": 0.890625,
      "grad_norm": 3.6526739597320557,
      "learning_rate": 9.1109375e-06,
      "loss": 0.8222,
      "step": 570
    },
    {
      "epoch": 0.90625,
      "grad_norm": 5.03896951675415,
      "learning_rate": 9.095312500000002e-06,
      "loss": 0.702,
      "step": 580
    },
    {
      "epoch": 0.921875,
      "grad_norm": 4.147180557250977,
      "learning_rate": 9.079687500000001e-06,
      "loss": 0.712,
      "step": 590
    },
    {
      "epoch": 0.9375,
      "grad_norm": 3.121415376663208,
      "learning_rate": 9.064062500000001e-06,
      "loss": 0.8245,
      "step": 600
    },
    {
      "epoch": 0.953125,
      "grad_norm": 3.543242931365967,
      "learning_rate": 9.0484375e-06,
      "loss": 0.7052,
      "step": 610
    },
    {
      "epoch": 0.96875,
      "grad_norm": 3.7722280025482178,
      "learning_rate": 9.032812500000002e-06,
      "loss": 0.7626,
      "step": 620
    },
    {
      "epoch": 0.984375,
      "grad_norm": 10.250044822692871,
      "learning_rate": 9.017187500000001e-06,
      "loss": 0.7495,
      "step": 630
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2241357564926147,
      "learning_rate": 9.001562500000001e-06,
      "loss": 0.716,
      "step": 640
    },
    {
      "epoch": 1.0,
      "eval_gen_len": 1.0,
      "eval_loss": 0.9641740322113037,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 97.3327,
      "eval_samples_per_second": 5.805,
      "eval_steps_per_second": 0.37,
      "step": 640
    },
    {
      "epoch": 1.015625,
      "grad_norm": 2.8589839935302734,
      "learning_rate": 8.9859375e-06,
      "loss": 0.674,
      "step": 650
    },
    {
      "epoch": 1.03125,
      "grad_norm": 3.2480921745300293,
      "learning_rate": 8.9703125e-06,
      "loss": 0.8771,
      "step": 660
    },
    {
      "epoch": 1.046875,
      "grad_norm": 8.714532852172852,
      "learning_rate": 8.954687500000002e-06,
      "loss": 0.7392,
      "step": 670
    },
    {
      "epoch": 1.0625,
      "grad_norm": 3.627073049545288,
      "learning_rate": 8.939062500000001e-06,
      "loss": 0.7737,
      "step": 680
    },
    {
      "epoch": 1.078125,
      "grad_norm": 3.1083860397338867,
      "learning_rate": 8.923437500000001e-06,
      "loss": 0.704,
      "step": 690
    },
    {
      "epoch": 1.09375,
      "grad_norm": 2.6854407787323,
      "learning_rate": 8.9078125e-06,
      "loss": 0.7887,
      "step": 700
    },
    {
      "epoch": 1.109375,
      "grad_norm": 2.828821897506714,
      "learning_rate": 8.8921875e-06,
      "loss": 0.7098,
      "step": 710
    },
    {
      "epoch": 1.125,
      "grad_norm": 2.5602822303771973,
      "learning_rate": 8.876562500000001e-06,
      "loss": 0.8558,
      "step": 720
    },
    {
      "epoch": 1.140625,
      "grad_norm": 4.890735149383545,
      "learning_rate": 8.860937500000001e-06,
      "loss": 0.6793,
      "step": 730
    },
    {
      "epoch": 1.15625,
      "grad_norm": 3.149939775466919,
      "learning_rate": 8.8453125e-06,
      "loss": 0.696,
      "step": 740
    },
    {
      "epoch": 1.171875,
      "grad_norm": 3.664557456970215,
      "learning_rate": 8.8296875e-06,
      "loss": 0.8227,
      "step": 750
    },
    {
      "epoch": 1.1875,
      "grad_norm": 3.0686073303222656,
      "learning_rate": 8.8140625e-06,
      "loss": 0.745,
      "step": 760
    },
    {
      "epoch": 1.203125,
      "grad_norm": 4.406620979309082,
      "learning_rate": 8.798437500000001e-06,
      "loss": 0.731,
      "step": 770
    },
    {
      "epoch": 1.21875,
      "grad_norm": 2.406273126602173,
      "learning_rate": 8.782812500000001e-06,
      "loss": 0.5469,
      "step": 780
    },
    {
      "epoch": 1.234375,
      "grad_norm": 3.1455960273742676,
      "learning_rate": 8.7671875e-06,
      "loss": 0.6394,
      "step": 790
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.1163766384124756,
      "learning_rate": 8.7515625e-06,
      "loss": 0.705,
      "step": 800
    },
    {
      "epoch": 1.265625,
      "grad_norm": 2.0119688510894775,
      "learning_rate": 8.7359375e-06,
      "loss": 0.599,
      "step": 810
    },
    {
      "epoch": 1.28125,
      "grad_norm": 3.470705270767212,
      "learning_rate": 8.720312500000001e-06,
      "loss": 0.6863,
      "step": 820
    },
    {
      "epoch": 1.296875,
      "grad_norm": 2.9890339374542236,
      "learning_rate": 8.7046875e-06,
      "loss": 0.7417,
      "step": 830
    },
    {
      "epoch": 1.3125,
      "grad_norm": 4.2407732009887695,
      "learning_rate": 8.6890625e-06,
      "loss": 0.7375,
      "step": 840
    },
    {
      "epoch": 1.328125,
      "grad_norm": 3.2048001289367676,
      "learning_rate": 8.6734375e-06,
      "loss": 0.7502,
      "step": 850
    },
    {
      "epoch": 1.34375,
      "grad_norm": 4.003453731536865,
      "learning_rate": 8.6578125e-06,
      "loss": 0.7608,
      "step": 860
    },
    {
      "epoch": 1.359375,
      "grad_norm": 3.0554749965667725,
      "learning_rate": 8.642187500000001e-06,
      "loss": 0.673,
      "step": 870
    },
    {
      "epoch": 1.375,
      "grad_norm": 3.055096387863159,
      "learning_rate": 8.6265625e-06,
      "loss": 0.6687,
      "step": 880
    },
    {
      "epoch": 1.390625,
      "grad_norm": 2.8021092414855957,
      "learning_rate": 8.6109375e-06,
      "loss": 0.8237,
      "step": 890
    },
    {
      "epoch": 1.40625,
      "grad_norm": 2.4969942569732666,
      "learning_rate": 8.5953125e-06,
      "loss": 0.6951,
      "step": 900
    },
    {
      "epoch": 1.421875,
      "grad_norm": 2.1175649166107178,
      "learning_rate": 8.5796875e-06,
      "loss": 0.6117,
      "step": 910
    },
    {
      "epoch": 1.4375,
      "grad_norm": 2.5154550075531006,
      "learning_rate": 8.5640625e-06,
      "loss": 0.6252,
      "step": 920
    },
    {
      "epoch": 1.453125,
      "grad_norm": 4.5841755867004395,
      "learning_rate": 8.5484375e-06,
      "loss": 0.7692,
      "step": 930
    },
    {
      "epoch": 1.46875,
      "grad_norm": 3.581568956375122,
      "learning_rate": 8.5328125e-06,
      "loss": 0.952,
      "step": 940
    },
    {
      "epoch": 1.484375,
      "grad_norm": 3.7717316150665283,
      "learning_rate": 8.517187500000001e-06,
      "loss": 0.6356,
      "step": 950
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.7246453762054443,
      "learning_rate": 8.5015625e-06,
      "loss": 0.7778,
      "step": 960
    },
    {
      "epoch": 1.515625,
      "grad_norm": 2.1426515579223633,
      "learning_rate": 8.4859375e-06,
      "loss": 0.6939,
      "step": 970
    },
    {
      "epoch": 1.53125,
      "grad_norm": 5.456077575683594,
      "learning_rate": 8.4703125e-06,
      "loss": 0.7243,
      "step": 980
    },
    {
      "epoch": 1.546875,
      "grad_norm": 3.827204465866089,
      "learning_rate": 8.454687500000001e-06,
      "loss": 0.7648,
      "step": 990
    },
    {
      "epoch": 1.5625,
      "grad_norm": 3.7405152320861816,
      "learning_rate": 8.439062500000001e-06,
      "loss": 0.5699,
      "step": 1000
    },
    {
      "epoch": 1.578125,
      "grad_norm": 3.9927124977111816,
      "learning_rate": 8.4234375e-06,
      "loss": 0.7434,
      "step": 1010
    },
    {
      "epoch": 1.59375,
      "grad_norm": 3.6725914478302,
      "learning_rate": 8.4078125e-06,
      "loss": 0.7912,
      "step": 1020
    },
    {
      "epoch": 1.609375,
      "grad_norm": 2.404083013534546,
      "learning_rate": 8.392187500000002e-06,
      "loss": 0.6244,
      "step": 1030
    },
    {
      "epoch": 1.625,
      "grad_norm": 3.9017140865325928,
      "learning_rate": 8.376562500000001e-06,
      "loss": 0.5982,
      "step": 1040
    },
    {
      "epoch": 1.640625,
      "grad_norm": 3.2533578872680664,
      "learning_rate": 8.3609375e-06,
      "loss": 0.6752,
      "step": 1050
    },
    {
      "epoch": 1.65625,
      "grad_norm": 3.166900634765625,
      "learning_rate": 8.3453125e-06,
      "loss": 0.8096,
      "step": 1060
    },
    {
      "epoch": 1.671875,
      "grad_norm": 2.0537643432617188,
      "learning_rate": 8.329687500000002e-06,
      "loss": 0.7012,
      "step": 1070
    },
    {
      "epoch": 1.6875,
      "grad_norm": 2.742269992828369,
      "learning_rate": 8.314062500000001e-06,
      "loss": 0.7013,
      "step": 1080
    },
    {
      "epoch": 1.703125,
      "grad_norm": 1.969572901725769,
      "learning_rate": 8.298437500000001e-06,
      "loss": 0.5368,
      "step": 1090
    },
    {
      "epoch": 1.71875,
      "grad_norm": 2.8703601360321045,
      "learning_rate": 8.2828125e-06,
      "loss": 0.721,
      "step": 1100
    },
    {
      "epoch": 1.734375,
      "grad_norm": 3.900315046310425,
      "learning_rate": 8.2671875e-06,
      "loss": 0.76,
      "step": 1110
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.547670841217041,
      "learning_rate": 8.251562500000002e-06,
      "loss": 0.6523,
      "step": 1120
    },
    {
      "epoch": 1.765625,
      "grad_norm": 3.5911576747894287,
      "learning_rate": 8.235937500000001e-06,
      "loss": 0.6922,
      "step": 1130
    },
    {
      "epoch": 1.78125,
      "grad_norm": 4.5903000831604,
      "learning_rate": 8.2203125e-06,
      "loss": 0.5676,
      "step": 1140
    },
    {
      "epoch": 1.796875,
      "grad_norm": 3.2262847423553467,
      "learning_rate": 8.2046875e-06,
      "loss": 0.7079,
      "step": 1150
    },
    {
      "epoch": 1.8125,
      "grad_norm": 4.136082172393799,
      "learning_rate": 8.1890625e-06,
      "loss": 0.6367,
      "step": 1160
    },
    {
      "epoch": 1.828125,
      "grad_norm": 4.1362433433532715,
      "learning_rate": 8.173437500000001e-06,
      "loss": 0.7048,
      "step": 1170
    },
    {
      "epoch": 1.84375,
      "grad_norm": 3.6773264408111572,
      "learning_rate": 8.157812500000001e-06,
      "loss": 0.7981,
      "step": 1180
    },
    {
      "epoch": 1.859375,
      "grad_norm": 3.0469183921813965,
      "learning_rate": 8.1421875e-06,
      "loss": 0.6844,
      "step": 1190
    },
    {
      "epoch": 1.875,
      "grad_norm": 2.377060651779175,
      "learning_rate": 8.1265625e-06,
      "loss": 0.7248,
      "step": 1200
    },
    {
      "epoch": 1.890625,
      "grad_norm": 2.451228141784668,
      "learning_rate": 8.1109375e-06,
      "loss": 0.7344,
      "step": 1210
    },
    {
      "epoch": 1.90625,
      "grad_norm": 4.181485652923584,
      "learning_rate": 8.095312500000001e-06,
      "loss": 0.8213,
      "step": 1220
    },
    {
      "epoch": 1.921875,
      "grad_norm": 3.805722713470459,
      "learning_rate": 8.0796875e-06,
      "loss": 0.6745,
      "step": 1230
    },
    {
      "epoch": 1.9375,
      "grad_norm": 2.7033612728118896,
      "learning_rate": 8.0640625e-06,
      "loss": 0.7516,
      "step": 1240
    },
    {
      "epoch": 1.953125,
      "grad_norm": 4.48045015335083,
      "learning_rate": 8.0484375e-06,
      "loss": 0.6553,
      "step": 1250
    },
    {
      "epoch": 1.96875,
      "grad_norm": 3.0597078800201416,
      "learning_rate": 8.0328125e-06,
      "loss": 0.7559,
      "step": 1260
    },
    {
      "epoch": 1.984375,
      "grad_norm": 2.682657480239868,
      "learning_rate": 8.017187500000001e-06,
      "loss": 0.6201,
      "step": 1270
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.450525999069214,
      "learning_rate": 8.0015625e-06,
      "loss": 0.6876,
      "step": 1280
    },
    {
      "epoch": 2.0,
      "eval_gen_len": 1.111504424778761,
      "eval_loss": 0.8900495171546936,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 98.6564,
      "eval_samples_per_second": 5.727,
      "eval_steps_per_second": 0.365,
      "step": 1280
    },
    {
      "epoch": 2.015625,
      "grad_norm": 3.6990880966186523,
      "learning_rate": 7.9859375e-06,
      "loss": 0.7331,
      "step": 1290
    },
    {
      "epoch": 2.03125,
      "grad_norm": 2.78983211517334,
      "learning_rate": 7.9703125e-06,
      "loss": 0.7143,
      "step": 1300
    },
    {
      "epoch": 2.046875,
      "grad_norm": 2.6495413780212402,
      "learning_rate": 7.9546875e-06,
      "loss": 0.7268,
      "step": 1310
    },
    {
      "epoch": 2.0625,
      "grad_norm": 2.187645673751831,
      "learning_rate": 7.9390625e-06,
      "loss": 0.7683,
      "step": 1320
    },
    {
      "epoch": 2.078125,
      "grad_norm": 2.674410820007324,
      "learning_rate": 7.9234375e-06,
      "loss": 0.6438,
      "step": 1330
    },
    {
      "epoch": 2.09375,
      "grad_norm": 2.724907159805298,
      "learning_rate": 7.9078125e-06,
      "loss": 0.6153,
      "step": 1340
    },
    {
      "epoch": 2.109375,
      "grad_norm": 2.7777671813964844,
      "learning_rate": 7.8921875e-06,
      "loss": 0.7851,
      "step": 1350
    },
    {
      "epoch": 2.125,
      "grad_norm": 2.6303110122680664,
      "learning_rate": 7.876562500000001e-06,
      "loss": 0.7344,
      "step": 1360
    },
    {
      "epoch": 2.140625,
      "grad_norm": 3.4115426540374756,
      "learning_rate": 7.8609375e-06,
      "loss": 0.69,
      "step": 1370
    },
    {
      "epoch": 2.15625,
      "grad_norm": 1.9685642719268799,
      "learning_rate": 7.8453125e-06,
      "loss": 0.7106,
      "step": 1380
    },
    {
      "epoch": 2.171875,
      "grad_norm": 3.0170018672943115,
      "learning_rate": 7.8296875e-06,
      "loss": 0.6717,
      "step": 1390
    },
    {
      "epoch": 2.1875,
      "grad_norm": 3.5273866653442383,
      "learning_rate": 7.814062500000001e-06,
      "loss": 0.7097,
      "step": 1400
    },
    {
      "epoch": 2.203125,
      "grad_norm": 2.291107654571533,
      "learning_rate": 7.7984375e-06,
      "loss": 0.6583,
      "step": 1410
    },
    {
      "epoch": 2.21875,
      "grad_norm": 2.788076877593994,
      "learning_rate": 7.7828125e-06,
      "loss": 0.5863,
      "step": 1420
    },
    {
      "epoch": 2.234375,
      "grad_norm": 1.942647099494934,
      "learning_rate": 7.767187500000002e-06,
      "loss": 0.7734,
      "step": 1430
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.7570114135742188,
      "learning_rate": 7.751562500000001e-06,
      "loss": 0.7753,
      "step": 1440
    },
    {
      "epoch": 2.265625,
      "grad_norm": 3.780627965927124,
      "learning_rate": 7.7359375e-06,
      "loss": 0.6924,
      "step": 1450
    },
    {
      "epoch": 2.28125,
      "grad_norm": 3.4928061962127686,
      "learning_rate": 7.7203125e-06,
      "loss": 0.687,
      "step": 1460
    },
    {
      "epoch": 2.296875,
      "grad_norm": 2.564694404602051,
      "learning_rate": 7.704687500000002e-06,
      "loss": 0.6411,
      "step": 1470
    },
    {
      "epoch": 2.3125,
      "grad_norm": 3.5715816020965576,
      "learning_rate": 7.689062500000001e-06,
      "loss": 0.662,
      "step": 1480
    },
    {
      "epoch": 2.328125,
      "grad_norm": 9.890701293945312,
      "learning_rate": 7.673437500000001e-06,
      "loss": 0.7009,
      "step": 1490
    },
    {
      "epoch": 2.34375,
      "grad_norm": 4.415441513061523,
      "learning_rate": 7.6578125e-06,
      "loss": 0.7285,
      "step": 1500
    },
    {
      "epoch": 2.359375,
      "grad_norm": 6.076531887054443,
      "learning_rate": 7.6421875e-06,
      "loss": 0.6119,
      "step": 1510
    },
    {
      "epoch": 2.375,
      "grad_norm": 2.4835615158081055,
      "learning_rate": 7.626562500000001e-06,
      "loss": 0.6286,
      "step": 1520
    },
    {
      "epoch": 2.390625,
      "grad_norm": 2.8606019020080566,
      "learning_rate": 7.6109375e-06,
      "loss": 0.6718,
      "step": 1530
    },
    {
      "epoch": 2.40625,
      "grad_norm": 3.1791694164276123,
      "learning_rate": 7.595312500000001e-06,
      "loss": 0.6158,
      "step": 1540
    },
    {
      "epoch": 2.421875,
      "grad_norm": 2.5457704067230225,
      "learning_rate": 7.5796875000000004e-06,
      "loss": 0.6137,
      "step": 1550
    },
    {
      "epoch": 2.4375,
      "grad_norm": 3.128305673599243,
      "learning_rate": 7.5640625e-06,
      "loss": 0.7175,
      "step": 1560
    },
    {
      "epoch": 2.453125,
      "grad_norm": 2.5150558948516846,
      "learning_rate": 7.548437500000001e-06,
      "loss": 0.6851,
      "step": 1570
    },
    {
      "epoch": 2.46875,
      "grad_norm": 2.7268941402435303,
      "learning_rate": 7.532812500000001e-06,
      "loss": 0.6185,
      "step": 1580
    },
    {
      "epoch": 2.484375,
      "grad_norm": 2.821798086166382,
      "learning_rate": 7.517187500000001e-06,
      "loss": 0.5714,
      "step": 1590
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.5022709369659424,
      "learning_rate": 7.5015625e-06,
      "loss": 0.6564,
      "step": 1600
    },
    {
      "epoch": 2.515625,
      "grad_norm": 3.251844644546509,
      "learning_rate": 7.4859375e-06,
      "loss": 0.6872,
      "step": 1610
    },
    {
      "epoch": 2.53125,
      "grad_norm": 3.373138427734375,
      "learning_rate": 7.470312500000001e-06,
      "loss": 0.6328,
      "step": 1620
    },
    {
      "epoch": 2.546875,
      "grad_norm": 4.100490093231201,
      "learning_rate": 7.454687500000001e-06,
      "loss": 0.6889,
      "step": 1630
    },
    {
      "epoch": 2.5625,
      "grad_norm": 2.291491985321045,
      "learning_rate": 7.4390625e-06,
      "loss": 0.702,
      "step": 1640
    },
    {
      "epoch": 2.578125,
      "grad_norm": 2.227759838104248,
      "learning_rate": 7.4234375e-06,
      "loss": 0.5939,
      "step": 1650
    },
    {
      "epoch": 2.59375,
      "grad_norm": 3.1817054748535156,
      "learning_rate": 7.4078125000000005e-06,
      "loss": 0.6759,
      "step": 1660
    },
    {
      "epoch": 2.609375,
      "grad_norm": 5.9440789222717285,
      "learning_rate": 7.392187500000001e-06,
      "loss": 0.5106,
      "step": 1670
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.9892312288284302,
      "learning_rate": 7.376562500000001e-06,
      "loss": 0.7051,
      "step": 1680
    },
    {
      "epoch": 2.640625,
      "grad_norm": 3.6917858123779297,
      "learning_rate": 7.3609375e-06,
      "loss": 0.7155,
      "step": 1690
    },
    {
      "epoch": 2.65625,
      "grad_norm": 3.262164831161499,
      "learning_rate": 7.345312500000001e-06,
      "loss": 0.6209,
      "step": 1700
    },
    {
      "epoch": 2.671875,
      "grad_norm": 3.0291926860809326,
      "learning_rate": 7.3296875e-06,
      "loss": 0.6434,
      "step": 1710
    },
    {
      "epoch": 2.6875,
      "grad_norm": 2.915748119354248,
      "learning_rate": 7.314062500000001e-06,
      "loss": 0.6651,
      "step": 1720
    },
    {
      "epoch": 2.703125,
      "grad_norm": 3.6299843788146973,
      "learning_rate": 7.2984375e-06,
      "loss": 0.6041,
      "step": 1730
    },
    {
      "epoch": 2.71875,
      "grad_norm": 3.366178512573242,
      "learning_rate": 7.282812500000001e-06,
      "loss": 0.6304,
      "step": 1740
    },
    {
      "epoch": 2.734375,
      "grad_norm": 3.779905080795288,
      "learning_rate": 7.2671875000000005e-06,
      "loss": 0.6089,
      "step": 1750
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.9625407457351685,
      "learning_rate": 7.2515625e-06,
      "loss": 0.5961,
      "step": 1760
    },
    {
      "epoch": 2.765625,
      "grad_norm": 2.748246669769287,
      "learning_rate": 7.2359375000000005e-06,
      "loss": 0.6313,
      "step": 1770
    },
    {
      "epoch": 2.78125,
      "grad_norm": 3.116699695587158,
      "learning_rate": 7.220312500000001e-06,
      "loss": 0.6568,
      "step": 1780
    },
    {
      "epoch": 2.796875,
      "grad_norm": 2.2981300354003906,
      "learning_rate": 7.204687500000001e-06,
      "loss": 0.6466,
      "step": 1790
    },
    {
      "epoch": 2.8125,
      "grad_norm": 6.425499439239502,
      "learning_rate": 7.1890625e-06,
      "loss": 0.6278,
      "step": 1800
    },
    {
      "epoch": 2.828125,
      "grad_norm": 3.073742151260376,
      "learning_rate": 7.1734375e-06,
      "loss": 0.5974,
      "step": 1810
    },
    {
      "epoch": 2.84375,
      "grad_norm": 5.749710559844971,
      "learning_rate": 7.157812500000001e-06,
      "loss": 0.6931,
      "step": 1820
    },
    {
      "epoch": 2.859375,
      "grad_norm": 2.3922955989837646,
      "learning_rate": 7.142187500000001e-06,
      "loss": 0.6272,
      "step": 1830
    },
    {
      "epoch": 2.875,
      "grad_norm": 2.049074411392212,
      "learning_rate": 7.1265625000000004e-06,
      "loss": 0.5288,
      "step": 1840
    },
    {
      "epoch": 2.890625,
      "grad_norm": 3.07401442527771,
      "learning_rate": 7.1109375e-06,
      "loss": 0.6119,
      "step": 1850
    },
    {
      "epoch": 2.90625,
      "grad_norm": 3.786184072494507,
      "learning_rate": 7.0953125e-06,
      "loss": 0.6949,
      "step": 1860
    },
    {
      "epoch": 2.921875,
      "grad_norm": 3.758960485458374,
      "learning_rate": 7.079687500000001e-06,
      "loss": 0.6605,
      "step": 1870
    },
    {
      "epoch": 2.9375,
      "grad_norm": 2.81768798828125,
      "learning_rate": 7.064062500000001e-06,
      "loss": 0.7329,
      "step": 1880
    },
    {
      "epoch": 2.953125,
      "grad_norm": 2.7209370136260986,
      "learning_rate": 7.0484375e-06,
      "loss": 0.6399,
      "step": 1890
    },
    {
      "epoch": 2.96875,
      "grad_norm": 3.0896501541137695,
      "learning_rate": 7.0328125e-06,
      "loss": 0.5016,
      "step": 1900
    },
    {
      "epoch": 2.984375,
      "grad_norm": 3.3212428092956543,
      "learning_rate": 7.0171875e-06,
      "loss": 0.7279,
      "step": 1910
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.695927143096924,
      "learning_rate": 7.001562500000001e-06,
      "loss": 0.6699,
      "step": 1920
    },
    {
      "epoch": 3.0,
      "eval_gen_len": 1.2265486725663717,
      "eval_loss": 0.8605213761329651,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 100.2164,
      "eval_samples_per_second": 5.638,
      "eval_steps_per_second": 0.359,
      "step": 1920
    },
    {
      "epoch": 3.015625,
      "grad_norm": 3.5178964138031006,
      "learning_rate": 6.9859375e-06,
      "loss": 0.5395,
      "step": 1930
    },
    {
      "epoch": 3.03125,
      "grad_norm": 2.1583471298217773,
      "learning_rate": 6.970312500000001e-06,
      "loss": 0.6623,
      "step": 1940
    },
    {
      "epoch": 3.046875,
      "grad_norm": 4.0385541915893555,
      "learning_rate": 6.9546875000000005e-06,
      "loss": 0.6978,
      "step": 1950
    },
    {
      "epoch": 3.0625,
      "grad_norm": 2.955066442489624,
      "learning_rate": 6.9390625e-06,
      "loss": 0.6972,
      "step": 1960
    },
    {
      "epoch": 3.078125,
      "grad_norm": 3.542282819747925,
      "learning_rate": 6.9234375000000006e-06,
      "loss": 0.6791,
      "step": 1970
    },
    {
      "epoch": 3.09375,
      "grad_norm": 2.6745502948760986,
      "learning_rate": 6.907812500000001e-06,
      "loss": 0.6717,
      "step": 1980
    },
    {
      "epoch": 3.109375,
      "grad_norm": 2.977724552154541,
      "learning_rate": 6.892187500000001e-06,
      "loss": 0.5369,
      "step": 1990
    },
    {
      "epoch": 3.125,
      "grad_norm": 4.758754730224609,
      "learning_rate": 6.8765625e-06,
      "loss": 0.6907,
      "step": 2000
    },
    {
      "epoch": 3.140625,
      "grad_norm": 5.061398029327393,
      "learning_rate": 6.8609375e-06,
      "loss": 0.6591,
      "step": 2010
    },
    {
      "epoch": 3.15625,
      "grad_norm": 2.059232234954834,
      "learning_rate": 6.845312500000001e-06,
      "loss": 0.6116,
      "step": 2020
    },
    {
      "epoch": 3.171875,
      "grad_norm": 3.847731590270996,
      "learning_rate": 6.829687500000001e-06,
      "loss": 0.6054,
      "step": 2030
    },
    {
      "epoch": 3.1875,
      "grad_norm": 2.162285089492798,
      "learning_rate": 6.8140625000000005e-06,
      "loss": 0.6259,
      "step": 2040
    },
    {
      "epoch": 3.203125,
      "grad_norm": 2.9598841667175293,
      "learning_rate": 6.7984375e-06,
      "loss": 0.5492,
      "step": 2050
    },
    {
      "epoch": 3.21875,
      "grad_norm": 2.25484561920166,
      "learning_rate": 6.7828125e-06,
      "loss": 0.6607,
      "step": 2060
    },
    {
      "epoch": 3.234375,
      "grad_norm": 4.77207612991333,
      "learning_rate": 6.767187500000001e-06,
      "loss": 0.7139,
      "step": 2070
    },
    {
      "epoch": 3.25,
      "grad_norm": 2.0583558082580566,
      "learning_rate": 6.751562500000001e-06,
      "loss": 0.6514,
      "step": 2080
    },
    {
      "epoch": 3.265625,
      "grad_norm": 3.5033364295959473,
      "learning_rate": 6.7359375e-06,
      "loss": 0.6571,
      "step": 2090
    },
    {
      "epoch": 3.28125,
      "grad_norm": 2.6146771907806396,
      "learning_rate": 6.7203125e-06,
      "loss": 0.6403,
      "step": 2100
    },
    {
      "epoch": 3.296875,
      "grad_norm": 2.777143955230713,
      "learning_rate": 6.7046875e-06,
      "loss": 0.5332,
      "step": 2110
    },
    {
      "epoch": 3.3125,
      "grad_norm": 2.6043834686279297,
      "learning_rate": 6.689062500000001e-06,
      "loss": 0.614,
      "step": 2120
    },
    {
      "epoch": 3.328125,
      "grad_norm": 2.623831272125244,
      "learning_rate": 6.6734375000000004e-06,
      "loss": 0.6394,
      "step": 2130
    },
    {
      "epoch": 3.34375,
      "grad_norm": 1.7848328351974487,
      "learning_rate": 6.6578125e-06,
      "loss": 0.4944,
      "step": 2140
    },
    {
      "epoch": 3.359375,
      "grad_norm": 2.5141844749450684,
      "learning_rate": 6.6421875000000005e-06,
      "loss": 0.5021,
      "step": 2150
    },
    {
      "epoch": 3.375,
      "grad_norm": 4.622405529022217,
      "learning_rate": 6.6265625e-06,
      "loss": 0.5236,
      "step": 2160
    },
    {
      "epoch": 3.390625,
      "grad_norm": 2.556696653366089,
      "learning_rate": 6.610937500000001e-06,
      "loss": 0.6094,
      "step": 2170
    },
    {
      "epoch": 3.40625,
      "grad_norm": 5.699034214019775,
      "learning_rate": 6.595312500000001e-06,
      "loss": 0.5619,
      "step": 2180
    },
    {
      "epoch": 3.421875,
      "grad_norm": 3.1589107513427734,
      "learning_rate": 6.579687500000001e-06,
      "loss": 0.6577,
      "step": 2190
    },
    {
      "epoch": 3.4375,
      "grad_norm": 2.850801467895508,
      "learning_rate": 6.5640625e-06,
      "loss": 0.6225,
      "step": 2200
    },
    {
      "epoch": 3.453125,
      "grad_norm": 2.6492490768432617,
      "learning_rate": 6.5484375e-06,
      "loss": 0.5901,
      "step": 2210
    },
    {
      "epoch": 3.46875,
      "grad_norm": 3.247100353240967,
      "learning_rate": 6.532812500000001e-06,
      "loss": 0.7404,
      "step": 2220
    },
    {
      "epoch": 3.484375,
      "grad_norm": 3.4123151302337646,
      "learning_rate": 6.517187500000001e-06,
      "loss": 0.6611,
      "step": 2230
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.7985284328460693,
      "learning_rate": 6.5015625000000005e-06,
      "loss": 0.7309,
      "step": 2240
    },
    {
      "epoch": 3.515625,
      "grad_norm": 2.4544265270233154,
      "learning_rate": 6.4859375e-06,
      "loss": 0.6283,
      "step": 2250
    },
    {
      "epoch": 3.53125,
      "grad_norm": 2.231135129928589,
      "learning_rate": 6.4703125e-06,
      "loss": 0.6863,
      "step": 2260
    },
    {
      "epoch": 3.546875,
      "grad_norm": 2.3064236640930176,
      "learning_rate": 6.454687500000001e-06,
      "loss": 0.5595,
      "step": 2270
    },
    {
      "epoch": 3.5625,
      "grad_norm": 5.132854461669922,
      "learning_rate": 6.439062500000001e-06,
      "loss": 0.6551,
      "step": 2280
    },
    {
      "epoch": 3.578125,
      "grad_norm": 3.365143060684204,
      "learning_rate": 6.4234375e-06,
      "loss": 0.5483,
      "step": 2290
    },
    {
      "epoch": 3.59375,
      "grad_norm": 7.210935592651367,
      "learning_rate": 6.4078125e-06,
      "loss": 0.6037,
      "step": 2300
    },
    {
      "epoch": 3.609375,
      "grad_norm": 2.3795697689056396,
      "learning_rate": 6.3921875e-06,
      "loss": 0.7678,
      "step": 2310
    },
    {
      "epoch": 3.625,
      "grad_norm": 2.5542092323303223,
      "learning_rate": 6.376562500000001e-06,
      "loss": 0.726,
      "step": 2320
    },
    {
      "epoch": 3.640625,
      "grad_norm": 3.195406198501587,
      "learning_rate": 6.3609375000000005e-06,
      "loss": 0.7136,
      "step": 2330
    },
    {
      "epoch": 3.65625,
      "grad_norm": 2.41059947013855,
      "learning_rate": 6.3453125e-06,
      "loss": 0.5993,
      "step": 2340
    },
    {
      "epoch": 3.671875,
      "grad_norm": 2.9095489978790283,
      "learning_rate": 6.3296875000000005e-06,
      "loss": 0.7541,
      "step": 2350
    },
    {
      "epoch": 3.6875,
      "grad_norm": 3.5120627880096436,
      "learning_rate": 6.3140625e-06,
      "loss": 0.6178,
      "step": 2360
    },
    {
      "epoch": 3.703125,
      "grad_norm": 3.2884528636932373,
      "learning_rate": 6.298437500000001e-06,
      "loss": 0.6507,
      "step": 2370
    },
    {
      "epoch": 3.71875,
      "grad_norm": 2.293924570083618,
      "learning_rate": 6.2828125e-06,
      "loss": 0.5122,
      "step": 2380
    },
    {
      "epoch": 3.734375,
      "grad_norm": 1.8569920063018799,
      "learning_rate": 6.267187500000001e-06,
      "loss": 0.6256,
      "step": 2390
    },
    {
      "epoch": 3.75,
      "grad_norm": 4.836036205291748,
      "learning_rate": 6.2515625e-06,
      "loss": 0.4879,
      "step": 2400
    },
    {
      "epoch": 3.765625,
      "grad_norm": 2.756363868713379,
      "learning_rate": 6.2359375e-06,
      "loss": 0.7198,
      "step": 2410
    },
    {
      "epoch": 3.78125,
      "grad_norm": 2.7735683917999268,
      "learning_rate": 6.220312500000001e-06,
      "loss": 0.627,
      "step": 2420
    },
    {
      "epoch": 3.796875,
      "grad_norm": 2.769929885864258,
      "learning_rate": 6.204687500000001e-06,
      "loss": 0.6443,
      "step": 2430
    },
    {
      "epoch": 3.8125,
      "grad_norm": 2.460536003112793,
      "learning_rate": 6.1890625000000005e-06,
      "loss": 0.5852,
      "step": 2440
    },
    {
      "epoch": 3.828125,
      "grad_norm": 3.2015769481658936,
      "learning_rate": 6.1734375e-06,
      "loss": 0.7156,
      "step": 2450
    },
    {
      "epoch": 3.84375,
      "grad_norm": 2.3476650714874268,
      "learning_rate": 6.1578125e-06,
      "loss": 0.5961,
      "step": 2460
    },
    {
      "epoch": 3.859375,
      "grad_norm": 3.2033207416534424,
      "learning_rate": 6.142187500000001e-06,
      "loss": 0.6394,
      "step": 2470
    },
    {
      "epoch": 3.875,
      "grad_norm": 2.649275064468384,
      "learning_rate": 6.126562500000001e-06,
      "loss": 0.6346,
      "step": 2480
    },
    {
      "epoch": 3.890625,
      "grad_norm": 3.843060255050659,
      "learning_rate": 6.1109375e-06,
      "loss": 0.5532,
      "step": 2490
    },
    {
      "epoch": 3.90625,
      "grad_norm": 2.563892364501953,
      "learning_rate": 6.0953125e-06,
      "loss": 0.6108,
      "step": 2500
    },
    {
      "epoch": 3.921875,
      "grad_norm": 3.390444755554199,
      "learning_rate": 6.0796874999999995e-06,
      "loss": 0.6011,
      "step": 2510
    },
    {
      "epoch": 3.9375,
      "grad_norm": 2.309893846511841,
      "learning_rate": 6.064062500000001e-06,
      "loss": 0.6191,
      "step": 2520
    },
    {
      "epoch": 3.953125,
      "grad_norm": 2.179335355758667,
      "learning_rate": 6.0484375000000005e-06,
      "loss": 0.5414,
      "step": 2530
    },
    {
      "epoch": 3.96875,
      "grad_norm": 2.8462131023406982,
      "learning_rate": 6.0328125e-06,
      "loss": 0.6616,
      "step": 2540
    },
    {
      "epoch": 3.984375,
      "grad_norm": 2.156238079071045,
      "learning_rate": 6.0171875000000006e-06,
      "loss": 0.6829,
      "step": 2550
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.8751674890518188,
      "learning_rate": 6.0015625e-06,
      "loss": 0.6179,
      "step": 2560
    },
    {
      "epoch": 4.0,
      "eval_gen_len": 1.215929203539823,
      "eval_loss": 0.8351075649261475,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 100.2562,
      "eval_samples_per_second": 5.636,
      "eval_steps_per_second": 0.359,
      "step": 2560
    },
    {
      "epoch": 4.015625,
      "grad_norm": 4.284813404083252,
      "learning_rate": 5.985937500000001e-06,
      "loss": 0.6301,
      "step": 2570
    },
    {
      "epoch": 4.03125,
      "grad_norm": 1.9973868131637573,
      "learning_rate": 5.9703125e-06,
      "loss": 0.5459,
      "step": 2580
    },
    {
      "epoch": 4.046875,
      "grad_norm": 2.2144463062286377,
      "learning_rate": 5.954687500000001e-06,
      "loss": 0.7339,
      "step": 2590
    },
    {
      "epoch": 4.0625,
      "grad_norm": 3.4426348209381104,
      "learning_rate": 5.9390625e-06,
      "loss": 0.6038,
      "step": 2600
    },
    {
      "epoch": 4.078125,
      "grad_norm": 3.1230123043060303,
      "learning_rate": 5.9234375e-06,
      "loss": 0.6358,
      "step": 2610
    },
    {
      "epoch": 4.09375,
      "grad_norm": 3.487405776977539,
      "learning_rate": 5.9078125000000005e-06,
      "loss": 0.5775,
      "step": 2620
    },
    {
      "epoch": 4.109375,
      "grad_norm": 2.719758987426758,
      "learning_rate": 5.892187500000001e-06,
      "loss": 0.5392,
      "step": 2630
    },
    {
      "epoch": 4.125,
      "grad_norm": 2.3820388317108154,
      "learning_rate": 5.8765625000000005e-06,
      "loss": 0.6633,
      "step": 2640
    },
    {
      "epoch": 4.140625,
      "grad_norm": 2.513791799545288,
      "learning_rate": 5.8609375e-06,
      "loss": 0.5245,
      "step": 2650
    },
    {
      "epoch": 4.15625,
      "grad_norm": 2.805018424987793,
      "learning_rate": 5.8453125e-06,
      "loss": 0.6551,
      "step": 2660
    },
    {
      "epoch": 4.171875,
      "grad_norm": 3.432919979095459,
      "learning_rate": 5.829687500000001e-06,
      "loss": 0.6723,
      "step": 2670
    },
    {
      "epoch": 4.1875,
      "grad_norm": 3.745474100112915,
      "learning_rate": 5.814062500000001e-06,
      "loss": 0.7277,
      "step": 2680
    },
    {
      "epoch": 4.203125,
      "grad_norm": 2.9330999851226807,
      "learning_rate": 5.7984375e-06,
      "loss": 0.545,
      "step": 2690
    },
    {
      "epoch": 4.21875,
      "grad_norm": 4.60884952545166,
      "learning_rate": 5.7828125e-06,
      "loss": 0.6178,
      "step": 2700
    },
    {
      "epoch": 4.234375,
      "grad_norm": 3.1067147254943848,
      "learning_rate": 5.7671874999999996e-06,
      "loss": 0.7408,
      "step": 2710
    },
    {
      "epoch": 4.25,
      "grad_norm": 2.1812140941619873,
      "learning_rate": 5.751562500000001e-06,
      "loss": 0.6307,
      "step": 2720
    },
    {
      "epoch": 4.265625,
      "grad_norm": 4.574139595031738,
      "learning_rate": 5.7359375000000005e-06,
      "loss": 0.6153,
      "step": 2730
    },
    {
      "epoch": 4.28125,
      "grad_norm": 2.6131815910339355,
      "learning_rate": 5.7203125e-06,
      "loss": 0.7334,
      "step": 2740
    },
    {
      "epoch": 4.296875,
      "grad_norm": 2.5206549167633057,
      "learning_rate": 5.7046875e-06,
      "loss": 0.6719,
      "step": 2750
    },
    {
      "epoch": 4.3125,
      "grad_norm": 2.7913835048675537,
      "learning_rate": 5.6890625e-06,
      "loss": 0.6624,
      "step": 2760
    },
    {
      "epoch": 4.328125,
      "grad_norm": 2.1156466007232666,
      "learning_rate": 5.673437500000001e-06,
      "loss": 0.5503,
      "step": 2770
    },
    {
      "epoch": 4.34375,
      "grad_norm": 2.8281662464141846,
      "learning_rate": 5.6578125e-06,
      "loss": 0.5405,
      "step": 2780
    },
    {
      "epoch": 4.359375,
      "grad_norm": 2.055347204208374,
      "learning_rate": 5.642187500000001e-06,
      "loss": 0.6061,
      "step": 2790
    },
    {
      "epoch": 4.375,
      "grad_norm": 2.735952854156494,
      "learning_rate": 5.6265625e-06,
      "loss": 0.705,
      "step": 2800
    },
    {
      "epoch": 4.390625,
      "grad_norm": 2.436300277709961,
      "learning_rate": 5.6109375e-06,
      "loss": 0.4495,
      "step": 2810
    },
    {
      "epoch": 4.40625,
      "grad_norm": 1.5712605714797974,
      "learning_rate": 5.5953125000000005e-06,
      "loss": 0.5324,
      "step": 2820
    },
    {
      "epoch": 4.421875,
      "grad_norm": 3.3034486770629883,
      "learning_rate": 5.579687500000001e-06,
      "loss": 0.588,
      "step": 2830
    },
    {
      "epoch": 4.4375,
      "grad_norm": 2.873762845993042,
      "learning_rate": 5.5640625000000006e-06,
      "loss": 0.6104,
      "step": 2840
    },
    {
      "epoch": 4.453125,
      "grad_norm": 2.899381160736084,
      "learning_rate": 5.5484375e-06,
      "loss": 0.6265,
      "step": 2850
    },
    {
      "epoch": 4.46875,
      "grad_norm": 1.9996331930160522,
      "learning_rate": 5.5328125e-06,
      "loss": 0.6393,
      "step": 2860
    },
    {
      "epoch": 4.484375,
      "grad_norm": 2.3344860076904297,
      "learning_rate": 5.517187500000001e-06,
      "loss": 0.5239,
      "step": 2870
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.9608383178710938,
      "learning_rate": 5.501562500000001e-06,
      "loss": 0.5983,
      "step": 2880
    },
    {
      "epoch": 4.515625,
      "grad_norm": 3.1424107551574707,
      "learning_rate": 5.4859375e-06,
      "loss": 0.6953,
      "step": 2890
    },
    {
      "epoch": 4.53125,
      "grad_norm": 2.232172966003418,
      "learning_rate": 5.4703125e-06,
      "loss": 0.6164,
      "step": 2900
    },
    {
      "epoch": 4.546875,
      "grad_norm": 4.2806243896484375,
      "learning_rate": 5.4546875e-06,
      "loss": 0.7051,
      "step": 2910
    },
    {
      "epoch": 4.5625,
      "grad_norm": 4.507791996002197,
      "learning_rate": 5.439062500000001e-06,
      "loss": 0.653,
      "step": 2920
    },
    {
      "epoch": 4.578125,
      "grad_norm": 3.5473968982696533,
      "learning_rate": 5.4234375000000005e-06,
      "loss": 0.6227,
      "step": 2930
    },
    {
      "epoch": 4.59375,
      "grad_norm": 3.2899413108825684,
      "learning_rate": 5.4078125e-06,
      "loss": 0.5525,
      "step": 2940
    },
    {
      "epoch": 4.609375,
      "grad_norm": 2.325514554977417,
      "learning_rate": 5.3921875e-06,
      "loss": 0.616,
      "step": 2950
    },
    {
      "epoch": 4.625,
      "grad_norm": 2.290097951889038,
      "learning_rate": 5.3765625e-06,
      "loss": 0.5226,
      "step": 2960
    },
    {
      "epoch": 4.640625,
      "grad_norm": 2.5247654914855957,
      "learning_rate": 5.360937500000001e-06,
      "loss": 0.4904,
      "step": 2970
    },
    {
      "epoch": 4.65625,
      "grad_norm": 3.119652032852173,
      "learning_rate": 5.3453125e-06,
      "loss": 0.58,
      "step": 2980
    },
    {
      "epoch": 4.671875,
      "grad_norm": 2.303663969039917,
      "learning_rate": 5.3296875e-06,
      "loss": 0.5696,
      "step": 2990
    },
    {
      "epoch": 4.6875,
      "grad_norm": 3.088575601577759,
      "learning_rate": 5.3140625e-06,
      "loss": 0.5776,
      "step": 3000
    },
    {
      "epoch": 4.703125,
      "grad_norm": 2.51265025138855,
      "learning_rate": 5.2984375e-06,
      "loss": 0.4551,
      "step": 3010
    },
    {
      "epoch": 4.71875,
      "grad_norm": 2.4537484645843506,
      "learning_rate": 5.2828125000000005e-06,
      "loss": 0.6263,
      "step": 3020
    },
    {
      "epoch": 4.734375,
      "grad_norm": 1.9501276016235352,
      "learning_rate": 5.267187500000001e-06,
      "loss": 0.7137,
      "step": 3030
    },
    {
      "epoch": 4.75,
      "grad_norm": 2.729675769805908,
      "learning_rate": 5.251562500000001e-06,
      "loss": 0.4911,
      "step": 3040
    },
    {
      "epoch": 4.765625,
      "grad_norm": 3.21073842048645,
      "learning_rate": 5.2359375e-06,
      "loss": 0.5926,
      "step": 3050
    },
    {
      "epoch": 4.78125,
      "grad_norm": 3.8206887245178223,
      "learning_rate": 5.2203125e-06,
      "loss": 0.6478,
      "step": 3060
    },
    {
      "epoch": 4.796875,
      "grad_norm": 3.456700086593628,
      "learning_rate": 5.204687500000001e-06,
      "loss": 0.623,
      "step": 3070
    },
    {
      "epoch": 4.8125,
      "grad_norm": 2.5076000690460205,
      "learning_rate": 5.189062500000001e-06,
      "loss": 0.5502,
      "step": 3080
    },
    {
      "epoch": 4.828125,
      "grad_norm": 3.1307713985443115,
      "learning_rate": 5.1734375e-06,
      "loss": 0.6128,
      "step": 3090
    },
    {
      "epoch": 4.84375,
      "grad_norm": 2.6229476928710938,
      "learning_rate": 5.1578125e-06,
      "loss": 0.6403,
      "step": 3100
    },
    {
      "epoch": 4.859375,
      "grad_norm": 2.8259339332580566,
      "learning_rate": 5.1421875e-06,
      "loss": 0.6216,
      "step": 3110
    },
    {
      "epoch": 4.875,
      "grad_norm": 2.203131914138794,
      "learning_rate": 5.126562500000001e-06,
      "loss": 0.5971,
      "step": 3120
    },
    {
      "epoch": 4.890625,
      "grad_norm": 2.2109851837158203,
      "learning_rate": 5.1109375000000006e-06,
      "loss": 0.6282,
      "step": 3130
    },
    {
      "epoch": 4.90625,
      "grad_norm": 4.816274166107178,
      "learning_rate": 5.0953125e-06,
      "loss": 0.6754,
      "step": 3140
    },
    {
      "epoch": 4.921875,
      "grad_norm": 2.0337371826171875,
      "learning_rate": 5.0796875e-06,
      "loss": 0.6234,
      "step": 3150
    },
    {
      "epoch": 4.9375,
      "grad_norm": 1.962634801864624,
      "learning_rate": 5.0640625e-06,
      "loss": 0.4983,
      "step": 3160
    },
    {
      "epoch": 4.953125,
      "grad_norm": 2.595968246459961,
      "learning_rate": 5.048437500000001e-06,
      "loss": 0.578,
      "step": 3170
    },
    {
      "epoch": 4.96875,
      "grad_norm": 1.6037647724151611,
      "learning_rate": 5.0328125e-06,
      "loss": 0.5889,
      "step": 3180
    },
    {
      "epoch": 4.984375,
      "grad_norm": 2.044787645339966,
      "learning_rate": 5.0171875e-06,
      "loss": 0.5905,
      "step": 3190
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.9501380920410156,
      "learning_rate": 5.0015625000000004e-06,
      "loss": 0.6432,
      "step": 3200
    },
    {
      "epoch": 5.0,
      "eval_gen_len": 1.415929203539823,
      "eval_loss": 0.8165095448493958,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 101.8272,
      "eval_samples_per_second": 5.549,
      "eval_steps_per_second": 0.354,
      "step": 3200
    },
    {
      "epoch": 5.015625,
      "grad_norm": 2.3149197101593018,
      "learning_rate": 4.9859375e-06,
      "loss": 0.581,
      "step": 3210
    },
    {
      "epoch": 5.03125,
      "grad_norm": 2.406219720840454,
      "learning_rate": 4.9703125000000005e-06,
      "loss": 0.6078,
      "step": 3220
    },
    {
      "epoch": 5.046875,
      "grad_norm": 2.8120782375335693,
      "learning_rate": 4.9546875e-06,
      "loss": 0.5968,
      "step": 3230
    },
    {
      "epoch": 5.0625,
      "grad_norm": 2.220857620239258,
      "learning_rate": 4.939062500000001e-06,
      "loss": 0.6521,
      "step": 3240
    },
    {
      "epoch": 5.078125,
      "grad_norm": 1.7254530191421509,
      "learning_rate": 4.9234375e-06,
      "loss": 0.5697,
      "step": 3250
    },
    {
      "epoch": 5.09375,
      "grad_norm": 3.0879459381103516,
      "learning_rate": 4.907812500000001e-06,
      "loss": 0.552,
      "step": 3260
    },
    {
      "epoch": 5.109375,
      "grad_norm": 7.349985599517822,
      "learning_rate": 4.8921875e-06,
      "loss": 0.6728,
      "step": 3270
    },
    {
      "epoch": 5.125,
      "grad_norm": 2.984347343444824,
      "learning_rate": 4.876562500000001e-06,
      "loss": 0.6097,
      "step": 3280
    },
    {
      "epoch": 5.140625,
      "grad_norm": 2.3268537521362305,
      "learning_rate": 4.8609375e-06,
      "loss": 0.6119,
      "step": 3290
    },
    {
      "epoch": 5.15625,
      "grad_norm": 2.132493257522583,
      "learning_rate": 4.845312500000001e-06,
      "loss": 0.5101,
      "step": 3300
    },
    {
      "epoch": 5.171875,
      "grad_norm": 2.211536407470703,
      "learning_rate": 4.8296875000000005e-06,
      "loss": 0.7286,
      "step": 3310
    },
    {
      "epoch": 5.1875,
      "grad_norm": 2.382032871246338,
      "learning_rate": 4.8140625e-06,
      "loss": 0.5863,
      "step": 3320
    },
    {
      "epoch": 5.203125,
      "grad_norm": 2.2043166160583496,
      "learning_rate": 4.798437500000001e-06,
      "loss": 0.6008,
      "step": 3330
    },
    {
      "epoch": 5.21875,
      "grad_norm": 5.080004692077637,
      "learning_rate": 4.7828125e-06,
      "loss": 0.5716,
      "step": 3340
    },
    {
      "epoch": 5.234375,
      "grad_norm": 2.223437786102295,
      "learning_rate": 4.767187500000001e-06,
      "loss": 0.5253,
      "step": 3350
    },
    {
      "epoch": 5.25,
      "grad_norm": 2.1012487411499023,
      "learning_rate": 4.7515625e-06,
      "loss": 0.5888,
      "step": 3360
    },
    {
      "epoch": 5.265625,
      "grad_norm": 2.2855849266052246,
      "learning_rate": 4.7359375e-06,
      "loss": 0.4497,
      "step": 3370
    },
    {
      "epoch": 5.28125,
      "grad_norm": 2.0382087230682373,
      "learning_rate": 4.7203125e-06,
      "loss": 0.6368,
      "step": 3380
    },
    {
      "epoch": 5.296875,
      "grad_norm": 2.1414756774902344,
      "learning_rate": 4.7046875e-06,
      "loss": 0.6306,
      "step": 3390
    },
    {
      "epoch": 5.3125,
      "grad_norm": 3.061967611312866,
      "learning_rate": 4.6890625000000005e-06,
      "loss": 0.7063,
      "step": 3400
    },
    {
      "epoch": 5.328125,
      "grad_norm": 2.666142702102661,
      "learning_rate": 4.6734375e-06,
      "loss": 0.7085,
      "step": 3410
    },
    {
      "epoch": 5.34375,
      "grad_norm": 2.0842597484588623,
      "learning_rate": 4.6578125000000006e-06,
      "loss": 0.4893,
      "step": 3420
    },
    {
      "epoch": 5.359375,
      "grad_norm": 3.350649118423462,
      "learning_rate": 4.6421875e-06,
      "loss": 0.7461,
      "step": 3430
    },
    {
      "epoch": 5.375,
      "grad_norm": 2.8542842864990234,
      "learning_rate": 4.626562500000001e-06,
      "loss": 0.6296,
      "step": 3440
    },
    {
      "epoch": 5.390625,
      "grad_norm": 3.1124794483184814,
      "learning_rate": 4.6109375e-06,
      "loss": 0.5626,
      "step": 3450
    },
    {
      "epoch": 5.40625,
      "grad_norm": 2.761781692504883,
      "learning_rate": 4.595312500000001e-06,
      "loss": 0.6089,
      "step": 3460
    },
    {
      "epoch": 5.421875,
      "grad_norm": 4.649127960205078,
      "learning_rate": 4.5796875e-06,
      "loss": 0.6442,
      "step": 3470
    },
    {
      "epoch": 5.4375,
      "grad_norm": 2.3083200454711914,
      "learning_rate": 4.564062500000001e-06,
      "loss": 0.5909,
      "step": 3480
    },
    {
      "epoch": 5.453125,
      "grad_norm": 3.202434539794922,
      "learning_rate": 4.5484375000000004e-06,
      "loss": 0.5668,
      "step": 3490
    },
    {
      "epoch": 5.46875,
      "grad_norm": 4.398802280426025,
      "learning_rate": 4.532812500000001e-06,
      "loss": 0.6962,
      "step": 3500
    },
    {
      "epoch": 5.484375,
      "grad_norm": 2.9625282287597656,
      "learning_rate": 4.5171875000000005e-06,
      "loss": 0.6792,
      "step": 3510
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.307950973510742,
      "learning_rate": 4.5015625e-06,
      "loss": 0.6232,
      "step": 3520
    },
    {
      "epoch": 5.515625,
      "grad_norm": 2.046342611312866,
      "learning_rate": 4.485937500000001e-06,
      "loss": 0.5209,
      "step": 3530
    },
    {
      "epoch": 5.53125,
      "grad_norm": 2.979947566986084,
      "learning_rate": 4.4703125e-06,
      "loss": 0.7101,
      "step": 3540
    },
    {
      "epoch": 5.546875,
      "grad_norm": 3.0446717739105225,
      "learning_rate": 4.454687500000001e-06,
      "loss": 0.5017,
      "step": 3550
    },
    {
      "epoch": 5.5625,
      "grad_norm": 2.710904836654663,
      "learning_rate": 4.4390625e-06,
      "loss": 0.5796,
      "step": 3560
    },
    {
      "epoch": 5.578125,
      "grad_norm": 1.866012692451477,
      "learning_rate": 4.4234375e-06,
      "loss": 0.5968,
      "step": 3570
    },
    {
      "epoch": 5.59375,
      "grad_norm": 2.701810359954834,
      "learning_rate": 4.4078125e-06,
      "loss": 0.614,
      "step": 3580
    },
    {
      "epoch": 5.609375,
      "grad_norm": 2.4600608348846436,
      "learning_rate": 4.3921875e-06,
      "loss": 0.5639,
      "step": 3590
    },
    {
      "epoch": 5.625,
      "grad_norm": 3.419152021408081,
      "learning_rate": 4.3765625000000005e-06,
      "loss": 0.5292,
      "step": 3600
    },
    {
      "epoch": 5.640625,
      "grad_norm": 2.336015224456787,
      "learning_rate": 4.3609375e-06,
      "loss": 0.55,
      "step": 3610
    },
    {
      "epoch": 5.65625,
      "grad_norm": 2.38405179977417,
      "learning_rate": 4.3453125e-06,
      "loss": 0.5808,
      "step": 3620
    },
    {
      "epoch": 5.671875,
      "grad_norm": 4.019728183746338,
      "learning_rate": 4.3296875e-06,
      "loss": 0.5468,
      "step": 3630
    },
    {
      "epoch": 5.6875,
      "grad_norm": 2.1596851348876953,
      "learning_rate": 4.314062500000001e-06,
      "loss": 0.5742,
      "step": 3640
    },
    {
      "epoch": 5.703125,
      "grad_norm": 3.1606504917144775,
      "learning_rate": 4.2984375e-06,
      "loss": 0.5018,
      "step": 3650
    },
    {
      "epoch": 5.71875,
      "grad_norm": 5.370838642120361,
      "learning_rate": 4.282812500000001e-06,
      "loss": 0.4943,
      "step": 3660
    },
    {
      "epoch": 5.734375,
      "grad_norm": 3.0614728927612305,
      "learning_rate": 4.2671875e-06,
      "loss": 0.5701,
      "step": 3670
    },
    {
      "epoch": 5.75,
      "grad_norm": 2.4324700832366943,
      "learning_rate": 4.251562500000001e-06,
      "loss": 0.6884,
      "step": 3680
    },
    {
      "epoch": 5.765625,
      "grad_norm": 2.3357088565826416,
      "learning_rate": 4.2359375000000005e-06,
      "loss": 0.608,
      "step": 3690
    },
    {
      "epoch": 5.78125,
      "grad_norm": 2.357501983642578,
      "learning_rate": 4.220312500000001e-06,
      "loss": 0.5359,
      "step": 3700
    },
    {
      "epoch": 5.796875,
      "grad_norm": 3.3224589824676514,
      "learning_rate": 4.2046875000000006e-06,
      "loss": 0.5066,
      "step": 3710
    },
    {
      "epoch": 5.8125,
      "grad_norm": 2.20235276222229,
      "learning_rate": 4.1890625e-06,
      "loss": 0.6425,
      "step": 3720
    },
    {
      "epoch": 5.828125,
      "grad_norm": 1.4530322551727295,
      "learning_rate": 4.173437500000001e-06,
      "loss": 0.6076,
      "step": 3730
    },
    {
      "epoch": 5.84375,
      "grad_norm": 1.8572760820388794,
      "learning_rate": 4.1578125e-06,
      "loss": 0.6347,
      "step": 3740
    },
    {
      "epoch": 5.859375,
      "grad_norm": 2.542391300201416,
      "learning_rate": 4.142187500000001e-06,
      "loss": 0.6998,
      "step": 3750
    },
    {
      "epoch": 5.875,
      "grad_norm": 1.5909653902053833,
      "learning_rate": 4.1265625e-06,
      "loss": 0.5675,
      "step": 3760
    },
    {
      "epoch": 5.890625,
      "grad_norm": 2.8728740215301514,
      "learning_rate": 4.1109375e-06,
      "loss": 0.546,
      "step": 3770
    },
    {
      "epoch": 5.90625,
      "grad_norm": 3.680447816848755,
      "learning_rate": 4.0953125000000004e-06,
      "loss": 0.5704,
      "step": 3780
    },
    {
      "epoch": 5.921875,
      "grad_norm": 2.1189091205596924,
      "learning_rate": 4.0796875e-06,
      "loss": 0.5693,
      "step": 3790
    },
    {
      "epoch": 5.9375,
      "grad_norm": 2.9671790599823,
      "learning_rate": 4.0640625000000005e-06,
      "loss": 0.5897,
      "step": 3800
    },
    {
      "epoch": 5.953125,
      "grad_norm": 2.6283557415008545,
      "learning_rate": 4.0484375e-06,
      "loss": 0.5894,
      "step": 3810
    },
    {
      "epoch": 5.96875,
      "grad_norm": 1.7355749607086182,
      "learning_rate": 4.0328125e-06,
      "loss": 0.6244,
      "step": 3820
    },
    {
      "epoch": 5.984375,
      "grad_norm": 3.1561717987060547,
      "learning_rate": 4.0171875e-06,
      "loss": 0.6316,
      "step": 3830
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.7255728244781494,
      "learning_rate": 4.0015625e-06,
      "loss": 0.5642,
      "step": 3840
    },
    {
      "epoch": 6.0,
      "eval_gen_len": 1.4991150442477876,
      "eval_loss": 0.8018126487731934,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 102.9576,
      "eval_samples_per_second": 5.488,
      "eval_steps_per_second": 0.35,
      "step": 3840
    },
    {
      "epoch": 6.015625,
      "grad_norm": 2.3873205184936523,
      "learning_rate": 3.9859375e-06,
      "loss": 0.5522,
      "step": 3850
    },
    {
      "epoch": 6.03125,
      "grad_norm": 3.780683755874634,
      "learning_rate": 3.9703125e-06,
      "loss": 0.5556,
      "step": 3860
    },
    {
      "epoch": 6.046875,
      "grad_norm": 1.9805551767349243,
      "learning_rate": 3.9546875e-06,
      "loss": 0.5353,
      "step": 3870
    },
    {
      "epoch": 6.0625,
      "grad_norm": 2.708660364151001,
      "learning_rate": 3.939062500000001e-06,
      "loss": 0.6065,
      "step": 3880
    },
    {
      "epoch": 6.078125,
      "grad_norm": 3.289579391479492,
      "learning_rate": 3.9234375000000005e-06,
      "loss": 0.5838,
      "step": 3890
    },
    {
      "epoch": 6.09375,
      "grad_norm": 2.1933767795562744,
      "learning_rate": 3.907812500000001e-06,
      "loss": 0.5699,
      "step": 3900
    },
    {
      "epoch": 6.109375,
      "grad_norm": 2.7406723499298096,
      "learning_rate": 3.892187500000001e-06,
      "loss": 0.5553,
      "step": 3910
    },
    {
      "epoch": 6.125,
      "grad_norm": 2.325598955154419,
      "learning_rate": 3.8765625e-06,
      "loss": 0.5675,
      "step": 3920
    },
    {
      "epoch": 6.140625,
      "grad_norm": 2.1838390827178955,
      "learning_rate": 3.860937500000001e-06,
      "loss": 0.5455,
      "step": 3930
    },
    {
      "epoch": 6.15625,
      "grad_norm": 3.785754442214966,
      "learning_rate": 3.8453125e-06,
      "loss": 0.6373,
      "step": 3940
    },
    {
      "epoch": 6.171875,
      "grad_norm": 5.421413421630859,
      "learning_rate": 3.829687500000001e-06,
      "loss": 0.6316,
      "step": 3950
    },
    {
      "epoch": 6.1875,
      "grad_norm": 2.7802317142486572,
      "learning_rate": 3.8140625000000004e-06,
      "loss": 0.4838,
      "step": 3960
    },
    {
      "epoch": 6.203125,
      "grad_norm": 2.0929388999938965,
      "learning_rate": 3.7984375e-06,
      "loss": 0.6438,
      "step": 3970
    },
    {
      "epoch": 6.21875,
      "grad_norm": 2.444362163543701,
      "learning_rate": 3.7828125000000005e-06,
      "loss": 0.7029,
      "step": 3980
    },
    {
      "epoch": 6.234375,
      "grad_norm": 2.965733289718628,
      "learning_rate": 3.7671875e-06,
      "loss": 0.6733,
      "step": 3990
    },
    {
      "epoch": 6.25,
      "grad_norm": 2.5358495712280273,
      "learning_rate": 3.7515625000000006e-06,
      "loss": 0.4673,
      "step": 4000
    },
    {
      "epoch": 6.265625,
      "grad_norm": 3.6884002685546875,
      "learning_rate": 3.7359375e-06,
      "loss": 0.5952,
      "step": 4010
    },
    {
      "epoch": 6.28125,
      "grad_norm": 2.5821785926818848,
      "learning_rate": 3.7203125000000002e-06,
      "loss": 0.6745,
      "step": 4020
    },
    {
      "epoch": 6.296875,
      "grad_norm": 2.1106936931610107,
      "learning_rate": 3.7046875000000003e-06,
      "loss": 0.6366,
      "step": 4030
    },
    {
      "epoch": 6.3125,
      "grad_norm": 3.1698319911956787,
      "learning_rate": 3.6890625000000003e-06,
      "loss": 0.524,
      "step": 4040
    },
    {
      "epoch": 6.328125,
      "grad_norm": 3.039729356765747,
      "learning_rate": 3.6734375000000004e-06,
      "loss": 0.6561,
      "step": 4050
    },
    {
      "epoch": 6.34375,
      "grad_norm": 1.525319218635559,
      "learning_rate": 3.6578125000000004e-06,
      "loss": 0.5738,
      "step": 4060
    },
    {
      "epoch": 6.359375,
      "grad_norm": 2.8287100791931152,
      "learning_rate": 3.6421875e-06,
      "loss": 0.5833,
      "step": 4070
    },
    {
      "epoch": 6.375,
      "grad_norm": 3.032418966293335,
      "learning_rate": 3.6265625000000005e-06,
      "loss": 0.6543,
      "step": 4080
    },
    {
      "epoch": 6.390625,
      "grad_norm": 3.3677892684936523,
      "learning_rate": 3.6109375e-06,
      "loss": 0.6641,
      "step": 4090
    },
    {
      "epoch": 6.40625,
      "grad_norm": 3.068978786468506,
      "learning_rate": 3.5953125000000006e-06,
      "loss": 0.5413,
      "step": 4100
    },
    {
      "epoch": 6.421875,
      "grad_norm": 2.1687960624694824,
      "learning_rate": 3.5796875e-06,
      "loss": 0.5518,
      "step": 4110
    },
    {
      "epoch": 6.4375,
      "grad_norm": 2.4624288082122803,
      "learning_rate": 3.5640625000000002e-06,
      "loss": 0.6071,
      "step": 4120
    },
    {
      "epoch": 6.453125,
      "grad_norm": 3.58215069770813,
      "learning_rate": 3.5484375000000003e-06,
      "loss": 0.6111,
      "step": 4130
    },
    {
      "epoch": 6.46875,
      "grad_norm": 2.630014419555664,
      "learning_rate": 3.5328125000000003e-06,
      "loss": 0.4667,
      "step": 4140
    },
    {
      "epoch": 6.484375,
      "grad_norm": 2.5145537853240967,
      "learning_rate": 3.5171875000000004e-06,
      "loss": 0.5083,
      "step": 4150
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.388355255126953,
      "learning_rate": 3.5015625000000004e-06,
      "loss": 0.51,
      "step": 4160
    },
    {
      "epoch": 6.515625,
      "grad_norm": 3.230302333831787,
      "learning_rate": 3.4859375e-06,
      "loss": 0.6477,
      "step": 4170
    },
    {
      "epoch": 6.53125,
      "grad_norm": 2.085252285003662,
      "learning_rate": 3.4703125000000005e-06,
      "loss": 0.505,
      "step": 4180
    },
    {
      "epoch": 6.546875,
      "grad_norm": 2.1796014308929443,
      "learning_rate": 3.4546875e-06,
      "loss": 0.5735,
      "step": 4190
    },
    {
      "epoch": 6.5625,
      "grad_norm": 1.9052153825759888,
      "learning_rate": 3.4390625000000006e-06,
      "loss": 0.6461,
      "step": 4200
    },
    {
      "epoch": 6.578125,
      "grad_norm": 1.9532339572906494,
      "learning_rate": 3.4234375e-06,
      "loss": 0.4999,
      "step": 4210
    },
    {
      "epoch": 6.59375,
      "grad_norm": 3.959872245788574,
      "learning_rate": 3.4078125000000002e-06,
      "loss": 0.5226,
      "step": 4220
    },
    {
      "epoch": 6.609375,
      "grad_norm": 3.181898355484009,
      "learning_rate": 3.3921875000000003e-06,
      "loss": 0.5861,
      "step": 4230
    },
    {
      "epoch": 6.625,
      "grad_norm": 3.7585535049438477,
      "learning_rate": 3.3765625000000003e-06,
      "loss": 0.6273,
      "step": 4240
    },
    {
      "epoch": 6.640625,
      "grad_norm": 2.241392135620117,
      "learning_rate": 3.3609375000000004e-06,
      "loss": 0.5906,
      "step": 4250
    },
    {
      "epoch": 6.65625,
      "grad_norm": 2.6725072860717773,
      "learning_rate": 3.3453125000000004e-06,
      "loss": 0.5898,
      "step": 4260
    },
    {
      "epoch": 6.671875,
      "grad_norm": 12.434407234191895,
      "learning_rate": 3.3296875e-06,
      "loss": 0.53,
      "step": 4270
    },
    {
      "epoch": 6.6875,
      "grad_norm": 2.2061164379119873,
      "learning_rate": 3.3140625000000005e-06,
      "loss": 0.5809,
      "step": 4280
    },
    {
      "epoch": 6.703125,
      "grad_norm": 3.0776867866516113,
      "learning_rate": 3.2984375e-06,
      "loss": 0.5581,
      "step": 4290
    },
    {
      "epoch": 6.71875,
      "grad_norm": 3.2868545055389404,
      "learning_rate": 3.2828125000000006e-06,
      "loss": 0.5261,
      "step": 4300
    },
    {
      "epoch": 6.734375,
      "grad_norm": 3.0811753273010254,
      "learning_rate": 3.2671875000000002e-06,
      "loss": 0.5669,
      "step": 4310
    },
    {
      "epoch": 6.75,
      "grad_norm": 2.9281084537506104,
      "learning_rate": 3.2515625000000003e-06,
      "loss": 0.5685,
      "step": 4320
    },
    {
      "epoch": 6.765625,
      "grad_norm": 2.6973142623901367,
      "learning_rate": 3.2359375000000003e-06,
      "loss": 0.6757,
      "step": 4330
    },
    {
      "epoch": 6.78125,
      "grad_norm": 2.181300401687622,
      "learning_rate": 3.2203125000000003e-06,
      "loss": 0.5768,
      "step": 4340
    },
    {
      "epoch": 6.796875,
      "grad_norm": 3.1215999126434326,
      "learning_rate": 3.2046875000000004e-06,
      "loss": 0.766,
      "step": 4350
    },
    {
      "epoch": 6.8125,
      "grad_norm": 2.281552791595459,
      "learning_rate": 3.1890625000000004e-06,
      "loss": 0.5695,
      "step": 4360
    },
    {
      "epoch": 6.828125,
      "grad_norm": 4.049951076507568,
      "learning_rate": 3.1734375e-06,
      "loss": 0.4929,
      "step": 4370
    },
    {
      "epoch": 6.84375,
      "grad_norm": 1.9717851877212524,
      "learning_rate": 3.1578125000000005e-06,
      "loss": 0.5347,
      "step": 4380
    },
    {
      "epoch": 6.859375,
      "grad_norm": 2.0404012203216553,
      "learning_rate": 3.1421875e-06,
      "loss": 0.653,
      "step": 4390
    },
    {
      "epoch": 6.875,
      "grad_norm": 3.602691888809204,
      "learning_rate": 3.1265625000000006e-06,
      "loss": 0.4788,
      "step": 4400
    },
    {
      "epoch": 6.890625,
      "grad_norm": 2.5264408588409424,
      "learning_rate": 3.1109375000000002e-06,
      "loss": 0.618,
      "step": 4410
    },
    {
      "epoch": 6.90625,
      "grad_norm": 3.152461528778076,
      "learning_rate": 3.0953125e-06,
      "loss": 0.6151,
      "step": 4420
    },
    {
      "epoch": 6.921875,
      "grad_norm": 2.222569227218628,
      "learning_rate": 3.0796875000000003e-06,
      "loss": 0.555,
      "step": 4430
    },
    {
      "epoch": 6.9375,
      "grad_norm": 3.1099905967712402,
      "learning_rate": 3.0640625000000004e-06,
      "loss": 0.6513,
      "step": 4440
    },
    {
      "epoch": 6.953125,
      "grad_norm": 1.7091214656829834,
      "learning_rate": 3.0484375000000004e-06,
      "loss": 0.4282,
      "step": 4450
    },
    {
      "epoch": 6.96875,
      "grad_norm": 2.396103620529175,
      "learning_rate": 3.0328125000000005e-06,
      "loss": 0.6598,
      "step": 4460
    },
    {
      "epoch": 6.984375,
      "grad_norm": 2.4385812282562256,
      "learning_rate": 3.0171875e-06,
      "loss": 0.5931,
      "step": 4470
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.8113434314727783,
      "learning_rate": 3.0015625000000005e-06,
      "loss": 0.5644,
      "step": 4480
    },
    {
      "epoch": 7.0,
      "eval_gen_len": 1.5309734513274336,
      "eval_loss": 0.8014264702796936,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 103.3168,
      "eval_samples_per_second": 5.469,
      "eval_steps_per_second": 0.348,
      "step": 4480
    },
    {
      "epoch": 7.015625,
      "grad_norm": 2.5087502002716064,
      "learning_rate": 2.9859375e-06,
      "loss": 0.5799,
      "step": 4490
    },
    {
      "epoch": 7.03125,
      "grad_norm": 1.5846024751663208,
      "learning_rate": 2.9703125000000006e-06,
      "loss": 0.658,
      "step": 4500
    },
    {
      "epoch": 7.046875,
      "grad_norm": 3.088937997817993,
      "learning_rate": 2.9546875000000002e-06,
      "loss": 0.4589,
      "step": 4510
    },
    {
      "epoch": 7.0625,
      "grad_norm": 2.3488833904266357,
      "learning_rate": 2.9390625e-06,
      "loss": 0.53,
      "step": 4520
    },
    {
      "epoch": 7.078125,
      "grad_norm": 2.2890965938568115,
      "learning_rate": 2.9234375000000003e-06,
      "loss": 0.5562,
      "step": 4530
    },
    {
      "epoch": 7.09375,
      "grad_norm": 2.0334949493408203,
      "learning_rate": 2.9078125e-06,
      "loss": 0.5268,
      "step": 4540
    },
    {
      "epoch": 7.109375,
      "grad_norm": 2.353694438934326,
      "learning_rate": 2.8921875000000004e-06,
      "loss": 0.4935,
      "step": 4550
    },
    {
      "epoch": 7.125,
      "grad_norm": 1.7132318019866943,
      "learning_rate": 2.8765625000000005e-06,
      "loss": 0.5249,
      "step": 4560
    },
    {
      "epoch": 7.140625,
      "grad_norm": 3.18103289604187,
      "learning_rate": 2.8609375e-06,
      "loss": 0.4819,
      "step": 4570
    },
    {
      "epoch": 7.15625,
      "grad_norm": 1.8589427471160889,
      "learning_rate": 2.8453125000000006e-06,
      "loss": 0.5593,
      "step": 4580
    },
    {
      "epoch": 7.171875,
      "grad_norm": 2.097872495651245,
      "learning_rate": 2.8296875e-06,
      "loss": 0.6543,
      "step": 4590
    },
    {
      "epoch": 7.1875,
      "grad_norm": 2.248558282852173,
      "learning_rate": 2.8140625000000006e-06,
      "loss": 0.544,
      "step": 4600
    },
    {
      "epoch": 7.203125,
      "grad_norm": 2.4700841903686523,
      "learning_rate": 2.7984375000000003e-06,
      "loss": 0.6057,
      "step": 4610
    },
    {
      "epoch": 7.21875,
      "grad_norm": 1.9143577814102173,
      "learning_rate": 2.7828125e-06,
      "loss": 0.6134,
      "step": 4620
    },
    {
      "epoch": 7.234375,
      "grad_norm": 2.837564706802368,
      "learning_rate": 2.7671875000000003e-06,
      "loss": 0.5985,
      "step": 4630
    },
    {
      "epoch": 7.25,
      "grad_norm": 1.6721950769424438,
      "learning_rate": 2.7515625e-06,
      "loss": 0.4754,
      "step": 4640
    },
    {
      "epoch": 7.265625,
      "grad_norm": 2.9603958129882812,
      "learning_rate": 2.7359375000000004e-06,
      "loss": 0.5514,
      "step": 4650
    },
    {
      "epoch": 7.28125,
      "grad_norm": 2.9564833641052246,
      "learning_rate": 2.7203125e-06,
      "loss": 0.5976,
      "step": 4660
    },
    {
      "epoch": 7.296875,
      "grad_norm": 3.739792585372925,
      "learning_rate": 2.7046875e-06,
      "loss": 0.6189,
      "step": 4670
    },
    {
      "epoch": 7.3125,
      "grad_norm": 3.862053394317627,
      "learning_rate": 2.6890625000000006e-06,
      "loss": 0.642,
      "step": 4680
    },
    {
      "epoch": 7.328125,
      "grad_norm": 4.586073875427246,
      "learning_rate": 2.6734375e-06,
      "loss": 0.6057,
      "step": 4690
    },
    {
      "epoch": 7.34375,
      "grad_norm": 1.9010127782821655,
      "learning_rate": 2.6578125000000007e-06,
      "loss": 0.5654,
      "step": 4700
    },
    {
      "epoch": 7.359375,
      "grad_norm": 3.625119924545288,
      "learning_rate": 2.6421875000000003e-06,
      "loss": 0.5627,
      "step": 4710
    },
    {
      "epoch": 7.375,
      "grad_norm": 3.37062668800354,
      "learning_rate": 2.6265625e-06,
      "loss": 0.5121,
      "step": 4720
    },
    {
      "epoch": 7.390625,
      "grad_norm": 2.486572027206421,
      "learning_rate": 2.6109375000000004e-06,
      "loss": 0.4714,
      "step": 4730
    },
    {
      "epoch": 7.40625,
      "grad_norm": 1.8883358240127563,
      "learning_rate": 2.5953125e-06,
      "loss": 0.4477,
      "step": 4740
    },
    {
      "epoch": 7.421875,
      "grad_norm": 2.4769110679626465,
      "learning_rate": 2.5796875000000004e-06,
      "loss": 0.6978,
      "step": 4750
    },
    {
      "epoch": 7.4375,
      "grad_norm": 5.94779634475708,
      "learning_rate": 2.5640625e-06,
      "loss": 0.625,
      "step": 4760
    },
    {
      "epoch": 7.453125,
      "grad_norm": 3.3220930099487305,
      "learning_rate": 2.5484375e-06,
      "loss": 0.5826,
      "step": 4770
    },
    {
      "epoch": 7.46875,
      "grad_norm": 2.6694633960723877,
      "learning_rate": 2.5328125e-06,
      "loss": 0.6431,
      "step": 4780
    },
    {
      "epoch": 7.484375,
      "grad_norm": 3.0962307453155518,
      "learning_rate": 2.5171875e-06,
      "loss": 0.5371,
      "step": 4790
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.7101426124572754,
      "learning_rate": 2.5015625000000002e-06,
      "loss": 0.6711,
      "step": 4800
    },
    {
      "epoch": 7.515625,
      "grad_norm": 3.7536115646362305,
      "learning_rate": 2.4859375000000003e-06,
      "loss": 0.5205,
      "step": 4810
    },
    {
      "epoch": 7.53125,
      "grad_norm": 5.937072277069092,
      "learning_rate": 2.4703125000000003e-06,
      "loss": 0.4807,
      "step": 4820
    },
    {
      "epoch": 7.546875,
      "grad_norm": 1.983966588973999,
      "learning_rate": 2.4546875000000004e-06,
      "loss": 0.503,
      "step": 4830
    },
    {
      "epoch": 7.5625,
      "grad_norm": 5.407309055328369,
      "learning_rate": 2.4390625e-06,
      "loss": 0.4726,
      "step": 4840
    },
    {
      "epoch": 7.578125,
      "grad_norm": 3.2104861736297607,
      "learning_rate": 2.4234375e-06,
      "loss": 0.5712,
      "step": 4850
    },
    {
      "epoch": 7.59375,
      "grad_norm": 1.9840397834777832,
      "learning_rate": 2.4078125e-06,
      "loss": 0.6222,
      "step": 4860
    },
    {
      "epoch": 7.609375,
      "grad_norm": 2.551924467086792,
      "learning_rate": 2.3921875e-06,
      "loss": 0.6178,
      "step": 4870
    },
    {
      "epoch": 7.625,
      "grad_norm": 2.7326455116271973,
      "learning_rate": 2.3765625e-06,
      "loss": 0.7653,
      "step": 4880
    },
    {
      "epoch": 7.640625,
      "grad_norm": 2.152224063873291,
      "learning_rate": 2.3609375000000002e-06,
      "loss": 0.6008,
      "step": 4890
    },
    {
      "epoch": 7.65625,
      "grad_norm": 2.265967607498169,
      "learning_rate": 2.3453125000000003e-06,
      "loss": 0.6179,
      "step": 4900
    },
    {
      "epoch": 7.671875,
      "grad_norm": 3.204728126525879,
      "learning_rate": 2.3296875000000003e-06,
      "loss": 0.5608,
      "step": 4910
    },
    {
      "epoch": 7.6875,
      "grad_norm": 2.467202663421631,
      "learning_rate": 2.3140625000000003e-06,
      "loss": 0.5463,
      "step": 4920
    },
    {
      "epoch": 7.703125,
      "grad_norm": 3.7235119342803955,
      "learning_rate": 2.2984375000000004e-06,
      "loss": 0.5719,
      "step": 4930
    },
    {
      "epoch": 7.71875,
      "grad_norm": 2.872673511505127,
      "learning_rate": 2.2828125e-06,
      "loss": 0.4751,
      "step": 4940
    },
    {
      "epoch": 7.734375,
      "grad_norm": 1.9708542823791504,
      "learning_rate": 2.2671875e-06,
      "loss": 0.5711,
      "step": 4950
    },
    {
      "epoch": 7.75,
      "grad_norm": 2.3213138580322266,
      "learning_rate": 2.2515625e-06,
      "loss": 0.5357,
      "step": 4960
    },
    {
      "epoch": 7.765625,
      "grad_norm": 1.6192995309829712,
      "learning_rate": 2.2359375e-06,
      "loss": 0.5359,
      "step": 4970
    },
    {
      "epoch": 7.78125,
      "grad_norm": 4.089494705200195,
      "learning_rate": 2.2203125e-06,
      "loss": 0.6431,
      "step": 4980
    },
    {
      "epoch": 7.796875,
      "grad_norm": 1.544552206993103,
      "learning_rate": 2.2046875000000002e-06,
      "loss": 0.5313,
      "step": 4990
    },
    {
      "epoch": 7.8125,
      "grad_norm": 2.7087173461914062,
      "learning_rate": 2.1890625000000003e-06,
      "loss": 0.5651,
      "step": 5000
    },
    {
      "epoch": 7.828125,
      "grad_norm": 3.3991963863372803,
      "learning_rate": 2.1734375000000003e-06,
      "loss": 0.6824,
      "step": 5010
    },
    {
      "epoch": 7.84375,
      "grad_norm": 1.750464677810669,
      "learning_rate": 2.1578125000000004e-06,
      "loss": 0.5683,
      "step": 5020
    },
    {
      "epoch": 7.859375,
      "grad_norm": 1.821704387664795,
      "learning_rate": 2.1421875000000004e-06,
      "loss": 0.624,
      "step": 5030
    },
    {
      "epoch": 7.875,
      "grad_norm": 2.1301963329315186,
      "learning_rate": 2.1265625e-06,
      "loss": 0.6121,
      "step": 5040
    },
    {
      "epoch": 7.890625,
      "grad_norm": 3.1121063232421875,
      "learning_rate": 2.1109375e-06,
      "loss": 0.5169,
      "step": 5050
    },
    {
      "epoch": 7.90625,
      "grad_norm": 2.3540616035461426,
      "learning_rate": 2.0953125e-06,
      "loss": 0.6842,
      "step": 5060
    },
    {
      "epoch": 7.921875,
      "grad_norm": 2.9262959957122803,
      "learning_rate": 2.0796875e-06,
      "loss": 0.6042,
      "step": 5070
    },
    {
      "epoch": 7.9375,
      "grad_norm": 2.4289047718048096,
      "learning_rate": 2.0640625e-06,
      "loss": 0.6097,
      "step": 5080
    },
    {
      "epoch": 7.953125,
      "grad_norm": 2.9985673427581787,
      "learning_rate": 2.0484375000000002e-06,
      "loss": 0.5573,
      "step": 5090
    },
    {
      "epoch": 7.96875,
      "grad_norm": 2.2816102504730225,
      "learning_rate": 2.0328125000000003e-06,
      "loss": 0.6122,
      "step": 5100
    },
    {
      "epoch": 7.984375,
      "grad_norm": 2.9307382106781006,
      "learning_rate": 2.0171875000000003e-06,
      "loss": 0.5757,
      "step": 5110
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.561234474182129,
      "learning_rate": 2.0015625000000004e-06,
      "loss": 0.5314,
      "step": 5120
    },
    {
      "epoch": 8.0,
      "eval_gen_len": 1.9787610619469027,
      "eval_loss": 0.7930135130882263,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 107.495,
      "eval_samples_per_second": 5.256,
      "eval_steps_per_second": 0.335,
      "step": 5120
    },
    {
      "epoch": 8.015625,
      "grad_norm": 1.9535578489303589,
      "learning_rate": 1.9859375000000004e-06,
      "loss": 0.3818,
      "step": 5130
    },
    {
      "epoch": 8.03125,
      "grad_norm": 2.003739833831787,
      "learning_rate": 1.9703125e-06,
      "loss": 0.5942,
      "step": 5140
    },
    {
      "epoch": 8.046875,
      "grad_norm": 2.3314568996429443,
      "learning_rate": 1.9546875e-06,
      "loss": 0.5823,
      "step": 5150
    },
    {
      "epoch": 8.0625,
      "grad_norm": 3.119131088256836,
      "learning_rate": 1.9390625e-06,
      "loss": 0.5705,
      "step": 5160
    },
    {
      "epoch": 8.078125,
      "grad_norm": 2.8036224842071533,
      "learning_rate": 1.9234375e-06,
      "loss": 0.634,
      "step": 5170
    },
    {
      "epoch": 8.09375,
      "grad_norm": 2.7025909423828125,
      "learning_rate": 1.9078125e-06,
      "loss": 0.473,
      "step": 5180
    },
    {
      "epoch": 8.109375,
      "grad_norm": 3.2023677825927734,
      "learning_rate": 1.8921875e-06,
      "loss": 0.5614,
      "step": 5190
    },
    {
      "epoch": 8.125,
      "grad_norm": 3.252897262573242,
      "learning_rate": 1.8765625e-06,
      "loss": 0.5625,
      "step": 5200
    },
    {
      "epoch": 8.140625,
      "grad_norm": 4.470966815948486,
      "learning_rate": 1.8609375000000001e-06,
      "loss": 0.566,
      "step": 5210
    },
    {
      "epoch": 8.15625,
      "grad_norm": 1.9260826110839844,
      "learning_rate": 1.8453125000000002e-06,
      "loss": 0.5011,
      "step": 5220
    },
    {
      "epoch": 8.171875,
      "grad_norm": 1.6902594566345215,
      "learning_rate": 1.8296875000000002e-06,
      "loss": 0.6056,
      "step": 5230
    },
    {
      "epoch": 8.1875,
      "grad_norm": 4.479923248291016,
      "learning_rate": 1.8140625e-06,
      "loss": 0.5628,
      "step": 5240
    },
    {
      "epoch": 8.203125,
      "grad_norm": 2.2032852172851562,
      "learning_rate": 1.7984375e-06,
      "loss": 0.5578,
      "step": 5250
    },
    {
      "epoch": 8.21875,
      "grad_norm": 2.5931713581085205,
      "learning_rate": 1.7828125000000001e-06,
      "loss": 0.6303,
      "step": 5260
    },
    {
      "epoch": 8.234375,
      "grad_norm": 3.1932501792907715,
      "learning_rate": 1.7671875000000002e-06,
      "loss": 0.5042,
      "step": 5270
    },
    {
      "epoch": 8.25,
      "grad_norm": 2.2649013996124268,
      "learning_rate": 1.7515625000000002e-06,
      "loss": 0.5153,
      "step": 5280
    },
    {
      "epoch": 8.265625,
      "grad_norm": 2.8757073879241943,
      "learning_rate": 1.7359375e-06,
      "loss": 0.5783,
      "step": 5290
    },
    {
      "epoch": 8.28125,
      "grad_norm": 2.898934841156006,
      "learning_rate": 1.7203125e-06,
      "loss": 0.5875,
      "step": 5300
    },
    {
      "epoch": 8.296875,
      "grad_norm": 3.1761579513549805,
      "learning_rate": 1.7046875000000001e-06,
      "loss": 0.6537,
      "step": 5310
    },
    {
      "epoch": 8.3125,
      "grad_norm": 2.959287643432617,
      "learning_rate": 1.6890625000000002e-06,
      "loss": 0.6035,
      "step": 5320
    },
    {
      "epoch": 8.328125,
      "grad_norm": 2.930631637573242,
      "learning_rate": 1.6734375000000002e-06,
      "loss": 0.651,
      "step": 5330
    },
    {
      "epoch": 8.34375,
      "grad_norm": 3.8094122409820557,
      "learning_rate": 1.6578125e-06,
      "loss": 0.5575,
      "step": 5340
    },
    {
      "epoch": 8.359375,
      "grad_norm": 3.3277335166931152,
      "learning_rate": 1.6421875000000001e-06,
      "loss": 0.4323,
      "step": 5350
    },
    {
      "epoch": 8.375,
      "grad_norm": 2.55831241607666,
      "learning_rate": 1.6265625000000001e-06,
      "loss": 0.5905,
      "step": 5360
    },
    {
      "epoch": 8.390625,
      "grad_norm": 3.680617332458496,
      "learning_rate": 1.6109375000000002e-06,
      "loss": 0.5472,
      "step": 5370
    },
    {
      "epoch": 8.40625,
      "grad_norm": 2.4181830883026123,
      "learning_rate": 1.5953125000000002e-06,
      "loss": 0.5533,
      "step": 5380
    },
    {
      "epoch": 8.421875,
      "grad_norm": 2.9997143745422363,
      "learning_rate": 1.5796875e-06,
      "loss": 0.5879,
      "step": 5390
    },
    {
      "epoch": 8.4375,
      "grad_norm": 1.6259255409240723,
      "learning_rate": 1.5640625000000001e-06,
      "loss": 0.5697,
      "step": 5400
    },
    {
      "epoch": 8.453125,
      "grad_norm": 2.210016965866089,
      "learning_rate": 1.5484375000000002e-06,
      "loss": 0.5641,
      "step": 5410
    },
    {
      "epoch": 8.46875,
      "grad_norm": 2.742792844772339,
      "learning_rate": 1.5328125000000002e-06,
      "loss": 0.6377,
      "step": 5420
    },
    {
      "epoch": 8.484375,
      "grad_norm": 1.8410686254501343,
      "learning_rate": 1.5171875000000002e-06,
      "loss": 0.5322,
      "step": 5430
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.784229278564453,
      "learning_rate": 1.5015625e-06,
      "loss": 0.5335,
      "step": 5440
    },
    {
      "epoch": 8.515625,
      "grad_norm": 2.3498713970184326,
      "learning_rate": 1.4859375000000001e-06,
      "loss": 0.5508,
      "step": 5450
    },
    {
      "epoch": 8.53125,
      "grad_norm": 1.9327890872955322,
      "learning_rate": 1.4703125000000002e-06,
      "loss": 0.648,
      "step": 5460
    },
    {
      "epoch": 8.546875,
      "grad_norm": 2.5099759101867676,
      "learning_rate": 1.4546875000000002e-06,
      "loss": 0.472,
      "step": 5470
    },
    {
      "epoch": 8.5625,
      "grad_norm": 2.54500412940979,
      "learning_rate": 1.4390625000000003e-06,
      "loss": 0.5781,
      "step": 5480
    },
    {
      "epoch": 8.578125,
      "grad_norm": 1.959538459777832,
      "learning_rate": 1.4234375e-06,
      "loss": 0.5897,
      "step": 5490
    },
    {
      "epoch": 8.59375,
      "grad_norm": 3.472217559814453,
      "learning_rate": 1.4078125000000001e-06,
      "loss": 0.6451,
      "step": 5500
    },
    {
      "epoch": 8.609375,
      "grad_norm": 2.0613021850585938,
      "learning_rate": 1.3921875000000002e-06,
      "loss": 0.6243,
      "step": 5510
    },
    {
      "epoch": 8.625,
      "grad_norm": 2.6792027950286865,
      "learning_rate": 1.3765625000000002e-06,
      "loss": 0.577,
      "step": 5520
    },
    {
      "epoch": 8.640625,
      "grad_norm": 2.2483012676239014,
      "learning_rate": 1.3609375000000003e-06,
      "loss": 0.5498,
      "step": 5530
    },
    {
      "epoch": 8.65625,
      "grad_norm": 2.928210496902466,
      "learning_rate": 1.3453125e-06,
      "loss": 0.5615,
      "step": 5540
    },
    {
      "epoch": 8.671875,
      "grad_norm": 3.07926607131958,
      "learning_rate": 1.3296875000000001e-06,
      "loss": 0.5548,
      "step": 5550
    },
    {
      "epoch": 8.6875,
      "grad_norm": 2.641416311264038,
      "learning_rate": 1.3140625000000002e-06,
      "loss": 0.631,
      "step": 5560
    },
    {
      "epoch": 8.703125,
      "grad_norm": 2.852245569229126,
      "learning_rate": 1.2984375000000002e-06,
      "loss": 0.57,
      "step": 5570
    },
    {
      "epoch": 8.71875,
      "grad_norm": 2.6685502529144287,
      "learning_rate": 1.2828125000000003e-06,
      "loss": 0.6243,
      "step": 5580
    },
    {
      "epoch": 8.734375,
      "grad_norm": 3.859367847442627,
      "learning_rate": 1.2671875e-06,
      "loss": 0.6147,
      "step": 5590
    },
    {
      "epoch": 8.75,
      "grad_norm": 2.9392142295837402,
      "learning_rate": 1.2515625000000001e-06,
      "loss": 0.6536,
      "step": 5600
    },
    {
      "epoch": 8.765625,
      "grad_norm": 1.6085124015808105,
      "learning_rate": 1.2359375000000002e-06,
      "loss": 0.4731,
      "step": 5610
    },
    {
      "epoch": 8.78125,
      "grad_norm": 3.8253676891326904,
      "learning_rate": 1.2203125e-06,
      "loss": 0.6356,
      "step": 5620
    },
    {
      "epoch": 8.796875,
      "grad_norm": 3.287217378616333,
      "learning_rate": 1.2046875e-06,
      "loss": 0.6395,
      "step": 5630
    },
    {
      "epoch": 8.8125,
      "grad_norm": 3.2518527507781982,
      "learning_rate": 1.1890625e-06,
      "loss": 0.5771,
      "step": 5640
    },
    {
      "epoch": 8.828125,
      "grad_norm": 2.1673576831817627,
      "learning_rate": 1.1734375000000001e-06,
      "loss": 0.5262,
      "step": 5650
    },
    {
      "epoch": 8.84375,
      "grad_norm": 2.8727307319641113,
      "learning_rate": 1.1578125000000002e-06,
      "loss": 0.6268,
      "step": 5660
    },
    {
      "epoch": 8.859375,
      "grad_norm": 2.2806191444396973,
      "learning_rate": 1.1421875e-06,
      "loss": 0.6132,
      "step": 5670
    },
    {
      "epoch": 8.875,
      "grad_norm": 2.6035361289978027,
      "learning_rate": 1.1265625e-06,
      "loss": 0.6372,
      "step": 5680
    },
    {
      "epoch": 8.890625,
      "grad_norm": 2.6771039962768555,
      "learning_rate": 1.1109375000000001e-06,
      "loss": 0.4789,
      "step": 5690
    },
    {
      "epoch": 8.90625,
      "grad_norm": 2.6365020275115967,
      "learning_rate": 1.0953125000000002e-06,
      "loss": 0.4349,
      "step": 5700
    },
    {
      "epoch": 8.921875,
      "grad_norm": 3.829338550567627,
      "learning_rate": 1.0796875000000002e-06,
      "loss": 0.5603,
      "step": 5710
    },
    {
      "epoch": 8.9375,
      "grad_norm": 3.143458127975464,
      "learning_rate": 1.0640625e-06,
      "loss": 0.4781,
      "step": 5720
    },
    {
      "epoch": 8.953125,
      "grad_norm": 3.742382764816284,
      "learning_rate": 1.0484375e-06,
      "loss": 0.6114,
      "step": 5730
    },
    {
      "epoch": 8.96875,
      "grad_norm": 2.462663412094116,
      "learning_rate": 1.0328125000000001e-06,
      "loss": 0.547,
      "step": 5740
    },
    {
      "epoch": 8.984375,
      "grad_norm": 1.76970636844635,
      "learning_rate": 1.0171875e-06,
      "loss": 0.5168,
      "step": 5750
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.791062116622925,
      "learning_rate": 1.0015625000000002e-06,
      "loss": 0.6407,
      "step": 5760
    },
    {
      "epoch": 9.0,
      "eval_gen_len": 2.1893805309734513,
      "eval_loss": 0.7886569499969482,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 107.9795,
      "eval_samples_per_second": 5.232,
      "eval_steps_per_second": 0.333,
      "step": 5760
    },
    {
      "epoch": 9.015625,
      "grad_norm": 2.3392140865325928,
      "learning_rate": 9.859375e-07,
      "loss": 0.6043,
      "step": 5770
    },
    {
      "epoch": 9.03125,
      "grad_norm": 2.5407941341400146,
      "learning_rate": 9.703125e-07,
      "loss": 0.6099,
      "step": 5780
    },
    {
      "epoch": 9.046875,
      "grad_norm": 2.483304023742676,
      "learning_rate": 9.546875000000001e-07,
      "loss": 0.5607,
      "step": 5790
    },
    {
      "epoch": 9.0625,
      "grad_norm": 2.0060243606567383,
      "learning_rate": 9.390625000000001e-07,
      "loss": 0.5197,
      "step": 5800
    },
    {
      "epoch": 9.078125,
      "grad_norm": 2.469550609588623,
      "learning_rate": 9.234375000000001e-07,
      "loss": 0.4974,
      "step": 5810
    },
    {
      "epoch": 9.09375,
      "grad_norm": 4.862508773803711,
      "learning_rate": 9.078125e-07,
      "loss": 0.5914,
      "step": 5820
    },
    {
      "epoch": 9.109375,
      "grad_norm": 2.436148166656494,
      "learning_rate": 8.921875000000001e-07,
      "loss": 0.5522,
      "step": 5830
    },
    {
      "epoch": 9.125,
      "grad_norm": 2.1680686473846436,
      "learning_rate": 8.765625000000001e-07,
      "loss": 0.486,
      "step": 5840
    },
    {
      "epoch": 9.140625,
      "grad_norm": 2.7894372940063477,
      "learning_rate": 8.609375000000001e-07,
      "loss": 0.608,
      "step": 5850
    },
    {
      "epoch": 9.15625,
      "grad_norm": 2.1766717433929443,
      "learning_rate": 8.453125000000001e-07,
      "loss": 0.5749,
      "step": 5860
    },
    {
      "epoch": 9.171875,
      "grad_norm": 2.97741961479187,
      "learning_rate": 8.296875e-07,
      "loss": 0.6166,
      "step": 5870
    },
    {
      "epoch": 9.1875,
      "grad_norm": 2.496675491333008,
      "learning_rate": 8.140625000000001e-07,
      "loss": 0.5551,
      "step": 5880
    },
    {
      "epoch": 9.203125,
      "grad_norm": 2.5631253719329834,
      "learning_rate": 7.984375000000001e-07,
      "loss": 0.5428,
      "step": 5890
    },
    {
      "epoch": 9.21875,
      "grad_norm": 2.8830738067626953,
      "learning_rate": 7.828125000000001e-07,
      "loss": 0.5762,
      "step": 5900
    },
    {
      "epoch": 9.234375,
      "grad_norm": 1.8986083269119263,
      "learning_rate": 7.671875000000001e-07,
      "loss": 0.6296,
      "step": 5910
    },
    {
      "epoch": 9.25,
      "grad_norm": 1.990946650505066,
      "learning_rate": 7.515625e-07,
      "loss": 0.5043,
      "step": 5920
    },
    {
      "epoch": 9.265625,
      "grad_norm": 2.9130303859710693,
      "learning_rate": 7.359375000000001e-07,
      "loss": 0.5713,
      "step": 5930
    },
    {
      "epoch": 9.28125,
      "grad_norm": 9.550603866577148,
      "learning_rate": 7.203125000000001e-07,
      "loss": 0.5917,
      "step": 5940
    },
    {
      "epoch": 9.296875,
      "grad_norm": 2.842991352081299,
      "learning_rate": 7.046875e-07,
      "loss": 0.5488,
      "step": 5950
    },
    {
      "epoch": 9.3125,
      "grad_norm": 2.5603630542755127,
      "learning_rate": 6.890625000000001e-07,
      "loss": 0.5861,
      "step": 5960
    },
    {
      "epoch": 9.328125,
      "grad_norm": 3.02754807472229,
      "learning_rate": 6.734375e-07,
      "loss": 0.5792,
      "step": 5970
    },
    {
      "epoch": 9.34375,
      "grad_norm": 3.369541883468628,
      "learning_rate": 6.578125e-07,
      "loss": 0.5392,
      "step": 5980
    },
    {
      "epoch": 9.359375,
      "grad_norm": 2.7275121212005615,
      "learning_rate": 6.421875000000002e-07,
      "loss": 0.6256,
      "step": 5990
    },
    {
      "epoch": 9.375,
      "grad_norm": 3.1966826915740967,
      "learning_rate": 6.265625e-07,
      "loss": 0.5193,
      "step": 6000
    },
    {
      "epoch": 9.390625,
      "grad_norm": 2.5606906414031982,
      "learning_rate": 6.109375e-07,
      "loss": 0.4986,
      "step": 6010
    },
    {
      "epoch": 9.40625,
      "grad_norm": 2.2858428955078125,
      "learning_rate": 5.953125000000001e-07,
      "loss": 0.6291,
      "step": 6020
    },
    {
      "epoch": 9.421875,
      "grad_norm": 2.330470323562622,
      "learning_rate": 5.796875e-07,
      "loss": 0.5279,
      "step": 6030
    },
    {
      "epoch": 9.4375,
      "grad_norm": 2.212543249130249,
      "learning_rate": 5.640625e-07,
      "loss": 0.5348,
      "step": 6040
    },
    {
      "epoch": 9.453125,
      "grad_norm": 2.6527674198150635,
      "learning_rate": 5.484375e-07,
      "loss": 0.5336,
      "step": 6050
    },
    {
      "epoch": 9.46875,
      "grad_norm": 4.826971530914307,
      "learning_rate": 5.328125e-07,
      "loss": 0.6194,
      "step": 6060
    },
    {
      "epoch": 9.484375,
      "grad_norm": 2.7511463165283203,
      "learning_rate": 5.171875000000001e-07,
      "loss": 0.5098,
      "step": 6070
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.7402355670928955,
      "learning_rate": 5.015625e-07,
      "loss": 0.5446,
      "step": 6080
    },
    {
      "epoch": 9.515625,
      "grad_norm": 2.39383864402771,
      "learning_rate": 4.859375000000001e-07,
      "loss": 0.5481,
      "step": 6090
    },
    {
      "epoch": 9.53125,
      "grad_norm": 2.0279557704925537,
      "learning_rate": 4.703125e-07,
      "loss": 0.4369,
      "step": 6100
    },
    {
      "epoch": 9.546875,
      "grad_norm": 2.4626352787017822,
      "learning_rate": 4.5468750000000004e-07,
      "loss": 0.5389,
      "step": 6110
    },
    {
      "epoch": 9.5625,
      "grad_norm": 3.0651233196258545,
      "learning_rate": 4.3906250000000003e-07,
      "loss": 0.6963,
      "step": 6120
    },
    {
      "epoch": 9.578125,
      "grad_norm": 2.992021083831787,
      "learning_rate": 4.234375e-07,
      "loss": 0.7195,
      "step": 6130
    },
    {
      "epoch": 9.59375,
      "grad_norm": 3.614997148513794,
      "learning_rate": 4.078125e-07,
      "loss": 0.6285,
      "step": 6140
    },
    {
      "epoch": 9.609375,
      "grad_norm": 2.310861110687256,
      "learning_rate": 3.921875e-07,
      "loss": 0.4807,
      "step": 6150
    },
    {
      "epoch": 9.625,
      "grad_norm": 4.495643615722656,
      "learning_rate": 3.7656250000000005e-07,
      "loss": 0.6061,
      "step": 6160
    },
    {
      "epoch": 9.640625,
      "grad_norm": 3.0685694217681885,
      "learning_rate": 3.6093750000000004e-07,
      "loss": 0.5749,
      "step": 6170
    },
    {
      "epoch": 9.65625,
      "grad_norm": 2.5765347480773926,
      "learning_rate": 3.4531250000000003e-07,
      "loss": 0.6407,
      "step": 6180
    },
    {
      "epoch": 9.671875,
      "grad_norm": 2.4373412132263184,
      "learning_rate": 3.296875e-07,
      "loss": 0.6216,
      "step": 6190
    },
    {
      "epoch": 9.6875,
      "grad_norm": 3.0782644748687744,
      "learning_rate": 3.140625e-07,
      "loss": 0.5479,
      "step": 6200
    },
    {
      "epoch": 9.703125,
      "grad_norm": 2.7898404598236084,
      "learning_rate": 2.984375e-07,
      "loss": 0.4829,
      "step": 6210
    },
    {
      "epoch": 9.71875,
      "grad_norm": 4.06141471862793,
      "learning_rate": 2.8281250000000005e-07,
      "loss": 0.5889,
      "step": 6220
    },
    {
      "epoch": 9.734375,
      "grad_norm": 2.807001829147339,
      "learning_rate": 2.6718750000000004e-07,
      "loss": 0.6254,
      "step": 6230
    },
    {
      "epoch": 9.75,
      "grad_norm": 2.1669204235076904,
      "learning_rate": 2.5156250000000003e-07,
      "loss": 0.5803,
      "step": 6240
    },
    {
      "epoch": 9.765625,
      "grad_norm": 2.488675594329834,
      "learning_rate": 2.3593750000000002e-07,
      "loss": 0.6511,
      "step": 6250
    },
    {
      "epoch": 9.78125,
      "grad_norm": 2.72700572013855,
      "learning_rate": 2.203125e-07,
      "loss": 0.5653,
      "step": 6260
    },
    {
      "epoch": 9.796875,
      "grad_norm": 6.389603614807129,
      "learning_rate": 2.0468750000000003e-07,
      "loss": 0.4767,
      "step": 6270
    },
    {
      "epoch": 9.8125,
      "grad_norm": 2.892944812774658,
      "learning_rate": 1.8906250000000002e-07,
      "loss": 0.527,
      "step": 6280
    },
    {
      "epoch": 9.828125,
      "grad_norm": 2.620351791381836,
      "learning_rate": 1.7343750000000003e-07,
      "loss": 0.5566,
      "step": 6290
    },
    {
      "epoch": 9.84375,
      "grad_norm": 3.300260305404663,
      "learning_rate": 1.5781250000000002e-07,
      "loss": 0.5899,
      "step": 6300
    },
    {
      "epoch": 9.859375,
      "grad_norm": 4.006499767303467,
      "learning_rate": 1.4218750000000002e-07,
      "loss": 0.6418,
      "step": 6310
    },
    {
      "epoch": 9.875,
      "grad_norm": 12.843069076538086,
      "learning_rate": 1.265625e-07,
      "loss": 0.4967,
      "step": 6320
    },
    {
      "epoch": 9.890625,
      "grad_norm": 2.833449363708496,
      "learning_rate": 1.1093750000000001e-07,
      "loss": 0.5401,
      "step": 6330
    },
    {
      "epoch": 9.90625,
      "grad_norm": 2.5526134967803955,
      "learning_rate": 9.53125e-08,
      "loss": 0.4979,
      "step": 6340
    },
    {
      "epoch": 9.921875,
      "grad_norm": 3.054715394973755,
      "learning_rate": 7.96875e-08,
      "loss": 0.5754,
      "step": 6350
    },
    {
      "epoch": 9.9375,
      "grad_norm": 3.014021635055542,
      "learning_rate": 6.40625e-08,
      "loss": 0.4932,
      "step": 6360
    },
    {
      "epoch": 9.953125,
      "grad_norm": 1.8206732273101807,
      "learning_rate": 4.8437500000000006e-08,
      "loss": 0.5382,
      "step": 6370
    },
    {
      "epoch": 9.96875,
      "grad_norm": 2.4438037872314453,
      "learning_rate": 3.2812500000000003e-08,
      "loss": 0.4973,
      "step": 6380
    },
    {
      "epoch": 9.984375,
      "grad_norm": 3.6971678733825684,
      "learning_rate": 1.71875e-08,
      "loss": 0.4915,
      "step": 6390
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.948953866958618,
      "learning_rate": 1.5625000000000001e-09,
      "loss": 0.5452,
      "step": 6400
    },
    {
      "epoch": 10.0,
      "eval_gen_len": 2.1893805309734513,
      "eval_loss": 0.787492036819458,
      "eval_model_preparation_time": 0.0066,
      "eval_runtime": 107.9446,
      "eval_samples_per_second": 5.234,
      "eval_steps_per_second": 0.334,
      "step": 6400
    },
    {
      "epoch": 10.0,
      "step": 6400,
      "total_flos": 5.526462604935168e+16,
      "train_loss": 0.6449548745527863,
      "train_runtime": 10073.532,
      "train_samples_per_second": 5.083,
      "train_steps_per_second": 0.635
    }
  ],
  "logging_steps": 10,
  "max_steps": 6400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.526462604935168e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
