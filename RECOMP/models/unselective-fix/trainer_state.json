{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015625,
      "grad_norm": 6.842161178588867,
      "learning_rate": 1e-05,
      "loss": 1.7844,
      "step": 1
    },
    {
      "epoch": 0.015625,
      "grad_norm": 6.727090358734131,
      "learning_rate": 9.9859375e-06,
      "loss": 1.6585,
      "step": 10
    },
    {
      "epoch": 0.03125,
      "grad_norm": 4.98220157623291,
      "learning_rate": 9.970312500000001e-06,
      "loss": 1.6426,
      "step": 20
    },
    {
      "epoch": 0.046875,
      "grad_norm": 5.583250045776367,
      "learning_rate": 9.9546875e-06,
      "loss": 1.55,
      "step": 30
    },
    {
      "epoch": 0.0625,
      "grad_norm": 3.8034844398498535,
      "learning_rate": 9.9390625e-06,
      "loss": 1.5215,
      "step": 40
    },
    {
      "epoch": 0.078125,
      "grad_norm": 4.142884254455566,
      "learning_rate": 9.9234375e-06,
      "loss": 1.5367,
      "step": 50
    },
    {
      "epoch": 0.09375,
      "grad_norm": 4.034753322601318,
      "learning_rate": 9.907812500000001e-06,
      "loss": 1.5645,
      "step": 60
    },
    {
      "epoch": 0.109375,
      "grad_norm": 4.081456661224365,
      "learning_rate": 9.8921875e-06,
      "loss": 1.3071,
      "step": 70
    },
    {
      "epoch": 0.125,
      "grad_norm": 4.349050521850586,
      "learning_rate": 9.8765625e-06,
      "loss": 1.4015,
      "step": 80
    },
    {
      "epoch": 0.140625,
      "grad_norm": 3.9675042629241943,
      "learning_rate": 9.8609375e-06,
      "loss": 1.3256,
      "step": 90
    },
    {
      "epoch": 0.15625,
      "grad_norm": 4.161568641662598,
      "learning_rate": 9.845312500000001e-06,
      "loss": 1.3283,
      "step": 100
    },
    {
      "epoch": 0.171875,
      "grad_norm": 3.500129222869873,
      "learning_rate": 9.829687500000001e-06,
      "loss": 1.4361,
      "step": 110
    },
    {
      "epoch": 0.1875,
      "grad_norm": 3.485775947570801,
      "learning_rate": 9.8140625e-06,
      "loss": 1.2354,
      "step": 120
    },
    {
      "epoch": 0.203125,
      "grad_norm": 3.4804487228393555,
      "learning_rate": 9.7984375e-06,
      "loss": 1.2157,
      "step": 130
    },
    {
      "epoch": 0.21875,
      "grad_norm": 7.064480304718018,
      "learning_rate": 9.782812500000001e-06,
      "loss": 1.3373,
      "step": 140
    },
    {
      "epoch": 0.234375,
      "grad_norm": 3.6451869010925293,
      "learning_rate": 9.767187500000001e-06,
      "loss": 1.2577,
      "step": 150
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.86973237991333,
      "learning_rate": 9.7515625e-06,
      "loss": 1.2581,
      "step": 160
    },
    {
      "epoch": 0.265625,
      "grad_norm": 4.137082099914551,
      "learning_rate": 9.7359375e-06,
      "loss": 1.2656,
      "step": 170
    },
    {
      "epoch": 0.28125,
      "grad_norm": 4.030848026275635,
      "learning_rate": 9.720312500000002e-06,
      "loss": 1.1588,
      "step": 180
    },
    {
      "epoch": 0.296875,
      "grad_norm": 3.492738723754883,
      "learning_rate": 9.704687500000001e-06,
      "loss": 1.1606,
      "step": 190
    },
    {
      "epoch": 0.3125,
      "grad_norm": 3.903069019317627,
      "learning_rate": 9.689062500000001e-06,
      "loss": 1.0828,
      "step": 200
    },
    {
      "epoch": 0.328125,
      "grad_norm": 3.960170030593872,
      "learning_rate": 9.6734375e-06,
      "loss": 1.2352,
      "step": 210
    },
    {
      "epoch": 0.34375,
      "grad_norm": 3.5638811588287354,
      "learning_rate": 9.657812500000002e-06,
      "loss": 1.2627,
      "step": 220
    },
    {
      "epoch": 0.359375,
      "grad_norm": 3.6285688877105713,
      "learning_rate": 9.642187500000001e-06,
      "loss": 1.1264,
      "step": 230
    },
    {
      "epoch": 0.375,
      "grad_norm": 3.944267749786377,
      "learning_rate": 9.626562500000001e-06,
      "loss": 1.125,
      "step": 240
    },
    {
      "epoch": 0.390625,
      "grad_norm": 3.4956719875335693,
      "learning_rate": 9.6109375e-06,
      "loss": 1.152,
      "step": 250
    },
    {
      "epoch": 0.40625,
      "grad_norm": 3.215294122695923,
      "learning_rate": 9.5953125e-06,
      "loss": 1.2045,
      "step": 260
    },
    {
      "epoch": 0.421875,
      "grad_norm": 4.390512466430664,
      "learning_rate": 9.579687500000002e-06,
      "loss": 1.2111,
      "step": 270
    },
    {
      "epoch": 0.4375,
      "grad_norm": 3.723097085952759,
      "learning_rate": 9.564062500000001e-06,
      "loss": 1.1594,
      "step": 280
    },
    {
      "epoch": 0.453125,
      "grad_norm": 3.8970415592193604,
      "learning_rate": 9.548437500000001e-06,
      "loss": 1.195,
      "step": 290
    },
    {
      "epoch": 0.46875,
      "grad_norm": 3.528759479522705,
      "learning_rate": 9.5328125e-06,
      "loss": 1.1333,
      "step": 300
    },
    {
      "epoch": 0.484375,
      "grad_norm": 4.01265287399292,
      "learning_rate": 9.5171875e-06,
      "loss": 1.2426,
      "step": 310
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.451681613922119,
      "learning_rate": 9.501562500000001e-06,
      "loss": 1.2401,
      "step": 320
    },
    {
      "epoch": 0.515625,
      "grad_norm": 3.33843994140625,
      "learning_rate": 9.485937500000001e-06,
      "loss": 1.0424,
      "step": 330
    },
    {
      "epoch": 0.53125,
      "grad_norm": 3.3872621059417725,
      "learning_rate": 9.4703125e-06,
      "loss": 1.2328,
      "step": 340
    },
    {
      "epoch": 0.546875,
      "grad_norm": 3.2771222591400146,
      "learning_rate": 9.4546875e-06,
      "loss": 1.1308,
      "step": 350
    },
    {
      "epoch": 0.5625,
      "grad_norm": 3.6748368740081787,
      "learning_rate": 9.4390625e-06,
      "loss": 1.145,
      "step": 360
    },
    {
      "epoch": 0.578125,
      "grad_norm": 4.512892246246338,
      "learning_rate": 9.423437500000001e-06,
      "loss": 1.0847,
      "step": 370
    },
    {
      "epoch": 0.59375,
      "grad_norm": 4.138082504272461,
      "learning_rate": 9.4078125e-06,
      "loss": 1.0485,
      "step": 380
    },
    {
      "epoch": 0.609375,
      "grad_norm": 3.076080322265625,
      "learning_rate": 9.3921875e-06,
      "loss": 1.0699,
      "step": 390
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.9107635021209717,
      "learning_rate": 9.3765625e-06,
      "loss": 1.102,
      "step": 400
    },
    {
      "epoch": 0.640625,
      "grad_norm": 5.00260591506958,
      "learning_rate": 9.3609375e-06,
      "loss": 1.0349,
      "step": 410
    },
    {
      "epoch": 0.65625,
      "grad_norm": 2.9923713207244873,
      "learning_rate": 9.345312500000001e-06,
      "loss": 1.1711,
      "step": 420
    },
    {
      "epoch": 0.671875,
      "grad_norm": 3.3651533126831055,
      "learning_rate": 9.3296875e-06,
      "loss": 1.0922,
      "step": 430
    },
    {
      "epoch": 0.6875,
      "grad_norm": 3.658252716064453,
      "learning_rate": 9.3140625e-06,
      "loss": 1.011,
      "step": 440
    },
    {
      "epoch": 0.703125,
      "grad_norm": 3.34348464012146,
      "learning_rate": 9.2984375e-06,
      "loss": 1.1332,
      "step": 450
    },
    {
      "epoch": 0.71875,
      "grad_norm": 3.8290421962738037,
      "learning_rate": 9.2828125e-06,
      "loss": 1.1533,
      "step": 460
    },
    {
      "epoch": 0.734375,
      "grad_norm": 3.619974374771118,
      "learning_rate": 9.2671875e-06,
      "loss": 1.0901,
      "step": 470
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.8391528129577637,
      "learning_rate": 9.2515625e-06,
      "loss": 1.0976,
      "step": 480
    },
    {
      "epoch": 0.765625,
      "grad_norm": 3.5914158821105957,
      "learning_rate": 9.2359375e-06,
      "loss": 1.1887,
      "step": 490
    },
    {
      "epoch": 0.78125,
      "grad_norm": 3.347529649734497,
      "learning_rate": 9.2203125e-06,
      "loss": 1.053,
      "step": 500
    },
    {
      "epoch": 0.796875,
      "grad_norm": 3.8682985305786133,
      "learning_rate": 9.204687500000001e-06,
      "loss": 0.9974,
      "step": 510
    },
    {
      "epoch": 0.8125,
      "grad_norm": 3.2928459644317627,
      "learning_rate": 9.1890625e-06,
      "loss": 0.9933,
      "step": 520
    },
    {
      "epoch": 0.828125,
      "grad_norm": 3.5769383907318115,
      "learning_rate": 9.1734375e-06,
      "loss": 1.0967,
      "step": 530
    },
    {
      "epoch": 0.84375,
      "grad_norm": 2.914160966873169,
      "learning_rate": 9.1578125e-06,
      "loss": 0.9991,
      "step": 540
    },
    {
      "epoch": 0.859375,
      "grad_norm": 3.088085889816284,
      "learning_rate": 9.142187500000001e-06,
      "loss": 0.9056,
      "step": 550
    },
    {
      "epoch": 0.875,
      "grad_norm": 3.6793508529663086,
      "learning_rate": 9.1265625e-06,
      "loss": 1.0038,
      "step": 560
    },
    {
      "epoch": 0.890625,
      "grad_norm": 3.2690787315368652,
      "learning_rate": 9.1109375e-06,
      "loss": 1.0291,
      "step": 570
    },
    {
      "epoch": 0.90625,
      "grad_norm": 4.0544114112854,
      "learning_rate": 9.095312500000002e-06,
      "loss": 1.021,
      "step": 580
    },
    {
      "epoch": 0.921875,
      "grad_norm": 3.6144344806671143,
      "learning_rate": 9.079687500000001e-06,
      "loss": 1.0072,
      "step": 590
    },
    {
      "epoch": 0.9375,
      "grad_norm": 4.402358055114746,
      "learning_rate": 9.064062500000001e-06,
      "loss": 1.127,
      "step": 600
    },
    {
      "epoch": 0.953125,
      "grad_norm": 2.6646828651428223,
      "learning_rate": 9.0484375e-06,
      "loss": 1.0009,
      "step": 610
    },
    {
      "epoch": 0.96875,
      "grad_norm": 2.9477994441986084,
      "learning_rate": 9.032812500000002e-06,
      "loss": 1.1103,
      "step": 620
    },
    {
      "epoch": 0.984375,
      "grad_norm": 3.2619881629943848,
      "learning_rate": 9.017187500000001e-06,
      "loss": 1.0117,
      "step": 630
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.1441681385040283,
      "learning_rate": 9.001562500000001e-06,
      "loss": 1.0761,
      "step": 640
    },
    {
      "epoch": 1.0,
      "eval_gen_len": 35.922123893805306,
      "eval_loss": 0.885487973690033,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7751,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 640
    },
    {
      "epoch": 1.015625,
      "grad_norm": 3.486438274383545,
      "learning_rate": 8.9859375e-06,
      "loss": 1.0356,
      "step": 650
    },
    {
      "epoch": 1.03125,
      "grad_norm": 3.2841427326202393,
      "learning_rate": 8.9703125e-06,
      "loss": 0.9504,
      "step": 660
    },
    {
      "epoch": 1.046875,
      "grad_norm": 3.2320351600646973,
      "learning_rate": 8.954687500000002e-06,
      "loss": 1.0219,
      "step": 670
    },
    {
      "epoch": 1.0625,
      "grad_norm": 2.6154372692108154,
      "learning_rate": 8.939062500000001e-06,
      "loss": 0.9944,
      "step": 680
    },
    {
      "epoch": 1.078125,
      "grad_norm": 2.921600103378296,
      "learning_rate": 8.923437500000001e-06,
      "loss": 0.9795,
      "step": 690
    },
    {
      "epoch": 1.09375,
      "grad_norm": 2.4443063735961914,
      "learning_rate": 8.9078125e-06,
      "loss": 1.0232,
      "step": 700
    },
    {
      "epoch": 1.109375,
      "grad_norm": 3.23069167137146,
      "learning_rate": 8.8921875e-06,
      "loss": 0.9681,
      "step": 710
    },
    {
      "epoch": 1.125,
      "grad_norm": 3.877638339996338,
      "learning_rate": 8.876562500000001e-06,
      "loss": 1.0933,
      "step": 720
    },
    {
      "epoch": 1.140625,
      "grad_norm": 3.495182991027832,
      "learning_rate": 8.860937500000001e-06,
      "loss": 0.903,
      "step": 730
    },
    {
      "epoch": 1.15625,
      "grad_norm": 3.632620334625244,
      "learning_rate": 8.8453125e-06,
      "loss": 0.9689,
      "step": 740
    },
    {
      "epoch": 1.171875,
      "grad_norm": 3.5199105739593506,
      "learning_rate": 8.8296875e-06,
      "loss": 1.0702,
      "step": 750
    },
    {
      "epoch": 1.1875,
      "grad_norm": 2.8960158824920654,
      "learning_rate": 8.8140625e-06,
      "loss": 1.1174,
      "step": 760
    },
    {
      "epoch": 1.203125,
      "grad_norm": 3.257580280303955,
      "learning_rate": 8.798437500000001e-06,
      "loss": 1.0454,
      "step": 770
    },
    {
      "epoch": 1.21875,
      "grad_norm": 2.926252603530884,
      "learning_rate": 8.782812500000001e-06,
      "loss": 1.0125,
      "step": 780
    },
    {
      "epoch": 1.234375,
      "grad_norm": 3.764845848083496,
      "learning_rate": 8.7671875e-06,
      "loss": 1.0087,
      "step": 790
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.2415289878845215,
      "learning_rate": 8.7515625e-06,
      "loss": 1.0442,
      "step": 800
    },
    {
      "epoch": 1.265625,
      "grad_norm": 2.766818046569824,
      "learning_rate": 8.7359375e-06,
      "loss": 0.9763,
      "step": 810
    },
    {
      "epoch": 1.28125,
      "grad_norm": 2.852755308151245,
      "learning_rate": 8.720312500000001e-06,
      "loss": 1.1055,
      "step": 820
    },
    {
      "epoch": 1.296875,
      "grad_norm": 3.625048875808716,
      "learning_rate": 8.7046875e-06,
      "loss": 0.9725,
      "step": 830
    },
    {
      "epoch": 1.3125,
      "grad_norm": 3.411088705062866,
      "learning_rate": 8.6890625e-06,
      "loss": 1.0517,
      "step": 840
    },
    {
      "epoch": 1.328125,
      "grad_norm": 2.8934812545776367,
      "learning_rate": 8.6734375e-06,
      "loss": 1.0445,
      "step": 850
    },
    {
      "epoch": 1.34375,
      "grad_norm": 4.243503093719482,
      "learning_rate": 8.6578125e-06,
      "loss": 1.0048,
      "step": 860
    },
    {
      "epoch": 1.359375,
      "grad_norm": 2.6567130088806152,
      "learning_rate": 8.642187500000001e-06,
      "loss": 0.944,
      "step": 870
    },
    {
      "epoch": 1.375,
      "grad_norm": 3.0903491973876953,
      "learning_rate": 8.6265625e-06,
      "loss": 0.9158,
      "step": 880
    },
    {
      "epoch": 1.390625,
      "grad_norm": 3.123324394226074,
      "learning_rate": 8.6109375e-06,
      "loss": 1.0564,
      "step": 890
    },
    {
      "epoch": 1.40625,
      "grad_norm": 3.2414233684539795,
      "learning_rate": 8.5953125e-06,
      "loss": 0.9979,
      "step": 900
    },
    {
      "epoch": 1.421875,
      "grad_norm": 2.6429874897003174,
      "learning_rate": 8.5796875e-06,
      "loss": 0.8262,
      "step": 910
    },
    {
      "epoch": 1.4375,
      "grad_norm": 2.773071050643921,
      "learning_rate": 8.5640625e-06,
      "loss": 1.0289,
      "step": 920
    },
    {
      "epoch": 1.453125,
      "grad_norm": 3.8332972526550293,
      "learning_rate": 8.5484375e-06,
      "loss": 1.0683,
      "step": 930
    },
    {
      "epoch": 1.46875,
      "grad_norm": 4.221847057342529,
      "learning_rate": 8.5328125e-06,
      "loss": 1.0042,
      "step": 940
    },
    {
      "epoch": 1.484375,
      "grad_norm": 2.7990474700927734,
      "learning_rate": 8.517187500000001e-06,
      "loss": 0.9882,
      "step": 950
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.09891414642334,
      "learning_rate": 8.5015625e-06,
      "loss": 1.0549,
      "step": 960
    },
    {
      "epoch": 1.515625,
      "grad_norm": 2.887308359146118,
      "learning_rate": 8.4859375e-06,
      "loss": 0.9384,
      "step": 970
    },
    {
      "epoch": 1.53125,
      "grad_norm": 3.119049549102783,
      "learning_rate": 8.4703125e-06,
      "loss": 1.0192,
      "step": 980
    },
    {
      "epoch": 1.546875,
      "grad_norm": 3.1052887439727783,
      "learning_rate": 8.454687500000001e-06,
      "loss": 1.0297,
      "step": 990
    },
    {
      "epoch": 1.5625,
      "grad_norm": 3.0802109241485596,
      "learning_rate": 8.439062500000001e-06,
      "loss": 0.8776,
      "step": 1000
    },
    {
      "epoch": 1.578125,
      "grad_norm": 3.2301037311553955,
      "learning_rate": 8.4234375e-06,
      "loss": 0.9758,
      "step": 1010
    },
    {
      "epoch": 1.59375,
      "grad_norm": 3.4659693241119385,
      "learning_rate": 8.4078125e-06,
      "loss": 0.9705,
      "step": 1020
    },
    {
      "epoch": 1.609375,
      "grad_norm": 3.0620803833007812,
      "learning_rate": 8.392187500000002e-06,
      "loss": 0.9585,
      "step": 1030
    },
    {
      "epoch": 1.625,
      "grad_norm": 2.699436664581299,
      "learning_rate": 8.376562500000001e-06,
      "loss": 0.9717,
      "step": 1040
    },
    {
      "epoch": 1.640625,
      "grad_norm": 4.327167510986328,
      "learning_rate": 8.3609375e-06,
      "loss": 0.9544,
      "step": 1050
    },
    {
      "epoch": 1.65625,
      "grad_norm": 5.491847991943359,
      "learning_rate": 8.3453125e-06,
      "loss": 1.0707,
      "step": 1060
    },
    {
      "epoch": 1.671875,
      "grad_norm": 4.033407211303711,
      "learning_rate": 8.329687500000002e-06,
      "loss": 0.9297,
      "step": 1070
    },
    {
      "epoch": 1.6875,
      "grad_norm": 3.1572492122650146,
      "learning_rate": 8.314062500000001e-06,
      "loss": 0.9615,
      "step": 1080
    },
    {
      "epoch": 1.703125,
      "grad_norm": 2.5796706676483154,
      "learning_rate": 8.298437500000001e-06,
      "loss": 0.8635,
      "step": 1090
    },
    {
      "epoch": 1.71875,
      "grad_norm": 3.5784711837768555,
      "learning_rate": 8.2828125e-06,
      "loss": 0.9039,
      "step": 1100
    },
    {
      "epoch": 1.734375,
      "grad_norm": 3.504023551940918,
      "learning_rate": 8.2671875e-06,
      "loss": 0.8826,
      "step": 1110
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.127307653427124,
      "learning_rate": 8.251562500000002e-06,
      "loss": 1.0029,
      "step": 1120
    },
    {
      "epoch": 1.765625,
      "grad_norm": 3.131136894226074,
      "learning_rate": 8.235937500000001e-06,
      "loss": 0.9453,
      "step": 1130
    },
    {
      "epoch": 1.78125,
      "grad_norm": 3.1653311252593994,
      "learning_rate": 8.2203125e-06,
      "loss": 0.9065,
      "step": 1140
    },
    {
      "epoch": 1.796875,
      "grad_norm": 2.6938512325286865,
      "learning_rate": 8.2046875e-06,
      "loss": 0.9393,
      "step": 1150
    },
    {
      "epoch": 1.8125,
      "grad_norm": 2.7629899978637695,
      "learning_rate": 8.1890625e-06,
      "loss": 0.9237,
      "step": 1160
    },
    {
      "epoch": 1.828125,
      "grad_norm": 3.1487739086151123,
      "learning_rate": 8.173437500000001e-06,
      "loss": 0.9056,
      "step": 1170
    },
    {
      "epoch": 1.84375,
      "grad_norm": 2.9489502906799316,
      "learning_rate": 8.157812500000001e-06,
      "loss": 0.9926,
      "step": 1180
    },
    {
      "epoch": 1.859375,
      "grad_norm": 2.750890016555786,
      "learning_rate": 8.1421875e-06,
      "loss": 1.005,
      "step": 1190
    },
    {
      "epoch": 1.875,
      "grad_norm": 3.211210250854492,
      "learning_rate": 8.1265625e-06,
      "loss": 0.9834,
      "step": 1200
    },
    {
      "epoch": 1.890625,
      "grad_norm": 2.9368340969085693,
      "learning_rate": 8.1109375e-06,
      "loss": 0.9659,
      "step": 1210
    },
    {
      "epoch": 1.90625,
      "grad_norm": 2.8888561725616455,
      "learning_rate": 8.095312500000001e-06,
      "loss": 1.0341,
      "step": 1220
    },
    {
      "epoch": 1.921875,
      "grad_norm": 3.261901378631592,
      "learning_rate": 8.0796875e-06,
      "loss": 0.9472,
      "step": 1230
    },
    {
      "epoch": 1.9375,
      "grad_norm": 2.7385053634643555,
      "learning_rate": 8.0640625e-06,
      "loss": 0.9878,
      "step": 1240
    },
    {
      "epoch": 1.953125,
      "grad_norm": 2.604307174682617,
      "learning_rate": 8.0484375e-06,
      "loss": 0.8984,
      "step": 1250
    },
    {
      "epoch": 1.96875,
      "grad_norm": 2.9306674003601074,
      "learning_rate": 8.0328125e-06,
      "loss": 0.9501,
      "step": 1260
    },
    {
      "epoch": 1.984375,
      "grad_norm": 2.742140293121338,
      "learning_rate": 8.017187500000001e-06,
      "loss": 0.9024,
      "step": 1270
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.6085660457611084,
      "learning_rate": 8.0015625e-06,
      "loss": 0.8632,
      "step": 1280
    },
    {
      "epoch": 2.0,
      "eval_gen_len": 34.69203539823009,
      "eval_loss": 0.8312128782272339,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.8585,
      "eval_samples_per_second": 4.128,
      "eval_steps_per_second": 0.263,
      "step": 1280
    },
    {
      "epoch": 2.015625,
      "grad_norm": 2.9124770164489746,
      "learning_rate": 7.9859375e-06,
      "loss": 0.8541,
      "step": 1290
    },
    {
      "epoch": 2.03125,
      "grad_norm": 2.770245313644409,
      "learning_rate": 7.9703125e-06,
      "loss": 0.9304,
      "step": 1300
    },
    {
      "epoch": 2.046875,
      "grad_norm": 3.32442045211792,
      "learning_rate": 7.9546875e-06,
      "loss": 0.875,
      "step": 1310
    },
    {
      "epoch": 2.0625,
      "grad_norm": 3.188056707382202,
      "learning_rate": 7.9390625e-06,
      "loss": 0.9698,
      "step": 1320
    },
    {
      "epoch": 2.078125,
      "grad_norm": 2.5026702880859375,
      "learning_rate": 7.9234375e-06,
      "loss": 0.9316,
      "step": 1330
    },
    {
      "epoch": 2.09375,
      "grad_norm": 3.5593230724334717,
      "learning_rate": 7.9078125e-06,
      "loss": 0.8827,
      "step": 1340
    },
    {
      "epoch": 2.109375,
      "grad_norm": 3.467747211456299,
      "learning_rate": 7.8921875e-06,
      "loss": 0.9335,
      "step": 1350
    },
    {
      "epoch": 2.125,
      "grad_norm": 2.986111640930176,
      "learning_rate": 7.876562500000001e-06,
      "loss": 0.921,
      "step": 1360
    },
    {
      "epoch": 2.140625,
      "grad_norm": 3.0674920082092285,
      "learning_rate": 7.8609375e-06,
      "loss": 0.9196,
      "step": 1370
    },
    {
      "epoch": 2.15625,
      "grad_norm": 2.451963424682617,
      "learning_rate": 7.8453125e-06,
      "loss": 0.9247,
      "step": 1380
    },
    {
      "epoch": 2.171875,
      "grad_norm": 2.456782341003418,
      "learning_rate": 7.8296875e-06,
      "loss": 0.9171,
      "step": 1390
    },
    {
      "epoch": 2.1875,
      "grad_norm": 3.8005261421203613,
      "learning_rate": 7.814062500000001e-06,
      "loss": 0.9123,
      "step": 1400
    },
    {
      "epoch": 2.203125,
      "grad_norm": 2.172229766845703,
      "learning_rate": 7.7984375e-06,
      "loss": 1.0035,
      "step": 1410
    },
    {
      "epoch": 2.21875,
      "grad_norm": 3.1246275901794434,
      "learning_rate": 7.7828125e-06,
      "loss": 0.9377,
      "step": 1420
    },
    {
      "epoch": 2.234375,
      "grad_norm": 2.8633391857147217,
      "learning_rate": 7.767187500000002e-06,
      "loss": 0.954,
      "step": 1430
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.2642099857330322,
      "learning_rate": 7.751562500000001e-06,
      "loss": 0.9129,
      "step": 1440
    },
    {
      "epoch": 2.265625,
      "grad_norm": 2.268662929534912,
      "learning_rate": 7.7359375e-06,
      "loss": 0.8967,
      "step": 1450
    },
    {
      "epoch": 2.28125,
      "grad_norm": 2.771530866622925,
      "learning_rate": 7.7203125e-06,
      "loss": 0.848,
      "step": 1460
    },
    {
      "epoch": 2.296875,
      "grad_norm": 2.9007017612457275,
      "learning_rate": 7.704687500000002e-06,
      "loss": 0.9177,
      "step": 1470
    },
    {
      "epoch": 2.3125,
      "grad_norm": 2.5107810497283936,
      "learning_rate": 7.689062500000001e-06,
      "loss": 0.8879,
      "step": 1480
    },
    {
      "epoch": 2.328125,
      "grad_norm": 2.6684114933013916,
      "learning_rate": 7.673437500000001e-06,
      "loss": 0.8628,
      "step": 1490
    },
    {
      "epoch": 2.34375,
      "grad_norm": 3.369044780731201,
      "learning_rate": 7.6578125e-06,
      "loss": 0.9697,
      "step": 1500
    },
    {
      "epoch": 2.359375,
      "grad_norm": 2.823183059692383,
      "learning_rate": 7.6421875e-06,
      "loss": 0.87,
      "step": 1510
    },
    {
      "epoch": 2.375,
      "grad_norm": 3.310032844543457,
      "learning_rate": 7.626562500000001e-06,
      "loss": 0.8966,
      "step": 1520
    },
    {
      "epoch": 2.390625,
      "grad_norm": 3.245603561401367,
      "learning_rate": 7.6109375e-06,
      "loss": 0.9143,
      "step": 1530
    },
    {
      "epoch": 2.40625,
      "grad_norm": 5.283011436462402,
      "learning_rate": 7.595312500000001e-06,
      "loss": 1.0378,
      "step": 1540
    },
    {
      "epoch": 2.421875,
      "grad_norm": 2.5750818252563477,
      "learning_rate": 7.5796875000000004e-06,
      "loss": 0.9498,
      "step": 1550
    },
    {
      "epoch": 2.4375,
      "grad_norm": 2.7277112007141113,
      "learning_rate": 7.5640625e-06,
      "loss": 0.918,
      "step": 1560
    },
    {
      "epoch": 2.453125,
      "grad_norm": 3.15165638923645,
      "learning_rate": 7.548437500000001e-06,
      "loss": 0.983,
      "step": 1570
    },
    {
      "epoch": 2.46875,
      "grad_norm": 2.8153395652770996,
      "learning_rate": 7.532812500000001e-06,
      "loss": 0.8922,
      "step": 1580
    },
    {
      "epoch": 2.484375,
      "grad_norm": 3.2997050285339355,
      "learning_rate": 7.517187500000001e-06,
      "loss": 0.8766,
      "step": 1590
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.3858938217163086,
      "learning_rate": 7.5015625e-06,
      "loss": 0.867,
      "step": 1600
    },
    {
      "epoch": 2.515625,
      "grad_norm": 4.097867965698242,
      "learning_rate": 7.4859375e-06,
      "loss": 0.8,
      "step": 1610
    },
    {
      "epoch": 2.53125,
      "grad_norm": 2.87019419670105,
      "learning_rate": 7.470312500000001e-06,
      "loss": 0.9127,
      "step": 1620
    },
    {
      "epoch": 2.546875,
      "grad_norm": 3.1691486835479736,
      "learning_rate": 7.454687500000001e-06,
      "loss": 0.9735,
      "step": 1630
    },
    {
      "epoch": 2.5625,
      "grad_norm": 2.646744728088379,
      "learning_rate": 7.4390625e-06,
      "loss": 0.9781,
      "step": 1640
    },
    {
      "epoch": 2.578125,
      "grad_norm": 3.400984048843384,
      "learning_rate": 7.4234375e-06,
      "loss": 0.9847,
      "step": 1650
    },
    {
      "epoch": 2.59375,
      "grad_norm": 3.1083474159240723,
      "learning_rate": 7.4078125000000005e-06,
      "loss": 0.8647,
      "step": 1660
    },
    {
      "epoch": 2.609375,
      "grad_norm": 3.164010763168335,
      "learning_rate": 7.392187500000001e-06,
      "loss": 0.9379,
      "step": 1670
    },
    {
      "epoch": 2.625,
      "grad_norm": 2.2875359058380127,
      "learning_rate": 7.376562500000001e-06,
      "loss": 0.87,
      "step": 1680
    },
    {
      "epoch": 2.640625,
      "grad_norm": 2.5251104831695557,
      "learning_rate": 7.3609375e-06,
      "loss": 0.8856,
      "step": 1690
    },
    {
      "epoch": 2.65625,
      "grad_norm": 3.1788792610168457,
      "learning_rate": 7.345312500000001e-06,
      "loss": 0.9242,
      "step": 1700
    },
    {
      "epoch": 2.671875,
      "grad_norm": 2.33160662651062,
      "learning_rate": 7.3296875e-06,
      "loss": 0.9706,
      "step": 1710
    },
    {
      "epoch": 2.6875,
      "grad_norm": 2.9933512210845947,
      "learning_rate": 7.314062500000001e-06,
      "loss": 0.9043,
      "step": 1720
    },
    {
      "epoch": 2.703125,
      "grad_norm": 3.094656229019165,
      "learning_rate": 7.2984375e-06,
      "loss": 0.9086,
      "step": 1730
    },
    {
      "epoch": 2.71875,
      "grad_norm": 3.4579694271087646,
      "learning_rate": 7.282812500000001e-06,
      "loss": 0.8655,
      "step": 1740
    },
    {
      "epoch": 2.734375,
      "grad_norm": 3.439558744430542,
      "learning_rate": 7.2671875000000005e-06,
      "loss": 0.8614,
      "step": 1750
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.181572675704956,
      "learning_rate": 7.2515625e-06,
      "loss": 0.9435,
      "step": 1760
    },
    {
      "epoch": 2.765625,
      "grad_norm": 3.6622743606567383,
      "learning_rate": 7.2359375000000005e-06,
      "loss": 0.9288,
      "step": 1770
    },
    {
      "epoch": 2.78125,
      "grad_norm": 3.4282445907592773,
      "learning_rate": 7.220312500000001e-06,
      "loss": 0.8739,
      "step": 1780
    },
    {
      "epoch": 2.796875,
      "grad_norm": 2.3281936645507812,
      "learning_rate": 7.204687500000001e-06,
      "loss": 0.8273,
      "step": 1790
    },
    {
      "epoch": 2.8125,
      "grad_norm": 2.8547351360321045,
      "learning_rate": 7.1890625e-06,
      "loss": 0.8784,
      "step": 1800
    },
    {
      "epoch": 2.828125,
      "grad_norm": 4.656309127807617,
      "learning_rate": 7.1734375e-06,
      "loss": 0.9081,
      "step": 1810
    },
    {
      "epoch": 2.84375,
      "grad_norm": 2.7862741947174072,
      "learning_rate": 7.157812500000001e-06,
      "loss": 0.8703,
      "step": 1820
    },
    {
      "epoch": 2.859375,
      "grad_norm": 3.04146409034729,
      "learning_rate": 7.142187500000001e-06,
      "loss": 0.9373,
      "step": 1830
    },
    {
      "epoch": 2.875,
      "grad_norm": 2.73407244682312,
      "learning_rate": 7.1265625000000004e-06,
      "loss": 0.9342,
      "step": 1840
    },
    {
      "epoch": 2.890625,
      "grad_norm": 2.2312629222869873,
      "learning_rate": 7.1109375e-06,
      "loss": 0.8618,
      "step": 1850
    },
    {
      "epoch": 2.90625,
      "grad_norm": 3.0037481784820557,
      "learning_rate": 7.0953125e-06,
      "loss": 0.901,
      "step": 1860
    },
    {
      "epoch": 2.921875,
      "grad_norm": 3.4438071250915527,
      "learning_rate": 7.079687500000001e-06,
      "loss": 0.9151,
      "step": 1870
    },
    {
      "epoch": 2.9375,
      "grad_norm": 3.858402729034424,
      "learning_rate": 7.064062500000001e-06,
      "loss": 0.9923,
      "step": 1880
    },
    {
      "epoch": 2.953125,
      "grad_norm": 3.341172456741333,
      "learning_rate": 7.0484375e-06,
      "loss": 0.8648,
      "step": 1890
    },
    {
      "epoch": 2.96875,
      "grad_norm": 3.023024082183838,
      "learning_rate": 7.0328125e-06,
      "loss": 0.8631,
      "step": 1900
    },
    {
      "epoch": 2.984375,
      "grad_norm": 2.8571622371673584,
      "learning_rate": 7.0171875e-06,
      "loss": 0.8503,
      "step": 1910
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.0797269344329834,
      "learning_rate": 7.001562500000001e-06,
      "loss": 0.8634,
      "step": 1920
    },
    {
      "epoch": 3.0,
      "eval_gen_len": 34.230088495575224,
      "eval_loss": 0.7977619171142578,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7863,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 1920
    },
    {
      "epoch": 3.015625,
      "grad_norm": 3.4201390743255615,
      "learning_rate": 6.9859375e-06,
      "loss": 0.7625,
      "step": 1930
    },
    {
      "epoch": 3.03125,
      "grad_norm": 2.4585795402526855,
      "learning_rate": 6.970312500000001e-06,
      "loss": 0.9089,
      "step": 1940
    },
    {
      "epoch": 3.046875,
      "grad_norm": 3.240579605102539,
      "learning_rate": 6.9546875000000005e-06,
      "loss": 0.9304,
      "step": 1950
    },
    {
      "epoch": 3.0625,
      "grad_norm": 3.1319005489349365,
      "learning_rate": 6.9390625e-06,
      "loss": 0.8968,
      "step": 1960
    },
    {
      "epoch": 3.078125,
      "grad_norm": 3.103029251098633,
      "learning_rate": 6.9234375000000006e-06,
      "loss": 0.9154,
      "step": 1970
    },
    {
      "epoch": 3.09375,
      "grad_norm": 3.3509318828582764,
      "learning_rate": 6.907812500000001e-06,
      "loss": 0.8666,
      "step": 1980
    },
    {
      "epoch": 3.109375,
      "grad_norm": 2.5476582050323486,
      "learning_rate": 6.892187500000001e-06,
      "loss": 0.9033,
      "step": 1990
    },
    {
      "epoch": 3.125,
      "grad_norm": 3.1649270057678223,
      "learning_rate": 6.8765625e-06,
      "loss": 0.8784,
      "step": 2000
    },
    {
      "epoch": 3.140625,
      "grad_norm": 2.8184916973114014,
      "learning_rate": 6.8609375e-06,
      "loss": 0.9269,
      "step": 2010
    },
    {
      "epoch": 3.15625,
      "grad_norm": 2.89841365814209,
      "learning_rate": 6.845312500000001e-06,
      "loss": 0.9323,
      "step": 2020
    },
    {
      "epoch": 3.171875,
      "grad_norm": 3.71685791015625,
      "learning_rate": 6.829687500000001e-06,
      "loss": 0.8379,
      "step": 2030
    },
    {
      "epoch": 3.1875,
      "grad_norm": 3.2080013751983643,
      "learning_rate": 6.8140625000000005e-06,
      "loss": 0.8385,
      "step": 2040
    },
    {
      "epoch": 3.203125,
      "grad_norm": 3.2623729705810547,
      "learning_rate": 6.7984375e-06,
      "loss": 0.8739,
      "step": 2050
    },
    {
      "epoch": 3.21875,
      "grad_norm": 2.4468777179718018,
      "learning_rate": 6.7828125e-06,
      "loss": 0.845,
      "step": 2060
    },
    {
      "epoch": 3.234375,
      "grad_norm": 3.714451313018799,
      "learning_rate": 6.767187500000001e-06,
      "loss": 0.8956,
      "step": 2070
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.3464033603668213,
      "learning_rate": 6.751562500000001e-06,
      "loss": 0.846,
      "step": 2080
    },
    {
      "epoch": 3.265625,
      "grad_norm": 3.887415885925293,
      "learning_rate": 6.7359375e-06,
      "loss": 0.8671,
      "step": 2090
    },
    {
      "epoch": 3.28125,
      "grad_norm": 2.686014413833618,
      "learning_rate": 6.7203125e-06,
      "loss": 0.8244,
      "step": 2100
    },
    {
      "epoch": 3.296875,
      "grad_norm": 3.0618033409118652,
      "learning_rate": 6.7046875e-06,
      "loss": 0.7675,
      "step": 2110
    },
    {
      "epoch": 3.3125,
      "grad_norm": 3.426661729812622,
      "learning_rate": 6.689062500000001e-06,
      "loss": 0.8649,
      "step": 2120
    },
    {
      "epoch": 3.328125,
      "grad_norm": 2.9940686225891113,
      "learning_rate": 6.6734375000000004e-06,
      "loss": 0.7992,
      "step": 2130
    },
    {
      "epoch": 3.34375,
      "grad_norm": 3.255910873413086,
      "learning_rate": 6.6578125e-06,
      "loss": 0.8524,
      "step": 2140
    },
    {
      "epoch": 3.359375,
      "grad_norm": 2.8103933334350586,
      "learning_rate": 6.6421875000000005e-06,
      "loss": 0.7943,
      "step": 2150
    },
    {
      "epoch": 3.375,
      "grad_norm": 3.6635940074920654,
      "learning_rate": 6.6265625e-06,
      "loss": 0.8204,
      "step": 2160
    },
    {
      "epoch": 3.390625,
      "grad_norm": 3.873373508453369,
      "learning_rate": 6.610937500000001e-06,
      "loss": 0.8848,
      "step": 2170
    },
    {
      "epoch": 3.40625,
      "grad_norm": 3.3833112716674805,
      "learning_rate": 6.595312500000001e-06,
      "loss": 0.8971,
      "step": 2180
    },
    {
      "epoch": 3.421875,
      "grad_norm": 4.177978515625,
      "learning_rate": 6.579687500000001e-06,
      "loss": 0.8473,
      "step": 2190
    },
    {
      "epoch": 3.4375,
      "grad_norm": 2.6713829040527344,
      "learning_rate": 6.5640625e-06,
      "loss": 0.8637,
      "step": 2200
    },
    {
      "epoch": 3.453125,
      "grad_norm": 2.278132200241089,
      "learning_rate": 6.5484375e-06,
      "loss": 0.9118,
      "step": 2210
    },
    {
      "epoch": 3.46875,
      "grad_norm": 2.1738436222076416,
      "learning_rate": 6.532812500000001e-06,
      "loss": 0.9307,
      "step": 2220
    },
    {
      "epoch": 3.484375,
      "grad_norm": 3.0359318256378174,
      "learning_rate": 6.517187500000001e-06,
      "loss": 0.8215,
      "step": 2230
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.334996223449707,
      "learning_rate": 6.5015625000000005e-06,
      "loss": 0.9174,
      "step": 2240
    },
    {
      "epoch": 3.515625,
      "grad_norm": 3.6047415733337402,
      "learning_rate": 6.4859375e-06,
      "loss": 0.8705,
      "step": 2250
    },
    {
      "epoch": 3.53125,
      "grad_norm": 2.8026316165924072,
      "learning_rate": 6.4703125e-06,
      "loss": 1.0691,
      "step": 2260
    },
    {
      "epoch": 3.546875,
      "grad_norm": 2.7064051628112793,
      "learning_rate": 6.454687500000001e-06,
      "loss": 0.8773,
      "step": 2270
    },
    {
      "epoch": 3.5625,
      "grad_norm": 2.7253870964050293,
      "learning_rate": 6.439062500000001e-06,
      "loss": 0.8974,
      "step": 2280
    },
    {
      "epoch": 3.578125,
      "grad_norm": 2.9364867210388184,
      "learning_rate": 6.4234375e-06,
      "loss": 0.7369,
      "step": 2290
    },
    {
      "epoch": 3.59375,
      "grad_norm": 3.195404052734375,
      "learning_rate": 6.4078125e-06,
      "loss": 0.8671,
      "step": 2300
    },
    {
      "epoch": 3.609375,
      "grad_norm": 2.375108480453491,
      "learning_rate": 6.3921875e-06,
      "loss": 0.9164,
      "step": 2310
    },
    {
      "epoch": 3.625,
      "grad_norm": 3.407278299331665,
      "learning_rate": 6.376562500000001e-06,
      "loss": 0.916,
      "step": 2320
    },
    {
      "epoch": 3.640625,
      "grad_norm": 2.904212474822998,
      "learning_rate": 6.3609375000000005e-06,
      "loss": 0.9327,
      "step": 2330
    },
    {
      "epoch": 3.65625,
      "grad_norm": 2.8590900897979736,
      "learning_rate": 6.3453125e-06,
      "loss": 0.8217,
      "step": 2340
    },
    {
      "epoch": 3.671875,
      "grad_norm": 3.018406391143799,
      "learning_rate": 6.3296875000000005e-06,
      "loss": 0.932,
      "step": 2350
    },
    {
      "epoch": 3.6875,
      "grad_norm": 2.6503782272338867,
      "learning_rate": 6.3140625e-06,
      "loss": 0.8945,
      "step": 2360
    },
    {
      "epoch": 3.703125,
      "grad_norm": 2.5963096618652344,
      "learning_rate": 6.298437500000001e-06,
      "loss": 0.8211,
      "step": 2370
    },
    {
      "epoch": 3.71875,
      "grad_norm": 3.100496768951416,
      "learning_rate": 6.2828125e-06,
      "loss": 0.8109,
      "step": 2380
    },
    {
      "epoch": 3.734375,
      "grad_norm": 3.348442316055298,
      "learning_rate": 6.267187500000001e-06,
      "loss": 0.8921,
      "step": 2390
    },
    {
      "epoch": 3.75,
      "grad_norm": 4.044034004211426,
      "learning_rate": 6.2515625e-06,
      "loss": 0.8187,
      "step": 2400
    },
    {
      "epoch": 3.765625,
      "grad_norm": 3.9787182807922363,
      "learning_rate": 6.2359375e-06,
      "loss": 0.9525,
      "step": 2410
    },
    {
      "epoch": 3.78125,
      "grad_norm": 2.8017613887786865,
      "learning_rate": 6.220312500000001e-06,
      "loss": 0.8429,
      "step": 2420
    },
    {
      "epoch": 3.796875,
      "grad_norm": 2.022667407989502,
      "learning_rate": 6.204687500000001e-06,
      "loss": 0.8512,
      "step": 2430
    },
    {
      "epoch": 3.8125,
      "grad_norm": 2.6702239513397217,
      "learning_rate": 6.1890625000000005e-06,
      "loss": 0.8134,
      "step": 2440
    },
    {
      "epoch": 3.828125,
      "grad_norm": 3.2435107231140137,
      "learning_rate": 6.1734375e-06,
      "loss": 0.9101,
      "step": 2450
    },
    {
      "epoch": 3.84375,
      "grad_norm": 2.9478211402893066,
      "learning_rate": 6.1578125e-06,
      "loss": 0.7769,
      "step": 2460
    },
    {
      "epoch": 3.859375,
      "grad_norm": 3.6120426654815674,
      "learning_rate": 6.142187500000001e-06,
      "loss": 0.8953,
      "step": 2470
    },
    {
      "epoch": 3.875,
      "grad_norm": 2.5539391040802,
      "learning_rate": 6.126562500000001e-06,
      "loss": 0.7967,
      "step": 2480
    },
    {
      "epoch": 3.890625,
      "grad_norm": 3.981292486190796,
      "learning_rate": 6.1109375e-06,
      "loss": 0.8721,
      "step": 2490
    },
    {
      "epoch": 3.90625,
      "grad_norm": 2.718233108520508,
      "learning_rate": 6.0953125e-06,
      "loss": 0.7904,
      "step": 2500
    },
    {
      "epoch": 3.921875,
      "grad_norm": 2.816776752471924,
      "learning_rate": 6.0796874999999995e-06,
      "loss": 0.871,
      "step": 2510
    },
    {
      "epoch": 3.9375,
      "grad_norm": 2.2285749912261963,
      "learning_rate": 6.064062500000001e-06,
      "loss": 0.7719,
      "step": 2520
    },
    {
      "epoch": 3.953125,
      "grad_norm": 2.868565559387207,
      "learning_rate": 6.0484375000000005e-06,
      "loss": 0.8748,
      "step": 2530
    },
    {
      "epoch": 3.96875,
      "grad_norm": 3.416968822479248,
      "learning_rate": 6.0328125e-06,
      "loss": 0.9043,
      "step": 2540
    },
    {
      "epoch": 3.984375,
      "grad_norm": 2.8768808841705322,
      "learning_rate": 6.0171875000000006e-06,
      "loss": 0.8822,
      "step": 2550
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.476682662963867,
      "learning_rate": 6.0015625e-06,
      "loss": 0.7968,
      "step": 2560
    },
    {
      "epoch": 4.0,
      "eval_gen_len": 33.96283185840708,
      "eval_loss": 0.7786944508552551,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7346,
      "eval_samples_per_second": 4.132,
      "eval_steps_per_second": 0.263,
      "step": 2560
    },
    {
      "epoch": 4.015625,
      "grad_norm": 4.060461044311523,
      "learning_rate": 5.985937500000001e-06,
      "loss": 0.8356,
      "step": 2570
    },
    {
      "epoch": 4.03125,
      "grad_norm": 2.7554781436920166,
      "learning_rate": 5.9703125e-06,
      "loss": 0.8762,
      "step": 2580
    },
    {
      "epoch": 4.046875,
      "grad_norm": 3.15421199798584,
      "learning_rate": 5.954687500000001e-06,
      "loss": 0.9584,
      "step": 2590
    },
    {
      "epoch": 4.0625,
      "grad_norm": 2.362602710723877,
      "learning_rate": 5.9390625e-06,
      "loss": 0.8078,
      "step": 2600
    },
    {
      "epoch": 4.078125,
      "grad_norm": 2.3326592445373535,
      "learning_rate": 5.9234375e-06,
      "loss": 0.8104,
      "step": 2610
    },
    {
      "epoch": 4.09375,
      "grad_norm": 2.200453042984009,
      "learning_rate": 5.9078125000000005e-06,
      "loss": 0.8746,
      "step": 2620
    },
    {
      "epoch": 4.109375,
      "grad_norm": 2.950693130493164,
      "learning_rate": 5.892187500000001e-06,
      "loss": 0.8456,
      "step": 2630
    },
    {
      "epoch": 4.125,
      "grad_norm": 3.0255684852600098,
      "learning_rate": 5.8765625000000005e-06,
      "loss": 0.7932,
      "step": 2640
    },
    {
      "epoch": 4.140625,
      "grad_norm": 2.577143430709839,
      "learning_rate": 5.8609375e-06,
      "loss": 0.7832,
      "step": 2650
    },
    {
      "epoch": 4.15625,
      "grad_norm": 3.0857295989990234,
      "learning_rate": 5.8453125e-06,
      "loss": 0.8596,
      "step": 2660
    },
    {
      "epoch": 4.171875,
      "grad_norm": 3.206843852996826,
      "learning_rate": 5.829687500000001e-06,
      "loss": 0.8919,
      "step": 2670
    },
    {
      "epoch": 4.1875,
      "grad_norm": 3.2522165775299072,
      "learning_rate": 5.814062500000001e-06,
      "loss": 0.8047,
      "step": 2680
    },
    {
      "epoch": 4.203125,
      "grad_norm": 2.7902302742004395,
      "learning_rate": 5.7984375e-06,
      "loss": 0.7956,
      "step": 2690
    },
    {
      "epoch": 4.21875,
      "grad_norm": 3.3750314712524414,
      "learning_rate": 5.7828125e-06,
      "loss": 0.8963,
      "step": 2700
    },
    {
      "epoch": 4.234375,
      "grad_norm": 2.8552968502044678,
      "learning_rate": 5.7671874999999996e-06,
      "loss": 0.8517,
      "step": 2710
    },
    {
      "epoch": 4.25,
      "grad_norm": 2.8376381397247314,
      "learning_rate": 5.751562500000001e-06,
      "loss": 0.8925,
      "step": 2720
    },
    {
      "epoch": 4.265625,
      "grad_norm": 3.0074501037597656,
      "learning_rate": 5.7359375000000005e-06,
      "loss": 0.8684,
      "step": 2730
    },
    {
      "epoch": 4.28125,
      "grad_norm": 2.9895243644714355,
      "learning_rate": 5.7203125e-06,
      "loss": 0.9245,
      "step": 2740
    },
    {
      "epoch": 4.296875,
      "grad_norm": 2.364435911178589,
      "learning_rate": 5.7046875e-06,
      "loss": 0.7743,
      "step": 2750
    },
    {
      "epoch": 4.3125,
      "grad_norm": 2.6237072944641113,
      "learning_rate": 5.6890625e-06,
      "loss": 0.804,
      "step": 2760
    },
    {
      "epoch": 4.328125,
      "grad_norm": 2.995648145675659,
      "learning_rate": 5.673437500000001e-06,
      "loss": 0.8479,
      "step": 2770
    },
    {
      "epoch": 4.34375,
      "grad_norm": 3.104933023452759,
      "learning_rate": 5.6578125e-06,
      "loss": 0.8862,
      "step": 2780
    },
    {
      "epoch": 4.359375,
      "grad_norm": 2.9605116844177246,
      "learning_rate": 5.642187500000001e-06,
      "loss": 0.8236,
      "step": 2790
    },
    {
      "epoch": 4.375,
      "grad_norm": 2.8216583728790283,
      "learning_rate": 5.6265625e-06,
      "loss": 0.8695,
      "step": 2800
    },
    {
      "epoch": 4.390625,
      "grad_norm": 2.5343692302703857,
      "learning_rate": 5.6109375e-06,
      "loss": 0.8009,
      "step": 2810
    },
    {
      "epoch": 4.40625,
      "grad_norm": 2.378582715988159,
      "learning_rate": 5.5953125000000005e-06,
      "loss": 0.8161,
      "step": 2820
    },
    {
      "epoch": 4.421875,
      "grad_norm": 3.7031641006469727,
      "learning_rate": 5.579687500000001e-06,
      "loss": 0.8684,
      "step": 2830
    },
    {
      "epoch": 4.4375,
      "grad_norm": 3.3335773944854736,
      "learning_rate": 5.5640625000000006e-06,
      "loss": 0.8435,
      "step": 2840
    },
    {
      "epoch": 4.453125,
      "grad_norm": 3.93965482711792,
      "learning_rate": 5.5484375e-06,
      "loss": 0.8907,
      "step": 2850
    },
    {
      "epoch": 4.46875,
      "grad_norm": 2.669783592224121,
      "learning_rate": 5.5328125e-06,
      "loss": 0.8619,
      "step": 2860
    },
    {
      "epoch": 4.484375,
      "grad_norm": 2.1492421627044678,
      "learning_rate": 5.517187500000001e-06,
      "loss": 0.8592,
      "step": 2870
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.4458279609680176,
      "learning_rate": 5.501562500000001e-06,
      "loss": 0.8207,
      "step": 2880
    },
    {
      "epoch": 4.515625,
      "grad_norm": 2.742967367172241,
      "learning_rate": 5.4859375e-06,
      "loss": 0.8918,
      "step": 2890
    },
    {
      "epoch": 4.53125,
      "grad_norm": 2.8055362701416016,
      "learning_rate": 5.4703125e-06,
      "loss": 0.9009,
      "step": 2900
    },
    {
      "epoch": 4.546875,
      "grad_norm": 4.718233108520508,
      "learning_rate": 5.4546875e-06,
      "loss": 0.8321,
      "step": 2910
    },
    {
      "epoch": 4.5625,
      "grad_norm": 3.2807319164276123,
      "learning_rate": 5.439062500000001e-06,
      "loss": 0.8219,
      "step": 2920
    },
    {
      "epoch": 4.578125,
      "grad_norm": 3.1664679050445557,
      "learning_rate": 5.4234375000000005e-06,
      "loss": 0.9125,
      "step": 2930
    },
    {
      "epoch": 4.59375,
      "grad_norm": 2.670992612838745,
      "learning_rate": 5.4078125e-06,
      "loss": 0.8238,
      "step": 2940
    },
    {
      "epoch": 4.609375,
      "grad_norm": 3.358381748199463,
      "learning_rate": 5.3921875e-06,
      "loss": 0.8502,
      "step": 2950
    },
    {
      "epoch": 4.625,
      "grad_norm": 3.65677547454834,
      "learning_rate": 5.3765625e-06,
      "loss": 0.8496,
      "step": 2960
    },
    {
      "epoch": 4.640625,
      "grad_norm": 2.0060980319976807,
      "learning_rate": 5.360937500000001e-06,
      "loss": 0.7756,
      "step": 2970
    },
    {
      "epoch": 4.65625,
      "grad_norm": 2.4187171459198,
      "learning_rate": 5.3453125e-06,
      "loss": 0.7295,
      "step": 2980
    },
    {
      "epoch": 4.671875,
      "grad_norm": 3.1378958225250244,
      "learning_rate": 5.3296875e-06,
      "loss": 0.8198,
      "step": 2990
    },
    {
      "epoch": 4.6875,
      "grad_norm": 3.073256731033325,
      "learning_rate": 5.3140625e-06,
      "loss": 0.8509,
      "step": 3000
    },
    {
      "epoch": 4.703125,
      "grad_norm": 3.37697172164917,
      "learning_rate": 5.2984375e-06,
      "loss": 0.7678,
      "step": 3010
    },
    {
      "epoch": 4.71875,
      "grad_norm": 3.206451892852783,
      "learning_rate": 5.2828125000000005e-06,
      "loss": 0.8585,
      "step": 3020
    },
    {
      "epoch": 4.734375,
      "grad_norm": 2.549008369445801,
      "learning_rate": 5.267187500000001e-06,
      "loss": 0.888,
      "step": 3030
    },
    {
      "epoch": 4.75,
      "grad_norm": 2.6755247116088867,
      "learning_rate": 5.251562500000001e-06,
      "loss": 0.7525,
      "step": 3040
    },
    {
      "epoch": 4.765625,
      "grad_norm": 2.7727653980255127,
      "learning_rate": 5.2359375e-06,
      "loss": 0.8245,
      "step": 3050
    },
    {
      "epoch": 4.78125,
      "grad_norm": 2.994007110595703,
      "learning_rate": 5.2203125e-06,
      "loss": 0.8689,
      "step": 3060
    },
    {
      "epoch": 4.796875,
      "grad_norm": 3.2288591861724854,
      "learning_rate": 5.204687500000001e-06,
      "loss": 0.8137,
      "step": 3070
    },
    {
      "epoch": 4.8125,
      "grad_norm": 2.8603293895721436,
      "learning_rate": 5.189062500000001e-06,
      "loss": 0.8432,
      "step": 3080
    },
    {
      "epoch": 4.828125,
      "grad_norm": 2.8871452808380127,
      "learning_rate": 5.1734375e-06,
      "loss": 0.7863,
      "step": 3090
    },
    {
      "epoch": 4.84375,
      "grad_norm": 2.7249886989593506,
      "learning_rate": 5.1578125e-06,
      "loss": 0.8152,
      "step": 3100
    },
    {
      "epoch": 4.859375,
      "grad_norm": 2.845209836959839,
      "learning_rate": 5.1421875e-06,
      "loss": 0.8144,
      "step": 3110
    },
    {
      "epoch": 4.875,
      "grad_norm": 2.614128589630127,
      "learning_rate": 5.126562500000001e-06,
      "loss": 0.8775,
      "step": 3120
    },
    {
      "epoch": 4.890625,
      "grad_norm": 2.4294517040252686,
      "learning_rate": 5.1109375000000006e-06,
      "loss": 0.7483,
      "step": 3130
    },
    {
      "epoch": 4.90625,
      "grad_norm": 2.459479331970215,
      "learning_rate": 5.0953125e-06,
      "loss": 0.8523,
      "step": 3140
    },
    {
      "epoch": 4.921875,
      "grad_norm": 3.112583637237549,
      "learning_rate": 5.0796875e-06,
      "loss": 0.8908,
      "step": 3150
    },
    {
      "epoch": 4.9375,
      "grad_norm": 2.6624791622161865,
      "learning_rate": 5.0640625e-06,
      "loss": 0.6854,
      "step": 3160
    },
    {
      "epoch": 4.953125,
      "grad_norm": 2.993502616882324,
      "learning_rate": 5.048437500000001e-06,
      "loss": 0.817,
      "step": 3170
    },
    {
      "epoch": 4.96875,
      "grad_norm": 2.4154741764068604,
      "learning_rate": 5.0328125e-06,
      "loss": 0.7968,
      "step": 3180
    },
    {
      "epoch": 4.984375,
      "grad_norm": 2.742497444152832,
      "learning_rate": 5.0171875e-06,
      "loss": 0.9251,
      "step": 3190
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.384711265563965,
      "learning_rate": 5.0015625000000004e-06,
      "loss": 0.8622,
      "step": 3200
    },
    {
      "epoch": 5.0,
      "eval_gen_len": 34.15221238938053,
      "eval_loss": 0.7597708702087402,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7809,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 3200
    },
    {
      "epoch": 5.015625,
      "grad_norm": 2.367250680923462,
      "learning_rate": 4.9859375e-06,
      "loss": 0.7196,
      "step": 3210
    },
    {
      "epoch": 5.03125,
      "grad_norm": 2.9218590259552,
      "learning_rate": 4.9703125000000005e-06,
      "loss": 0.852,
      "step": 3220
    },
    {
      "epoch": 5.046875,
      "grad_norm": 2.6878836154937744,
      "learning_rate": 4.9546875e-06,
      "loss": 0.8376,
      "step": 3230
    },
    {
      "epoch": 5.0625,
      "grad_norm": 2.741926670074463,
      "learning_rate": 4.939062500000001e-06,
      "loss": 0.8512,
      "step": 3240
    },
    {
      "epoch": 5.078125,
      "grad_norm": 3.5915896892547607,
      "learning_rate": 4.9234375e-06,
      "loss": 0.8687,
      "step": 3250
    },
    {
      "epoch": 5.09375,
      "grad_norm": 2.534818649291992,
      "learning_rate": 4.907812500000001e-06,
      "loss": 0.8595,
      "step": 3260
    },
    {
      "epoch": 5.109375,
      "grad_norm": 3.0919787883758545,
      "learning_rate": 4.8921875e-06,
      "loss": 0.8496,
      "step": 3270
    },
    {
      "epoch": 5.125,
      "grad_norm": 3.1111526489257812,
      "learning_rate": 4.876562500000001e-06,
      "loss": 0.8174,
      "step": 3280
    },
    {
      "epoch": 5.140625,
      "grad_norm": 3.139993906021118,
      "learning_rate": 4.8609375e-06,
      "loss": 0.8144,
      "step": 3290
    },
    {
      "epoch": 5.15625,
      "grad_norm": 2.332321882247925,
      "learning_rate": 4.845312500000001e-06,
      "loss": 0.7958,
      "step": 3300
    },
    {
      "epoch": 5.171875,
      "grad_norm": 2.7278969287872314,
      "learning_rate": 4.8296875000000005e-06,
      "loss": 0.9016,
      "step": 3310
    },
    {
      "epoch": 5.1875,
      "grad_norm": 2.6556053161621094,
      "learning_rate": 4.8140625e-06,
      "loss": 0.831,
      "step": 3320
    },
    {
      "epoch": 5.203125,
      "grad_norm": 3.007106304168701,
      "learning_rate": 4.798437500000001e-06,
      "loss": 0.8914,
      "step": 3330
    },
    {
      "epoch": 5.21875,
      "grad_norm": 2.8139281272888184,
      "learning_rate": 4.7828125e-06,
      "loss": 0.7996,
      "step": 3340
    },
    {
      "epoch": 5.234375,
      "grad_norm": 2.633035182952881,
      "learning_rate": 4.767187500000001e-06,
      "loss": 0.8418,
      "step": 3350
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.152076244354248,
      "learning_rate": 4.7515625e-06,
      "loss": 0.788,
      "step": 3360
    },
    {
      "epoch": 5.265625,
      "grad_norm": 2.4304745197296143,
      "learning_rate": 4.7359375e-06,
      "loss": 0.888,
      "step": 3370
    },
    {
      "epoch": 5.28125,
      "grad_norm": 3.598930597305298,
      "learning_rate": 4.7203125e-06,
      "loss": 0.8035,
      "step": 3380
    },
    {
      "epoch": 5.296875,
      "grad_norm": 2.993072509765625,
      "learning_rate": 4.7046875e-06,
      "loss": 0.8157,
      "step": 3390
    },
    {
      "epoch": 5.3125,
      "grad_norm": 2.923569679260254,
      "learning_rate": 4.6890625000000005e-06,
      "loss": 0.8393,
      "step": 3400
    },
    {
      "epoch": 5.328125,
      "grad_norm": 2.2139995098114014,
      "learning_rate": 4.6734375e-06,
      "loss": 0.9073,
      "step": 3410
    },
    {
      "epoch": 5.34375,
      "grad_norm": 3.9117751121520996,
      "learning_rate": 4.6578125000000006e-06,
      "loss": 0.7387,
      "step": 3420
    },
    {
      "epoch": 5.359375,
      "grad_norm": 2.3949506282806396,
      "learning_rate": 4.6421875e-06,
      "loss": 0.8822,
      "step": 3430
    },
    {
      "epoch": 5.375,
      "grad_norm": 2.4284210205078125,
      "learning_rate": 4.626562500000001e-06,
      "loss": 0.8384,
      "step": 3440
    },
    {
      "epoch": 5.390625,
      "grad_norm": 2.5498206615448,
      "learning_rate": 4.6109375e-06,
      "loss": 0.7411,
      "step": 3450
    },
    {
      "epoch": 5.40625,
      "grad_norm": 2.7120108604431152,
      "learning_rate": 4.595312500000001e-06,
      "loss": 0.8236,
      "step": 3460
    },
    {
      "epoch": 5.421875,
      "grad_norm": 2.748884439468384,
      "learning_rate": 4.5796875e-06,
      "loss": 0.8447,
      "step": 3470
    },
    {
      "epoch": 5.4375,
      "grad_norm": 3.398155927658081,
      "learning_rate": 4.564062500000001e-06,
      "loss": 0.7798,
      "step": 3480
    },
    {
      "epoch": 5.453125,
      "grad_norm": 2.2968413829803467,
      "learning_rate": 4.5484375000000004e-06,
      "loss": 0.7191,
      "step": 3490
    },
    {
      "epoch": 5.46875,
      "grad_norm": 2.815585136413574,
      "learning_rate": 4.532812500000001e-06,
      "loss": 0.7956,
      "step": 3500
    },
    {
      "epoch": 5.484375,
      "grad_norm": 2.3712499141693115,
      "learning_rate": 4.5171875000000005e-06,
      "loss": 0.8433,
      "step": 3510
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.982762098312378,
      "learning_rate": 4.5015625e-06,
      "loss": 0.741,
      "step": 3520
    },
    {
      "epoch": 5.515625,
      "grad_norm": 3.0669455528259277,
      "learning_rate": 4.485937500000001e-06,
      "loss": 0.8573,
      "step": 3530
    },
    {
      "epoch": 5.53125,
      "grad_norm": 2.6887452602386475,
      "learning_rate": 4.4703125e-06,
      "loss": 0.8309,
      "step": 3540
    },
    {
      "epoch": 5.546875,
      "grad_norm": 2.8727357387542725,
      "learning_rate": 4.454687500000001e-06,
      "loss": 0.7859,
      "step": 3550
    },
    {
      "epoch": 5.5625,
      "grad_norm": 2.7510671615600586,
      "learning_rate": 4.4390625e-06,
      "loss": 0.7958,
      "step": 3560
    },
    {
      "epoch": 5.578125,
      "grad_norm": 1.8098225593566895,
      "learning_rate": 4.4234375e-06,
      "loss": 0.7804,
      "step": 3570
    },
    {
      "epoch": 5.59375,
      "grad_norm": 2.7351534366607666,
      "learning_rate": 4.4078125e-06,
      "loss": 0.7475,
      "step": 3580
    },
    {
      "epoch": 5.609375,
      "grad_norm": 2.264000654220581,
      "learning_rate": 4.3921875e-06,
      "loss": 0.7343,
      "step": 3590
    },
    {
      "epoch": 5.625,
      "grad_norm": 2.731233835220337,
      "learning_rate": 4.3765625000000005e-06,
      "loss": 0.8082,
      "step": 3600
    },
    {
      "epoch": 5.640625,
      "grad_norm": 3.044187068939209,
      "learning_rate": 4.3609375e-06,
      "loss": 0.7169,
      "step": 3610
    },
    {
      "epoch": 5.65625,
      "grad_norm": 3.2945220470428467,
      "learning_rate": 4.3453125e-06,
      "loss": 0.7675,
      "step": 3620
    },
    {
      "epoch": 5.671875,
      "grad_norm": 2.8680124282836914,
      "learning_rate": 4.3296875e-06,
      "loss": 0.881,
      "step": 3630
    },
    {
      "epoch": 5.6875,
      "grad_norm": 2.2698116302490234,
      "learning_rate": 4.314062500000001e-06,
      "loss": 0.8159,
      "step": 3640
    },
    {
      "epoch": 5.703125,
      "grad_norm": 2.640238046646118,
      "learning_rate": 4.2984375e-06,
      "loss": 0.7493,
      "step": 3650
    },
    {
      "epoch": 5.71875,
      "grad_norm": 3.1072027683258057,
      "learning_rate": 4.282812500000001e-06,
      "loss": 0.8306,
      "step": 3660
    },
    {
      "epoch": 5.734375,
      "grad_norm": 2.177800416946411,
      "learning_rate": 4.2671875e-06,
      "loss": 0.8246,
      "step": 3670
    },
    {
      "epoch": 5.75,
      "grad_norm": 3.2971982955932617,
      "learning_rate": 4.251562500000001e-06,
      "loss": 0.8405,
      "step": 3680
    },
    {
      "epoch": 5.765625,
      "grad_norm": 3.1494574546813965,
      "learning_rate": 4.2359375000000005e-06,
      "loss": 0.8957,
      "step": 3690
    },
    {
      "epoch": 5.78125,
      "grad_norm": 2.8524487018585205,
      "learning_rate": 4.220312500000001e-06,
      "loss": 0.8122,
      "step": 3700
    },
    {
      "epoch": 5.796875,
      "grad_norm": 2.9556961059570312,
      "learning_rate": 4.2046875000000006e-06,
      "loss": 0.7594,
      "step": 3710
    },
    {
      "epoch": 5.8125,
      "grad_norm": 2.636814832687378,
      "learning_rate": 4.1890625e-06,
      "loss": 0.8436,
      "step": 3720
    },
    {
      "epoch": 5.828125,
      "grad_norm": 2.4744772911071777,
      "learning_rate": 4.173437500000001e-06,
      "loss": 0.7693,
      "step": 3730
    },
    {
      "epoch": 5.84375,
      "grad_norm": 3.912405490875244,
      "learning_rate": 4.1578125e-06,
      "loss": 0.9025,
      "step": 3740
    },
    {
      "epoch": 5.859375,
      "grad_norm": 3.1390886306762695,
      "learning_rate": 4.142187500000001e-06,
      "loss": 0.8592,
      "step": 3750
    },
    {
      "epoch": 5.875,
      "grad_norm": 2.9881255626678467,
      "learning_rate": 4.1265625e-06,
      "loss": 0.7584,
      "step": 3760
    },
    {
      "epoch": 5.890625,
      "grad_norm": 3.0377097129821777,
      "learning_rate": 4.1109375e-06,
      "loss": 0.8329,
      "step": 3770
    },
    {
      "epoch": 5.90625,
      "grad_norm": 3.0824060440063477,
      "learning_rate": 4.0953125000000004e-06,
      "loss": 0.7893,
      "step": 3780
    },
    {
      "epoch": 5.921875,
      "grad_norm": 2.0671465396881104,
      "learning_rate": 4.0796875e-06,
      "loss": 0.7969,
      "step": 3790
    },
    {
      "epoch": 5.9375,
      "grad_norm": 2.521632194519043,
      "learning_rate": 4.0640625000000005e-06,
      "loss": 0.8145,
      "step": 3800
    },
    {
      "epoch": 5.953125,
      "grad_norm": 2.727780342102051,
      "learning_rate": 4.0484375e-06,
      "loss": 0.8081,
      "step": 3810
    },
    {
      "epoch": 5.96875,
      "grad_norm": 2.9246838092803955,
      "learning_rate": 4.0328125e-06,
      "loss": 0.8877,
      "step": 3820
    },
    {
      "epoch": 5.984375,
      "grad_norm": 3.3891255855560303,
      "learning_rate": 4.0171875e-06,
      "loss": 0.7578,
      "step": 3830
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.493436574935913,
      "learning_rate": 4.0015625e-06,
      "loss": 0.823,
      "step": 3840
    },
    {
      "epoch": 6.0,
      "eval_gen_len": 34.408849557522124,
      "eval_loss": 0.7505595088005066,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7291,
      "eval_samples_per_second": 4.132,
      "eval_steps_per_second": 0.263,
      "step": 3840
    },
    {
      "epoch": 6.015625,
      "grad_norm": 2.583700656890869,
      "learning_rate": 3.9859375e-06,
      "loss": 0.8116,
      "step": 3850
    },
    {
      "epoch": 6.03125,
      "grad_norm": 3.1590306758880615,
      "learning_rate": 3.9703125e-06,
      "loss": 0.8541,
      "step": 3860
    },
    {
      "epoch": 6.046875,
      "grad_norm": 2.312591314315796,
      "learning_rate": 3.9546875e-06,
      "loss": 0.7472,
      "step": 3870
    },
    {
      "epoch": 6.0625,
      "grad_norm": 2.5691158771514893,
      "learning_rate": 3.939062500000001e-06,
      "loss": 0.8282,
      "step": 3880
    },
    {
      "epoch": 6.078125,
      "grad_norm": 2.685398817062378,
      "learning_rate": 3.9234375000000005e-06,
      "loss": 0.769,
      "step": 3890
    },
    {
      "epoch": 6.09375,
      "grad_norm": 2.7118141651153564,
      "learning_rate": 3.907812500000001e-06,
      "loss": 0.749,
      "step": 3900
    },
    {
      "epoch": 6.109375,
      "grad_norm": 2.8635940551757812,
      "learning_rate": 3.892187500000001e-06,
      "loss": 0.7676,
      "step": 3910
    },
    {
      "epoch": 6.125,
      "grad_norm": 2.640360116958618,
      "learning_rate": 3.8765625e-06,
      "loss": 0.7044,
      "step": 3920
    },
    {
      "epoch": 6.140625,
      "grad_norm": 2.975996732711792,
      "learning_rate": 3.860937500000001e-06,
      "loss": 0.8201,
      "step": 3930
    },
    {
      "epoch": 6.15625,
      "grad_norm": 2.528895616531372,
      "learning_rate": 3.8453125e-06,
      "loss": 0.8279,
      "step": 3940
    },
    {
      "epoch": 6.171875,
      "grad_norm": 2.791569232940674,
      "learning_rate": 3.829687500000001e-06,
      "loss": 0.8281,
      "step": 3950
    },
    {
      "epoch": 6.1875,
      "grad_norm": 2.9588541984558105,
      "learning_rate": 3.8140625000000004e-06,
      "loss": 0.8214,
      "step": 3960
    },
    {
      "epoch": 6.203125,
      "grad_norm": 2.846008062362671,
      "learning_rate": 3.7984375e-06,
      "loss": 0.7735,
      "step": 3970
    },
    {
      "epoch": 6.21875,
      "grad_norm": 2.450345993041992,
      "learning_rate": 3.7828125000000005e-06,
      "loss": 0.8073,
      "step": 3980
    },
    {
      "epoch": 6.234375,
      "grad_norm": 2.4893031120300293,
      "learning_rate": 3.7671875e-06,
      "loss": 0.7781,
      "step": 3990
    },
    {
      "epoch": 6.25,
      "grad_norm": 3.058295726776123,
      "learning_rate": 3.7515625000000006e-06,
      "loss": 0.7601,
      "step": 4000
    },
    {
      "epoch": 6.265625,
      "grad_norm": 3.658991813659668,
      "learning_rate": 3.7359375e-06,
      "loss": 0.8607,
      "step": 4010
    },
    {
      "epoch": 6.28125,
      "grad_norm": 2.351132869720459,
      "learning_rate": 3.7203125000000002e-06,
      "loss": 0.8891,
      "step": 4020
    },
    {
      "epoch": 6.296875,
      "grad_norm": 3.0353305339813232,
      "learning_rate": 3.7046875000000003e-06,
      "loss": 0.8534,
      "step": 4030
    },
    {
      "epoch": 6.3125,
      "grad_norm": 3.158738374710083,
      "learning_rate": 3.6890625000000003e-06,
      "loss": 0.7746,
      "step": 4040
    },
    {
      "epoch": 6.328125,
      "grad_norm": 2.5199999809265137,
      "learning_rate": 3.6734375000000004e-06,
      "loss": 0.7645,
      "step": 4050
    },
    {
      "epoch": 6.34375,
      "grad_norm": 2.0580649375915527,
      "learning_rate": 3.6578125000000004e-06,
      "loss": 0.8346,
      "step": 4060
    },
    {
      "epoch": 6.359375,
      "grad_norm": 3.018824338912964,
      "learning_rate": 3.6421875e-06,
      "loss": 0.828,
      "step": 4070
    },
    {
      "epoch": 6.375,
      "grad_norm": 2.7889630794525146,
      "learning_rate": 3.6265625000000005e-06,
      "loss": 0.835,
      "step": 4080
    },
    {
      "epoch": 6.390625,
      "grad_norm": 2.3607289791107178,
      "learning_rate": 3.6109375e-06,
      "loss": 0.8292,
      "step": 4090
    },
    {
      "epoch": 6.40625,
      "grad_norm": 2.1485652923583984,
      "learning_rate": 3.5953125000000006e-06,
      "loss": 0.8103,
      "step": 4100
    },
    {
      "epoch": 6.421875,
      "grad_norm": 3.2928788661956787,
      "learning_rate": 3.5796875e-06,
      "loss": 0.7778,
      "step": 4110
    },
    {
      "epoch": 6.4375,
      "grad_norm": 3.1085660457611084,
      "learning_rate": 3.5640625000000002e-06,
      "loss": 0.848,
      "step": 4120
    },
    {
      "epoch": 6.453125,
      "grad_norm": 2.6082870960235596,
      "learning_rate": 3.5484375000000003e-06,
      "loss": 0.751,
      "step": 4130
    },
    {
      "epoch": 6.46875,
      "grad_norm": 3.107018232345581,
      "learning_rate": 3.5328125000000003e-06,
      "loss": 0.7086,
      "step": 4140
    },
    {
      "epoch": 6.484375,
      "grad_norm": 3.0464119911193848,
      "learning_rate": 3.5171875000000004e-06,
      "loss": 0.747,
      "step": 4150
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.2728257179260254,
      "learning_rate": 3.5015625000000004e-06,
      "loss": 0.7927,
      "step": 4160
    },
    {
      "epoch": 6.515625,
      "grad_norm": 2.552356243133545,
      "learning_rate": 3.4859375e-06,
      "loss": 0.808,
      "step": 4170
    },
    {
      "epoch": 6.53125,
      "grad_norm": 3.3750076293945312,
      "learning_rate": 3.4703125000000005e-06,
      "loss": 0.7871,
      "step": 4180
    },
    {
      "epoch": 6.546875,
      "grad_norm": 2.562718152999878,
      "learning_rate": 3.4546875e-06,
      "loss": 0.8371,
      "step": 4190
    },
    {
      "epoch": 6.5625,
      "grad_norm": 2.5227231979370117,
      "learning_rate": 3.4390625000000006e-06,
      "loss": 0.802,
      "step": 4200
    },
    {
      "epoch": 6.578125,
      "grad_norm": 2.475008964538574,
      "learning_rate": 3.4234375e-06,
      "loss": 0.8326,
      "step": 4210
    },
    {
      "epoch": 6.59375,
      "grad_norm": 2.7450225353240967,
      "learning_rate": 3.4078125000000002e-06,
      "loss": 0.8125,
      "step": 4220
    },
    {
      "epoch": 6.609375,
      "grad_norm": 3.3730967044830322,
      "learning_rate": 3.3921875000000003e-06,
      "loss": 0.7955,
      "step": 4230
    },
    {
      "epoch": 6.625,
      "grad_norm": 2.5482468605041504,
      "learning_rate": 3.3765625000000003e-06,
      "loss": 0.7985,
      "step": 4240
    },
    {
      "epoch": 6.640625,
      "grad_norm": 2.5031516551971436,
      "learning_rate": 3.3609375000000004e-06,
      "loss": 0.7538,
      "step": 4250
    },
    {
      "epoch": 6.65625,
      "grad_norm": 3.0917747020721436,
      "learning_rate": 3.3453125000000004e-06,
      "loss": 0.8625,
      "step": 4260
    },
    {
      "epoch": 6.671875,
      "grad_norm": 2.888101100921631,
      "learning_rate": 3.3296875e-06,
      "loss": 0.752,
      "step": 4270
    },
    {
      "epoch": 6.6875,
      "grad_norm": 2.7425754070281982,
      "learning_rate": 3.3140625000000005e-06,
      "loss": 0.8924,
      "step": 4280
    },
    {
      "epoch": 6.703125,
      "grad_norm": 2.8138978481292725,
      "learning_rate": 3.2984375e-06,
      "loss": 0.7944,
      "step": 4290
    },
    {
      "epoch": 6.71875,
      "grad_norm": 2.9056146144866943,
      "learning_rate": 3.2828125000000006e-06,
      "loss": 0.7627,
      "step": 4300
    },
    {
      "epoch": 6.734375,
      "grad_norm": 2.8020403385162354,
      "learning_rate": 3.2671875000000002e-06,
      "loss": 0.7941,
      "step": 4310
    },
    {
      "epoch": 6.75,
      "grad_norm": 2.785475254058838,
      "learning_rate": 3.2515625000000003e-06,
      "loss": 0.8337,
      "step": 4320
    },
    {
      "epoch": 6.765625,
      "grad_norm": 3.066441059112549,
      "learning_rate": 3.2359375000000003e-06,
      "loss": 0.796,
      "step": 4330
    },
    {
      "epoch": 6.78125,
      "grad_norm": 2.5067625045776367,
      "learning_rate": 3.2203125000000003e-06,
      "loss": 0.7495,
      "step": 4340
    },
    {
      "epoch": 6.796875,
      "grad_norm": 2.207988739013672,
      "learning_rate": 3.2046875000000004e-06,
      "loss": 0.8347,
      "step": 4350
    },
    {
      "epoch": 6.8125,
      "grad_norm": 3.192890167236328,
      "learning_rate": 3.1890625000000004e-06,
      "loss": 0.724,
      "step": 4360
    },
    {
      "epoch": 6.828125,
      "grad_norm": 2.7869479656219482,
      "learning_rate": 3.1734375e-06,
      "loss": 0.7139,
      "step": 4370
    },
    {
      "epoch": 6.84375,
      "grad_norm": 3.720885992050171,
      "learning_rate": 3.1578125000000005e-06,
      "loss": 0.8326,
      "step": 4380
    },
    {
      "epoch": 6.859375,
      "grad_norm": 2.3923394680023193,
      "learning_rate": 3.1421875e-06,
      "loss": 0.8402,
      "step": 4390
    },
    {
      "epoch": 6.875,
      "grad_norm": 2.7171790599823,
      "learning_rate": 3.1265625000000006e-06,
      "loss": 0.7892,
      "step": 4400
    },
    {
      "epoch": 6.890625,
      "grad_norm": 2.9197123050689697,
      "learning_rate": 3.1109375000000002e-06,
      "loss": 0.842,
      "step": 4410
    },
    {
      "epoch": 6.90625,
      "grad_norm": 2.9087650775909424,
      "learning_rate": 3.0953125e-06,
      "loss": 0.7767,
      "step": 4420
    },
    {
      "epoch": 6.921875,
      "grad_norm": 2.8248825073242188,
      "learning_rate": 3.0796875000000003e-06,
      "loss": 0.8025,
      "step": 4430
    },
    {
      "epoch": 6.9375,
      "grad_norm": 2.559723377227783,
      "learning_rate": 3.0640625000000004e-06,
      "loss": 0.7962,
      "step": 4440
    },
    {
      "epoch": 6.953125,
      "grad_norm": 2.97367262840271,
      "learning_rate": 3.0484375000000004e-06,
      "loss": 0.7497,
      "step": 4450
    },
    {
      "epoch": 6.96875,
      "grad_norm": 3.0996992588043213,
      "learning_rate": 3.0328125000000005e-06,
      "loss": 0.8734,
      "step": 4460
    },
    {
      "epoch": 6.984375,
      "grad_norm": 3.3365797996520996,
      "learning_rate": 3.0171875e-06,
      "loss": 0.739,
      "step": 4470
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.2580254077911377,
      "learning_rate": 3.0015625000000005e-06,
      "loss": 0.7751,
      "step": 4480
    },
    {
      "epoch": 7.0,
      "eval_gen_len": 33.98053097345133,
      "eval_loss": 0.747579038143158,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7401,
      "eval_samples_per_second": 4.132,
      "eval_steps_per_second": 0.263,
      "step": 4480
    },
    {
      "epoch": 7.015625,
      "grad_norm": 3.0888962745666504,
      "learning_rate": 2.9859375e-06,
      "loss": 0.7631,
      "step": 4490
    },
    {
      "epoch": 7.03125,
      "grad_norm": 3.0575060844421387,
      "learning_rate": 2.9703125000000006e-06,
      "loss": 0.8334,
      "step": 4500
    },
    {
      "epoch": 7.046875,
      "grad_norm": 3.2613301277160645,
      "learning_rate": 2.9546875000000002e-06,
      "loss": 0.7109,
      "step": 4510
    },
    {
      "epoch": 7.0625,
      "grad_norm": 2.6085214614868164,
      "learning_rate": 2.9390625e-06,
      "loss": 0.8098,
      "step": 4520
    },
    {
      "epoch": 7.078125,
      "grad_norm": 2.524714708328247,
      "learning_rate": 2.9234375000000003e-06,
      "loss": 0.6497,
      "step": 4530
    },
    {
      "epoch": 7.09375,
      "grad_norm": 2.7143001556396484,
      "learning_rate": 2.9078125e-06,
      "loss": 0.8001,
      "step": 4540
    },
    {
      "epoch": 7.109375,
      "grad_norm": 2.6630101203918457,
      "learning_rate": 2.8921875000000004e-06,
      "loss": 0.675,
      "step": 4550
    },
    {
      "epoch": 7.125,
      "grad_norm": 2.2881314754486084,
      "learning_rate": 2.8765625000000005e-06,
      "loss": 0.7815,
      "step": 4560
    },
    {
      "epoch": 7.140625,
      "grad_norm": 2.4080538749694824,
      "learning_rate": 2.8609375e-06,
      "loss": 0.7504,
      "step": 4570
    },
    {
      "epoch": 7.15625,
      "grad_norm": 2.5864317417144775,
      "learning_rate": 2.8453125000000006e-06,
      "loss": 0.8253,
      "step": 4580
    },
    {
      "epoch": 7.171875,
      "grad_norm": 2.5848844051361084,
      "learning_rate": 2.8296875e-06,
      "loss": 0.7868,
      "step": 4590
    },
    {
      "epoch": 7.1875,
      "grad_norm": 2.7180819511413574,
      "learning_rate": 2.8140625000000006e-06,
      "loss": 0.8021,
      "step": 4600
    },
    {
      "epoch": 7.203125,
      "grad_norm": 3.654876947402954,
      "learning_rate": 2.7984375000000003e-06,
      "loss": 0.7747,
      "step": 4610
    },
    {
      "epoch": 7.21875,
      "grad_norm": 2.930325746536255,
      "learning_rate": 2.7828125e-06,
      "loss": 0.8664,
      "step": 4620
    },
    {
      "epoch": 7.234375,
      "grad_norm": 2.704735517501831,
      "learning_rate": 2.7671875000000003e-06,
      "loss": 0.8709,
      "step": 4630
    },
    {
      "epoch": 7.25,
      "grad_norm": 2.349513530731201,
      "learning_rate": 2.7515625e-06,
      "loss": 0.695,
      "step": 4640
    },
    {
      "epoch": 7.265625,
      "grad_norm": 2.675241708755493,
      "learning_rate": 2.7359375000000004e-06,
      "loss": 0.7692,
      "step": 4650
    },
    {
      "epoch": 7.28125,
      "grad_norm": 2.5986008644104004,
      "learning_rate": 2.7203125e-06,
      "loss": 0.7891,
      "step": 4660
    },
    {
      "epoch": 7.296875,
      "grad_norm": 2.8394501209259033,
      "learning_rate": 2.7046875e-06,
      "loss": 0.8603,
      "step": 4670
    },
    {
      "epoch": 7.3125,
      "grad_norm": 3.086785078048706,
      "learning_rate": 2.6890625000000006e-06,
      "loss": 0.7994,
      "step": 4680
    },
    {
      "epoch": 7.328125,
      "grad_norm": 2.6413421630859375,
      "learning_rate": 2.6734375e-06,
      "loss": 0.7687,
      "step": 4690
    },
    {
      "epoch": 7.34375,
      "grad_norm": 2.628194808959961,
      "learning_rate": 2.6578125000000007e-06,
      "loss": 0.7368,
      "step": 4700
    },
    {
      "epoch": 7.359375,
      "grad_norm": 2.8603358268737793,
      "learning_rate": 2.6421875000000003e-06,
      "loss": 0.8674,
      "step": 4710
    },
    {
      "epoch": 7.375,
      "grad_norm": 2.4225270748138428,
      "learning_rate": 2.6265625e-06,
      "loss": 0.7556,
      "step": 4720
    },
    {
      "epoch": 7.390625,
      "grad_norm": 4.262733459472656,
      "learning_rate": 2.6109375000000004e-06,
      "loss": 0.7594,
      "step": 4730
    },
    {
      "epoch": 7.40625,
      "grad_norm": 4.165572643280029,
      "learning_rate": 2.5953125e-06,
      "loss": 0.8113,
      "step": 4740
    },
    {
      "epoch": 7.421875,
      "grad_norm": 3.6043295860290527,
      "learning_rate": 2.5796875000000004e-06,
      "loss": 0.8263,
      "step": 4750
    },
    {
      "epoch": 7.4375,
      "grad_norm": 3.0167903900146484,
      "learning_rate": 2.5640625e-06,
      "loss": 0.7987,
      "step": 4760
    },
    {
      "epoch": 7.453125,
      "grad_norm": 2.856879472732544,
      "learning_rate": 2.5484375e-06,
      "loss": 0.7872,
      "step": 4770
    },
    {
      "epoch": 7.46875,
      "grad_norm": 2.8900184631347656,
      "learning_rate": 2.5328125e-06,
      "loss": 0.8272,
      "step": 4780
    },
    {
      "epoch": 7.484375,
      "grad_norm": 2.4830174446105957,
      "learning_rate": 2.5171875e-06,
      "loss": 0.7131,
      "step": 4790
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.072763442993164,
      "learning_rate": 2.5015625000000002e-06,
      "loss": 0.8692,
      "step": 4800
    },
    {
      "epoch": 7.515625,
      "grad_norm": 2.283705949783325,
      "learning_rate": 2.4859375000000003e-06,
      "loss": 0.7307,
      "step": 4810
    },
    {
      "epoch": 7.53125,
      "grad_norm": 2.2535977363586426,
      "learning_rate": 2.4703125000000003e-06,
      "loss": 0.7515,
      "step": 4820
    },
    {
      "epoch": 7.546875,
      "grad_norm": 2.796689748764038,
      "learning_rate": 2.4546875000000004e-06,
      "loss": 0.7672,
      "step": 4830
    },
    {
      "epoch": 7.5625,
      "grad_norm": 2.6910080909729004,
      "learning_rate": 2.4390625e-06,
      "loss": 0.7694,
      "step": 4840
    },
    {
      "epoch": 7.578125,
      "grad_norm": 2.7815232276916504,
      "learning_rate": 2.4234375e-06,
      "loss": 0.8185,
      "step": 4850
    },
    {
      "epoch": 7.59375,
      "grad_norm": 2.350102424621582,
      "learning_rate": 2.4078125e-06,
      "loss": 0.8113,
      "step": 4860
    },
    {
      "epoch": 7.609375,
      "grad_norm": 3.1217880249023438,
      "learning_rate": 2.3921875e-06,
      "loss": 0.7969,
      "step": 4870
    },
    {
      "epoch": 7.625,
      "grad_norm": 2.959057569503784,
      "learning_rate": 2.3765625e-06,
      "loss": 0.8261,
      "step": 4880
    },
    {
      "epoch": 7.640625,
      "grad_norm": 3.0838325023651123,
      "learning_rate": 2.3609375000000002e-06,
      "loss": 0.7892,
      "step": 4890
    },
    {
      "epoch": 7.65625,
      "grad_norm": 2.866570472717285,
      "learning_rate": 2.3453125000000003e-06,
      "loss": 0.7515,
      "step": 4900
    },
    {
      "epoch": 7.671875,
      "grad_norm": 2.6709258556365967,
      "learning_rate": 2.3296875000000003e-06,
      "loss": 0.8113,
      "step": 4910
    },
    {
      "epoch": 7.6875,
      "grad_norm": 2.5975422859191895,
      "learning_rate": 2.3140625000000003e-06,
      "loss": 0.764,
      "step": 4920
    },
    {
      "epoch": 7.703125,
      "grad_norm": 2.455249309539795,
      "learning_rate": 2.2984375000000004e-06,
      "loss": 0.7434,
      "step": 4930
    },
    {
      "epoch": 7.71875,
      "grad_norm": 2.8448128700256348,
      "learning_rate": 2.2828125e-06,
      "loss": 0.7973,
      "step": 4940
    },
    {
      "epoch": 7.734375,
      "grad_norm": 2.480184316635132,
      "learning_rate": 2.2671875e-06,
      "loss": 0.8195,
      "step": 4950
    },
    {
      "epoch": 7.75,
      "grad_norm": 2.4280648231506348,
      "learning_rate": 2.2515625e-06,
      "loss": 0.7227,
      "step": 4960
    },
    {
      "epoch": 7.765625,
      "grad_norm": 3.3362958431243896,
      "learning_rate": 2.2359375e-06,
      "loss": 0.8835,
      "step": 4970
    },
    {
      "epoch": 7.78125,
      "grad_norm": 2.472280979156494,
      "learning_rate": 2.2203125e-06,
      "loss": 0.8717,
      "step": 4980
    },
    {
      "epoch": 7.796875,
      "grad_norm": 3.7401366233825684,
      "learning_rate": 2.2046875000000002e-06,
      "loss": 0.7841,
      "step": 4990
    },
    {
      "epoch": 7.8125,
      "grad_norm": 3.108670473098755,
      "learning_rate": 2.1890625000000003e-06,
      "loss": 0.7814,
      "step": 5000
    },
    {
      "epoch": 7.828125,
      "grad_norm": 2.776508331298828,
      "learning_rate": 2.1734375000000003e-06,
      "loss": 0.7808,
      "step": 5010
    },
    {
      "epoch": 7.84375,
      "grad_norm": 2.0184788703918457,
      "learning_rate": 2.1578125000000004e-06,
      "loss": 0.7411,
      "step": 5020
    },
    {
      "epoch": 7.859375,
      "grad_norm": 3.501685619354248,
      "learning_rate": 2.1421875000000004e-06,
      "loss": 0.8199,
      "step": 5030
    },
    {
      "epoch": 7.875,
      "grad_norm": 2.6417112350463867,
      "learning_rate": 2.1265625e-06,
      "loss": 0.8088,
      "step": 5040
    },
    {
      "epoch": 7.890625,
      "grad_norm": 2.310300827026367,
      "learning_rate": 2.1109375e-06,
      "loss": 0.7708,
      "step": 5050
    },
    {
      "epoch": 7.90625,
      "grad_norm": 3.402578830718994,
      "learning_rate": 2.0953125e-06,
      "loss": 0.8261,
      "step": 5060
    },
    {
      "epoch": 7.921875,
      "grad_norm": 3.4039101600646973,
      "learning_rate": 2.0796875e-06,
      "loss": 0.7472,
      "step": 5070
    },
    {
      "epoch": 7.9375,
      "grad_norm": 2.6153483390808105,
      "learning_rate": 2.0640625e-06,
      "loss": 0.7908,
      "step": 5080
    },
    {
      "epoch": 7.953125,
      "grad_norm": 2.61311411857605,
      "learning_rate": 2.0484375000000002e-06,
      "loss": 0.7247,
      "step": 5090
    },
    {
      "epoch": 7.96875,
      "grad_norm": 2.3363218307495117,
      "learning_rate": 2.0328125000000003e-06,
      "loss": 0.7745,
      "step": 5100
    },
    {
      "epoch": 7.984375,
      "grad_norm": 3.7854232788085938,
      "learning_rate": 2.0171875000000003e-06,
      "loss": 0.8248,
      "step": 5110
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.275526523590088,
      "learning_rate": 2.0015625000000004e-06,
      "loss": 0.7584,
      "step": 5120
    },
    {
      "epoch": 8.0,
      "eval_gen_len": 34.054867256637166,
      "eval_loss": 0.7385391592979431,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7576,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 5120
    },
    {
      "epoch": 8.015625,
      "grad_norm": 2.6527044773101807,
      "learning_rate": 1.9859375000000004e-06,
      "loss": 0.7085,
      "step": 5130
    },
    {
      "epoch": 8.03125,
      "grad_norm": 2.813284397125244,
      "learning_rate": 1.9703125e-06,
      "loss": 0.7777,
      "step": 5140
    },
    {
      "epoch": 8.046875,
      "grad_norm": 2.7735824584960938,
      "learning_rate": 1.9546875e-06,
      "loss": 0.8198,
      "step": 5150
    },
    {
      "epoch": 8.0625,
      "grad_norm": 2.3561253547668457,
      "learning_rate": 1.9390625e-06,
      "loss": 0.7678,
      "step": 5160
    },
    {
      "epoch": 8.078125,
      "grad_norm": 2.744933605194092,
      "learning_rate": 1.9234375e-06,
      "loss": 0.7659,
      "step": 5170
    },
    {
      "epoch": 8.09375,
      "grad_norm": 5.059806823730469,
      "learning_rate": 1.9078125e-06,
      "loss": 0.7753,
      "step": 5180
    },
    {
      "epoch": 8.109375,
      "grad_norm": 2.9304049015045166,
      "learning_rate": 1.8921875e-06,
      "loss": 0.743,
      "step": 5190
    },
    {
      "epoch": 8.125,
      "grad_norm": 2.6472809314727783,
      "learning_rate": 1.8765625e-06,
      "loss": 0.7921,
      "step": 5200
    },
    {
      "epoch": 8.140625,
      "grad_norm": 2.5267672538757324,
      "learning_rate": 1.8609375000000001e-06,
      "loss": 0.8524,
      "step": 5210
    },
    {
      "epoch": 8.15625,
      "grad_norm": 3.686776638031006,
      "learning_rate": 1.8453125000000002e-06,
      "loss": 0.7251,
      "step": 5220
    },
    {
      "epoch": 8.171875,
      "grad_norm": 3.1398653984069824,
      "learning_rate": 1.8296875000000002e-06,
      "loss": 0.8162,
      "step": 5230
    },
    {
      "epoch": 8.1875,
      "grad_norm": 2.222506284713745,
      "learning_rate": 1.8140625e-06,
      "loss": 0.8514,
      "step": 5240
    },
    {
      "epoch": 8.203125,
      "grad_norm": 3.2037572860717773,
      "learning_rate": 1.7984375e-06,
      "loss": 0.8476,
      "step": 5250
    },
    {
      "epoch": 8.21875,
      "grad_norm": 2.5269641876220703,
      "learning_rate": 1.7828125000000001e-06,
      "loss": 0.8346,
      "step": 5260
    },
    {
      "epoch": 8.234375,
      "grad_norm": 2.1208138465881348,
      "learning_rate": 1.7671875000000002e-06,
      "loss": 0.7702,
      "step": 5270
    },
    {
      "epoch": 8.25,
      "grad_norm": 2.9300220012664795,
      "learning_rate": 1.7515625000000002e-06,
      "loss": 0.7586,
      "step": 5280
    },
    {
      "epoch": 8.265625,
      "grad_norm": 2.352041006088257,
      "learning_rate": 1.7359375e-06,
      "loss": 0.7849,
      "step": 5290
    },
    {
      "epoch": 8.28125,
      "grad_norm": 3.0321106910705566,
      "learning_rate": 1.7203125e-06,
      "loss": 0.7964,
      "step": 5300
    },
    {
      "epoch": 8.296875,
      "grad_norm": 4.320094585418701,
      "learning_rate": 1.7046875000000001e-06,
      "loss": 0.8186,
      "step": 5310
    },
    {
      "epoch": 8.3125,
      "grad_norm": 3.4712202548980713,
      "learning_rate": 1.6890625000000002e-06,
      "loss": 0.7613,
      "step": 5320
    },
    {
      "epoch": 8.328125,
      "grad_norm": 3.1195778846740723,
      "learning_rate": 1.6734375000000002e-06,
      "loss": 0.7981,
      "step": 5330
    },
    {
      "epoch": 8.34375,
      "grad_norm": 2.57951283454895,
      "learning_rate": 1.6578125e-06,
      "loss": 0.7727,
      "step": 5340
    },
    {
      "epoch": 8.359375,
      "grad_norm": 3.1354100704193115,
      "learning_rate": 1.6421875000000001e-06,
      "loss": 0.817,
      "step": 5350
    },
    {
      "epoch": 8.375,
      "grad_norm": 2.7760143280029297,
      "learning_rate": 1.6265625000000001e-06,
      "loss": 0.7693,
      "step": 5360
    },
    {
      "epoch": 8.390625,
      "grad_norm": 2.4868662357330322,
      "learning_rate": 1.6109375000000002e-06,
      "loss": 0.772,
      "step": 5370
    },
    {
      "epoch": 8.40625,
      "grad_norm": 2.853919267654419,
      "learning_rate": 1.5953125000000002e-06,
      "loss": 0.6828,
      "step": 5380
    },
    {
      "epoch": 8.421875,
      "grad_norm": 2.4942452907562256,
      "learning_rate": 1.5796875e-06,
      "loss": 0.746,
      "step": 5390
    },
    {
      "epoch": 8.4375,
      "grad_norm": 2.9518094062805176,
      "learning_rate": 1.5640625000000001e-06,
      "loss": 0.8195,
      "step": 5400
    },
    {
      "epoch": 8.453125,
      "grad_norm": 2.0918028354644775,
      "learning_rate": 1.5484375000000002e-06,
      "loss": 0.7907,
      "step": 5410
    },
    {
      "epoch": 8.46875,
      "grad_norm": 3.416642904281616,
      "learning_rate": 1.5328125000000002e-06,
      "loss": 0.793,
      "step": 5420
    },
    {
      "epoch": 8.484375,
      "grad_norm": 2.5268962383270264,
      "learning_rate": 1.5171875000000002e-06,
      "loss": 0.7912,
      "step": 5430
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.375182628631592,
      "learning_rate": 1.5015625e-06,
      "loss": 0.7475,
      "step": 5440
    },
    {
      "epoch": 8.515625,
      "grad_norm": 2.4278483390808105,
      "learning_rate": 1.4859375000000001e-06,
      "loss": 0.7341,
      "step": 5450
    },
    {
      "epoch": 8.53125,
      "grad_norm": 2.1462793350219727,
      "learning_rate": 1.4703125000000002e-06,
      "loss": 0.7778,
      "step": 5460
    },
    {
      "epoch": 8.546875,
      "grad_norm": 2.427478551864624,
      "learning_rate": 1.4546875000000002e-06,
      "loss": 0.7561,
      "step": 5470
    },
    {
      "epoch": 8.5625,
      "grad_norm": 2.2676281929016113,
      "learning_rate": 1.4390625000000003e-06,
      "loss": 0.7922,
      "step": 5480
    },
    {
      "epoch": 8.578125,
      "grad_norm": 2.7353639602661133,
      "learning_rate": 1.4234375e-06,
      "loss": 0.7642,
      "step": 5490
    },
    {
      "epoch": 8.59375,
      "grad_norm": 3.0794522762298584,
      "learning_rate": 1.4078125000000001e-06,
      "loss": 0.8316,
      "step": 5500
    },
    {
      "epoch": 8.609375,
      "grad_norm": 2.770841598510742,
      "learning_rate": 1.3921875000000002e-06,
      "loss": 0.8227,
      "step": 5510
    },
    {
      "epoch": 8.625,
      "grad_norm": 2.5818207263946533,
      "learning_rate": 1.3765625000000002e-06,
      "loss": 0.7222,
      "step": 5520
    },
    {
      "epoch": 8.640625,
      "grad_norm": 3.237973690032959,
      "learning_rate": 1.3609375000000003e-06,
      "loss": 0.7929,
      "step": 5530
    },
    {
      "epoch": 8.65625,
      "grad_norm": 2.5689756870269775,
      "learning_rate": 1.3453125e-06,
      "loss": 0.7248,
      "step": 5540
    },
    {
      "epoch": 8.671875,
      "grad_norm": 2.381561517715454,
      "learning_rate": 1.3296875000000001e-06,
      "loss": 0.787,
      "step": 5550
    },
    {
      "epoch": 8.6875,
      "grad_norm": 2.2918593883514404,
      "learning_rate": 1.3140625000000002e-06,
      "loss": 0.7727,
      "step": 5560
    },
    {
      "epoch": 8.703125,
      "grad_norm": 2.4428584575653076,
      "learning_rate": 1.2984375000000002e-06,
      "loss": 0.7519,
      "step": 5570
    },
    {
      "epoch": 8.71875,
      "grad_norm": 2.775190830230713,
      "learning_rate": 1.2828125000000003e-06,
      "loss": 0.7607,
      "step": 5580
    },
    {
      "epoch": 8.734375,
      "grad_norm": 2.980806350708008,
      "learning_rate": 1.2671875e-06,
      "loss": 0.8342,
      "step": 5590
    },
    {
      "epoch": 8.75,
      "grad_norm": 2.494868516921997,
      "learning_rate": 1.2515625000000001e-06,
      "loss": 0.7999,
      "step": 5600
    },
    {
      "epoch": 8.765625,
      "grad_norm": 2.9585518836975098,
      "learning_rate": 1.2359375000000002e-06,
      "loss": 0.7686,
      "step": 5610
    },
    {
      "epoch": 8.78125,
      "grad_norm": 2.4631755352020264,
      "learning_rate": 1.2203125e-06,
      "loss": 0.8495,
      "step": 5620
    },
    {
      "epoch": 8.796875,
      "grad_norm": 2.4335649013519287,
      "learning_rate": 1.2046875e-06,
      "loss": 0.7994,
      "step": 5630
    },
    {
      "epoch": 8.8125,
      "grad_norm": 3.4101126194000244,
      "learning_rate": 1.1890625e-06,
      "loss": 0.7074,
      "step": 5640
    },
    {
      "epoch": 8.828125,
      "grad_norm": 2.709172010421753,
      "learning_rate": 1.1734375000000001e-06,
      "loss": 0.67,
      "step": 5650
    },
    {
      "epoch": 8.84375,
      "grad_norm": 2.5873541831970215,
      "learning_rate": 1.1578125000000002e-06,
      "loss": 0.8536,
      "step": 5660
    },
    {
      "epoch": 8.859375,
      "grad_norm": 3.1506378650665283,
      "learning_rate": 1.1421875e-06,
      "loss": 0.7382,
      "step": 5670
    },
    {
      "epoch": 8.875,
      "grad_norm": 2.715820550918579,
      "learning_rate": 1.1265625e-06,
      "loss": 0.8555,
      "step": 5680
    },
    {
      "epoch": 8.890625,
      "grad_norm": 2.5137178897857666,
      "learning_rate": 1.1109375000000001e-06,
      "loss": 0.7803,
      "step": 5690
    },
    {
      "epoch": 8.90625,
      "grad_norm": 2.88106369972229,
      "learning_rate": 1.0953125000000002e-06,
      "loss": 0.6821,
      "step": 5700
    },
    {
      "epoch": 8.921875,
      "grad_norm": 3.074420928955078,
      "learning_rate": 1.0796875000000002e-06,
      "loss": 0.7897,
      "step": 5710
    },
    {
      "epoch": 8.9375,
      "grad_norm": 2.5477168560028076,
      "learning_rate": 1.0640625e-06,
      "loss": 0.7322,
      "step": 5720
    },
    {
      "epoch": 8.953125,
      "grad_norm": 3.2484793663024902,
      "learning_rate": 1.0484375e-06,
      "loss": 0.8802,
      "step": 5730
    },
    {
      "epoch": 8.96875,
      "grad_norm": 2.916710138320923,
      "learning_rate": 1.0328125000000001e-06,
      "loss": 0.7638,
      "step": 5740
    },
    {
      "epoch": 8.984375,
      "grad_norm": 2.886545181274414,
      "learning_rate": 1.0171875e-06,
      "loss": 0.7721,
      "step": 5750
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.3712027072906494,
      "learning_rate": 1.0015625000000002e-06,
      "loss": 0.7109,
      "step": 5760
    },
    {
      "epoch": 9.0,
      "eval_gen_len": 34.10973451327433,
      "eval_loss": 0.7362191677093506,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7855,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 5760
    },
    {
      "epoch": 9.015625,
      "grad_norm": 2.4656362533569336,
      "learning_rate": 9.859375e-07,
      "loss": 0.7802,
      "step": 5770
    },
    {
      "epoch": 9.03125,
      "grad_norm": 3.403615951538086,
      "learning_rate": 9.703125e-07,
      "loss": 0.8513,
      "step": 5780
    },
    {
      "epoch": 9.046875,
      "grad_norm": 3.073643445968628,
      "learning_rate": 9.546875000000001e-07,
      "loss": 0.7453,
      "step": 5790
    },
    {
      "epoch": 9.0625,
      "grad_norm": 2.774031639099121,
      "learning_rate": 9.390625000000001e-07,
      "loss": 0.785,
      "step": 5800
    },
    {
      "epoch": 9.078125,
      "grad_norm": 2.8038039207458496,
      "learning_rate": 9.234375000000001e-07,
      "loss": 0.7072,
      "step": 5810
    },
    {
      "epoch": 9.09375,
      "grad_norm": 2.9044101238250732,
      "learning_rate": 9.078125e-07,
      "loss": 0.7246,
      "step": 5820
    },
    {
      "epoch": 9.109375,
      "grad_norm": 2.7873430252075195,
      "learning_rate": 8.921875000000001e-07,
      "loss": 0.7849,
      "step": 5830
    },
    {
      "epoch": 9.125,
      "grad_norm": 2.5122268199920654,
      "learning_rate": 8.765625000000001e-07,
      "loss": 0.7587,
      "step": 5840
    },
    {
      "epoch": 9.140625,
      "grad_norm": 2.779384136199951,
      "learning_rate": 8.609375000000001e-07,
      "loss": 0.7845,
      "step": 5850
    },
    {
      "epoch": 9.15625,
      "grad_norm": 2.151966094970703,
      "learning_rate": 8.453125000000001e-07,
      "loss": 0.7816,
      "step": 5860
    },
    {
      "epoch": 9.171875,
      "grad_norm": 3.2705442905426025,
      "learning_rate": 8.296875e-07,
      "loss": 0.7791,
      "step": 5870
    },
    {
      "epoch": 9.1875,
      "grad_norm": 2.7694692611694336,
      "learning_rate": 8.140625000000001e-07,
      "loss": 0.7352,
      "step": 5880
    },
    {
      "epoch": 9.203125,
      "grad_norm": 3.385457754135132,
      "learning_rate": 7.984375000000001e-07,
      "loss": 0.8201,
      "step": 5890
    },
    {
      "epoch": 9.21875,
      "grad_norm": 4.977380752563477,
      "learning_rate": 7.828125000000001e-07,
      "loss": 0.9023,
      "step": 5900
    },
    {
      "epoch": 9.234375,
      "grad_norm": 2.0040252208709717,
      "learning_rate": 7.671875000000001e-07,
      "loss": 0.7497,
      "step": 5910
    },
    {
      "epoch": 9.25,
      "grad_norm": 3.578376293182373,
      "learning_rate": 7.515625e-07,
      "loss": 0.8121,
      "step": 5920
    },
    {
      "epoch": 9.265625,
      "grad_norm": 3.016551971435547,
      "learning_rate": 7.359375000000001e-07,
      "loss": 0.7614,
      "step": 5930
    },
    {
      "epoch": 9.28125,
      "grad_norm": 2.6800854206085205,
      "learning_rate": 7.203125000000001e-07,
      "loss": 0.8624,
      "step": 5940
    },
    {
      "epoch": 9.296875,
      "grad_norm": 3.357008457183838,
      "learning_rate": 7.046875e-07,
      "loss": 0.7218,
      "step": 5950
    },
    {
      "epoch": 9.3125,
      "grad_norm": 2.134024143218994,
      "learning_rate": 6.890625000000001e-07,
      "loss": 0.7484,
      "step": 5960
    },
    {
      "epoch": 9.328125,
      "grad_norm": 2.3592898845672607,
      "learning_rate": 6.734375e-07,
      "loss": 0.8151,
      "step": 5970
    },
    {
      "epoch": 9.34375,
      "grad_norm": 2.9227077960968018,
      "learning_rate": 6.578125e-07,
      "loss": 0.7235,
      "step": 5980
    },
    {
      "epoch": 9.359375,
      "grad_norm": 3.169830322265625,
      "learning_rate": 6.421875000000002e-07,
      "loss": 0.8168,
      "step": 5990
    },
    {
      "epoch": 9.375,
      "grad_norm": 2.757185220718384,
      "learning_rate": 6.265625e-07,
      "loss": 0.7336,
      "step": 6000
    },
    {
      "epoch": 9.390625,
      "grad_norm": 2.8790762424468994,
      "learning_rate": 6.109375e-07,
      "loss": 0.717,
      "step": 6010
    },
    {
      "epoch": 9.40625,
      "grad_norm": 2.7323062419891357,
      "learning_rate": 5.953125000000001e-07,
      "loss": 0.8341,
      "step": 6020
    },
    {
      "epoch": 9.421875,
      "grad_norm": 2.9720816612243652,
      "learning_rate": 5.796875e-07,
      "loss": 0.8102,
      "step": 6030
    },
    {
      "epoch": 9.4375,
      "grad_norm": 2.0911076068878174,
      "learning_rate": 5.640625e-07,
      "loss": 0.756,
      "step": 6040
    },
    {
      "epoch": 9.453125,
      "grad_norm": 2.824882745742798,
      "learning_rate": 5.484375e-07,
      "loss": 0.69,
      "step": 6050
    },
    {
      "epoch": 9.46875,
      "grad_norm": 2.868283987045288,
      "learning_rate": 5.328125e-07,
      "loss": 0.7275,
      "step": 6060
    },
    {
      "epoch": 9.484375,
      "grad_norm": 2.621896743774414,
      "learning_rate": 5.171875000000001e-07,
      "loss": 0.7116,
      "step": 6070
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.84016752243042,
      "learning_rate": 5.015625e-07,
      "loss": 0.7417,
      "step": 6080
    },
    {
      "epoch": 9.515625,
      "grad_norm": 3.6107406616210938,
      "learning_rate": 4.859375000000001e-07,
      "loss": 0.8218,
      "step": 6090
    },
    {
      "epoch": 9.53125,
      "grad_norm": 2.578209400177002,
      "learning_rate": 4.703125e-07,
      "loss": 0.7106,
      "step": 6100
    },
    {
      "epoch": 9.546875,
      "grad_norm": 2.7850844860076904,
      "learning_rate": 4.5468750000000004e-07,
      "loss": 0.7449,
      "step": 6110
    },
    {
      "epoch": 9.5625,
      "grad_norm": 2.341447114944458,
      "learning_rate": 4.3906250000000003e-07,
      "loss": 0.8649,
      "step": 6120
    },
    {
      "epoch": 9.578125,
      "grad_norm": 3.1630523204803467,
      "learning_rate": 4.234375e-07,
      "loss": 0.816,
      "step": 6130
    },
    {
      "epoch": 9.59375,
      "grad_norm": 3.06838321685791,
      "learning_rate": 4.078125e-07,
      "loss": 0.8211,
      "step": 6140
    },
    {
      "epoch": 9.609375,
      "grad_norm": 3.8238346576690674,
      "learning_rate": 3.921875e-07,
      "loss": 0.7197,
      "step": 6150
    },
    {
      "epoch": 9.625,
      "grad_norm": 2.6927638053894043,
      "learning_rate": 3.7656250000000005e-07,
      "loss": 0.7451,
      "step": 6160
    },
    {
      "epoch": 9.640625,
      "grad_norm": 2.6443514823913574,
      "learning_rate": 3.6093750000000004e-07,
      "loss": 0.8082,
      "step": 6170
    },
    {
      "epoch": 9.65625,
      "grad_norm": 2.837653398513794,
      "learning_rate": 3.4531250000000003e-07,
      "loss": 0.7385,
      "step": 6180
    },
    {
      "epoch": 9.671875,
      "grad_norm": 3.1295483112335205,
      "learning_rate": 3.296875e-07,
      "loss": 0.8316,
      "step": 6190
    },
    {
      "epoch": 9.6875,
      "grad_norm": 2.916923999786377,
      "learning_rate": 3.140625e-07,
      "loss": 0.7517,
      "step": 6200
    },
    {
      "epoch": 9.703125,
      "grad_norm": 2.794879913330078,
      "learning_rate": 2.984375e-07,
      "loss": 0.7123,
      "step": 6210
    },
    {
      "epoch": 9.71875,
      "grad_norm": 3.082508087158203,
      "learning_rate": 2.8281250000000005e-07,
      "loss": 0.7835,
      "step": 6220
    },
    {
      "epoch": 9.734375,
      "grad_norm": 2.741098403930664,
      "learning_rate": 2.6718750000000004e-07,
      "loss": 0.8477,
      "step": 6230
    },
    {
      "epoch": 9.75,
      "grad_norm": 2.4519171714782715,
      "learning_rate": 2.5156250000000003e-07,
      "loss": 0.7876,
      "step": 6240
    },
    {
      "epoch": 9.765625,
      "grad_norm": 2.4999043941497803,
      "learning_rate": 2.3593750000000002e-07,
      "loss": 0.8067,
      "step": 6250
    },
    {
      "epoch": 9.78125,
      "grad_norm": 2.473257541656494,
      "learning_rate": 2.203125e-07,
      "loss": 0.759,
      "step": 6260
    },
    {
      "epoch": 9.796875,
      "grad_norm": 3.285137176513672,
      "learning_rate": 2.0468750000000003e-07,
      "loss": 0.796,
      "step": 6270
    },
    {
      "epoch": 9.8125,
      "grad_norm": 2.534797430038452,
      "learning_rate": 1.8906250000000002e-07,
      "loss": 0.7919,
      "step": 6280
    },
    {
      "epoch": 9.828125,
      "grad_norm": 2.821101188659668,
      "learning_rate": 1.7343750000000003e-07,
      "loss": 0.7695,
      "step": 6290
    },
    {
      "epoch": 9.84375,
      "grad_norm": 2.7993767261505127,
      "learning_rate": 1.5781250000000002e-07,
      "loss": 0.8787,
      "step": 6300
    },
    {
      "epoch": 9.859375,
      "grad_norm": 3.643242120742798,
      "learning_rate": 1.4218750000000002e-07,
      "loss": 0.7681,
      "step": 6310
    },
    {
      "epoch": 9.875,
      "grad_norm": 2.673349380493164,
      "learning_rate": 1.265625e-07,
      "loss": 0.788,
      "step": 6320
    },
    {
      "epoch": 9.890625,
      "grad_norm": 3.3601558208465576,
      "learning_rate": 1.1093750000000001e-07,
      "loss": 0.7296,
      "step": 6330
    },
    {
      "epoch": 9.90625,
      "grad_norm": 2.582909345626831,
      "learning_rate": 9.53125e-08,
      "loss": 0.7362,
      "step": 6340
    },
    {
      "epoch": 9.921875,
      "grad_norm": 1.9862533807754517,
      "learning_rate": 7.96875e-08,
      "loss": 0.6989,
      "step": 6350
    },
    {
      "epoch": 9.9375,
      "grad_norm": 2.743544578552246,
      "learning_rate": 6.40625e-08,
      "loss": 0.6774,
      "step": 6360
    },
    {
      "epoch": 9.953125,
      "grad_norm": 2.7443666458129883,
      "learning_rate": 4.8437500000000006e-08,
      "loss": 0.8164,
      "step": 6370
    },
    {
      "epoch": 9.96875,
      "grad_norm": 2.9252383708953857,
      "learning_rate": 3.2812500000000003e-08,
      "loss": 0.7336,
      "step": 6380
    },
    {
      "epoch": 9.984375,
      "grad_norm": 2.7210254669189453,
      "learning_rate": 1.71875e-08,
      "loss": 0.737,
      "step": 6390
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.094369888305664,
      "learning_rate": 1.5625000000000001e-09,
      "loss": 0.8163,
      "step": 6400
    },
    {
      "epoch": 10.0,
      "eval_gen_len": 34.028318584070796,
      "eval_loss": 0.735078752040863,
      "eval_model_preparation_time": 0.0064,
      "eval_runtime": 136.7591,
      "eval_samples_per_second": 4.131,
      "eval_steps_per_second": 0.263,
      "step": 6400
    },
    {
      "epoch": 10.0,
      "step": 6400,
      "total_flos": 5.526462604935168e+16,
      "train_loss": 0.8730829840898514,
      "train_runtime": 10416.89,
      "train_samples_per_second": 4.915,
      "train_steps_per_second": 0.614
    }
  ],
  "logging_steps": 10,
  "max_steps": 6400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.526462604935168e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
